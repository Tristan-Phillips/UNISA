{"path":"Subjects/COS3751 - Techniques of Artificial Intelligence/Tutorial Letters/102_2018_1_b.pdf","text":"BAR CODE Deﬁne Tomorrow. university of south africa Tutorial Letter 102/1/2018 Techniques of Artiﬁcial Intelligence COS3751 Semester 1 School of Computing IMPORTANT INFORMATION This tutorial letter contains assignment 01 COS3751/102/1/2018 ASSIGNMENT 01 Due Date: 5 March 2018 UNIQUE ASSIGNMENT NUMBER: 698500 ONLY FOR SEMESTER 1 Study material: Chapters 1 through 4. You may skip sections 4.2 and 4.5. Important: when we use the phrase ‘formally deﬁne’, we are looking for a formal deﬁnition using some form of formal notation, and not simply an English description or deﬁnition. For example: ‘Deﬁne the initial state for an agent in Johannesburg. Answer: In(Johannesburg). Deﬁne the actions available to this agent given that the agent simply moves between major metropolitan areas. A: Actions(In(Johannesburg) = {Go(Bloemontein), Go(Durban),. . . }. When we want an English Deﬁnition we will explicitly ask for it. Question 1 (1.1) Consider an agent that is designed to deliver medication to a rural area. The area has very littly road access, and the nature of the settlement is such that there are no up to date maps of the lay-out of the settlement. The agent is a drone that is designed to ﬂy at low altitudes in order to deliver the medication to people who may not have access to medical services. The agent is capable of determining its location using a GPS, can determine its altitude, and speed, and can control these aspects (speed and altitude). It can thus ﬂy to a particular location and deliver medicine. Using a barcode reader it can determine that the correct medicine has been delivered to the correct person. Its fuel supply is sufﬁcient for deliveries and is thus not of consequence. Agents can also detect the presence of other agents. The company that provides the service may have many agents that delivers medicines. Choose from among the following environmental descriptions, and justify your choices in each case. (a) Is the environment fully, or partially observable? (b) Is the environment competative, or cooperative (you only need to consider medicine delivery agents)? (c) Is the environment static, or dynamic? (1.2) Is this an example of a model-based, or reﬂex-based agent? Justify your answer. Question 2 One night three friends come to a rickety bridge spanning a torrential river. They want to cross it, but do not trust the bridge to carry all of them at the same time. They decide to cross the bridge two at a time. To make matters worse, the bridge is in such disrepair that some of the wooden planks that make up the bridge have fallen away leaving gaping holes – making the crossing very dangerous. Luckily the three friends (Andile, Bob, and Charlize) have a single torch with them. 2 COS3751/102/1/2018 They decide that the people crossing the bridge will take the torch with them. Suppose the state is represented as a set S : {p|p ∈ P} with P = {Andile, Bob, Charlize, Torch}}. If pi ∈ S, then pi is on the right-hand side of the bridge, otherwise they (it) are on the left-hand side. Torch represents the torch and, as with the people, if it is present in S, then it means the torch is on the right-hand side of the bridge, otherwise it is on the left-hand side. As people (and the torch) move from one side of the bridge to the other, they are added/removed to the set reprenting the current state. For example, suppose we start with S = {Andile, Bob, Charlize, Torch} and Andile walks across the bridge with the torch, we have S′ = {Bob, Charlize}. (2.1) Deﬁne the goal state for this problem. (2.2) Suppose the current state is S = {Bob}. Deﬁne the applicable actions for this state. (Hint: you will ﬁrst need to deﬁne the possible actions that are available to the agent in general, then deﬁne the applicable actions for this state.) (2.3) Provide the transition model for the search, but limit your answer to the case where S = {Andile, Bob, Torch}. You will again have to provide the applicable actions before providing the transition model. Make sure you show the resulting states when applying the actions. Question 3 (3.1) Explain how a Breadth First Search (BFS) ensures that it always expands the shallow- est node ﬁrst. Provide an example to aid your discussion. (3.2) Explain when one might want to choose Depth First Search (DFS) over BFS. (Hint: In which version of the algorithm does one have an advantage over the other?) Question 4 Consider the search tree in Figure 1. Show the order in which the nodes will be expanded at each level (start with level 0 and continue until the goal test is successful), given that IDS is used. Assume the goal node is G, and that nodes are expanded from left to right (M is expanded before E and so on). (Hint: make sure you understand the difference between expansion and generation, and also that you understand when goal checks occur.) Question 5 Consider the graph provided in Figure 2, and answer the questions that follow. The step cost between nodes is provided next to the edges. (5.1) Prove that a consistent heuristic is admissable. (Hint: if you can prove that admissibility holds for nodes 1 step away from the goal, then you can prove that nodes k-steps away from the goal is admissible). 3 O M D K I C J H E L F G B N A Figure 1: Search Tree (Iterative Deepening Search (IDS)) K B J A O F M G I D E H L N C 8 2 7 5 2 4 8 4 6 2 2 10 7 8 6 5 2 Figure 2: Search (5.2) Perform a Uniform Cost Search (UCS) on the graph. The start node is M and the goal node is F . Provide a step-wise explanation of the search as it progresses. At each step, provide the frontier, and show which node is selected for expansion. Provide the ﬁnal path from the start to the goal. Use the following format for your answer (step 1 has been completed below): Step Node expanded Frontier 1. M( ˆg = 0) . . . . . . . . . Remember: the ﬁrst step of a well-written search algorithm is always to generate the start node (i.e. place the start node in the frontier). Step two should begin with expanding the node in the frontier with the smallest ˆg value. 4 COS3751/102/1/2018 (5.3) Perform an A ∗ search on the graph in Figure 2. The start node is G and the goal node is H. Provide a step-wise explanation of the search as it progresses. At each step, provide the frontier, and show which node is selected for expansion. Provide the ﬁnal path from the start to the goal. Use table 1 for the ˆh values for each node in the graph. Use the following format for your answer (step 1 has been completed below): Step Node expanded Frontier 1. G( ˆg = 0, ˆh = 20, ˆf = 20) 2 . . . . . . Remember: the ﬁrst step of a well-written search algorithm is always to generate the start node (i.e. place the start node in the frontier). Step two should begin with expanding the node in the frontier with the smallest ˆf value. Node Estimated distance to Goal A 12 B 15 C 8 D 13 E 15 F 18 G 19 H 0 I 7 J 7 K 14 L 14 M 12 N 17 O 8 Table 1: Estimated Distance to Goal for A ∗ search. Question 6 Consider the four-queens problem. We would like to populate a 4 × 4 board with 4 queens. A queen is a piece (from chess) that can capture any other piece on the same diagonal, or in the same ﬁle 1 or rank 2. Using local search algorithms, a search is performed as follows: • Initialise a board with queens placed randomly (one in each ﬁle), 1File is chess parlance for column. 2Rank is chess parlance for row. 5 • Deﬁne an objective function to aid the local search, • Generate a successor state from the current state by moving one queen randomly either up or down one square (in the same ﬁle), • An optimum (minimum/maximum) is considered a goal. Consider the following random start state (we represent the state grahically to aid your effort, and you are welcome to provide graphical representations of successor states if asked): 4 0Z0Z 3 ZqZq 2 0ZqZ 1 l0Z0 a b c d Figure 3: Four Queens Initial State (6.1) Provide a good objective function that can be used as a maximizer (i.e. a global maximum, a reward function) for the problem. Hint: 1. An objective function (also called either a loss, or reward function) is a function that maps the current state to some linear value which can be used to judge the ﬁtness or goodness of the state. When we want to avoid loss, we deﬁne an objective function with respect to loss, and we try to minimize loss by minimising the evaluation of the state using the objective function (i.e. we look for a state that results in the smallest value when evaluated using the objective function). When we want reward, we deﬁne an objective function with respect to reward and we try to maximize the objective function. 2. First write down the function in plain English, and then provide the mathematical equation for it. 3. Use the ranks, ﬁles, and diagonals in the state as part of your equation. (6.2) Now that you have deﬁned your objective function, use it to evaluate the start state as provided in Figure 3. Show your calculations. (6.3) A hill-climb/hill-descent local search generates a series of successors, and takes the best one from among them (using the objective function). Beginning from the initial state in Figure 3, provide two successors, one that is worse, and one that is an im- provement. Show why the successor is better, or worse by using the objective function to evaluate it. Remember: generate all possible successors, and choose the bet- ter/worse from among them. Remember, a successor state is generated by moving one queen, one row up or down. 6 COS3751/102/1/2018 (6.4) From the previous question, take the ’better’ state you identiﬁed. Generate all possible successors (remember: a successor is generated by moving one queen, one row up or down). Are there any improvements (show your calculations for each state)? (6.5) What type of topographical feature is most likely being created by the situation in the previous question? (Provide a rough sketch of this type of feature in a one dimensional state-space landscape.) c⃝UNISA 2018 (v2018.1.0) 7","libVersion":"0.2.3","langs":""}