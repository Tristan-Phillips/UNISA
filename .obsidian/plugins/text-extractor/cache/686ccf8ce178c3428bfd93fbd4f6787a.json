{"path":"Subjects/COS3712 - Computer Graphics/Unsorted/Ar/cos340exo-09_memo.pdf","text":"2 COS340-A October/November 2009 [TURN OVER] QUESTION 1 [10] a) OpenGL uses z-buffering for hidden surface removal. Explain how the z-buffer algorithm works and give one advantage of using this method. (5) b) Orthogonal, oblique and axonometric view scenes are all parallel view scenes. Define the term parallel view and explain the differences between orthogonal, axonometric, and oblique view scenes. (5) Answer: OpenGL uses a hidden-surface method called z-buffering T that saves depth information into an extra buffer which is used as objects are rendered so that parts of objects that are behind other objects do not appear in the image. The z-buffer records the depth or the distance from the COP of a pixel. T Thus, as polygons are scan-converted in random order, the algorithm checks the z-value of the pixel at the coordinates (in the frame buffer) that it is trying to draw to. If the existing pixel at these coordinates (i.e. if there already was a pixel) has a z-value further from the viewer than the pixel we are trying to draw, then the colour and depth of the existing pixel are updated, otherwise it continues without writing to the colour buffer or the depth buffer. T T Advantages:(1 mark for either answer) easy to implement in either software or hardware it is compatible with pipeline architectures - can execute at the same speed at which vertices are passing Answer: Parallel views - views with the COP at infinity. T Orthogonal views - projectors are perpendicular to the projection plane and projection plane is parallel to one of the principal faces of an object. T A single orthogonal view is restricted to one principal face of an object.T Axonometric view - projectors are perpendicular to the projection plane but projection plane can have any orientation with respect to object.T Oblique projection - projectors are parallel but can make an arbitrary angle to the projection plane T and projection plane can have any orientation with respect to object. 3 COS340-A October/November 2009 [TURN OVER] QUESTION 2 [8] a) Define the term homogeneous coordinates and explain why they are used in computer graphics. (4) b) Consider the line segment with endpoints a and b at (1, 2, 3) and (2, 1, 0) respectively. Compute the coordinates of vertices a and b that result after an anticlockwise rotation by 15E about the z- axis.(Show your workings) (4) Hint: The transformation matrix for rotation around the z-axis is (where θ is the angle of anticlockwise rotation). Answer: Homogeneous coordinates are four dimensional column matrices used to represent both point and vectors in three dimensions. TWhen points and vectors are represented using 3-dimensional column matrices one cannot distinguish between a point and a vector, with homogeneous coordinates we can make this distinction.TT marks can be awarded for any of the points mentioned below: A matrix multiplication in 3-dimensions cannot represent a change in frames, while this can be done using homogeneous coordinates.T All affine transformations can be represented as matrix multiplications in homogeneous coordinates.T Less arithmetic work is involved when using homogeneous coordinates.T The uniform representation of all affine transformations makes carrying out successive transformations far easier than in 3 dimensional space.T Modern hardware implements homogeneous coordinates operations directly, using parallelism to achieve high speed calculations.T 4 COS340-A October/November 2009 [TURN OVER] Then, to rotate a' and b' by 15E about the z-axis, we use the rotation matrix Similarly So a'' = (0.448, 2.191, 3) TT and b'' = (1.673, 1.484, 0) TT (4) QUESTION 3 [8] OpenGL is a pipeline model. In a typical OpenGL application a vertex will go through a sequence of 6 transformations or change of frames. In each frame the vertex has different coordinates. a) Name these coordinates in the order that they occur in the OpenGL vertex transformation process. [5] 5 COS340-A October/November 2009 [TURN OVER] b) Define the term perspective division and state specifically where it is used in the OpenGL vertex transformation process. [3] QUESTION 4 [12] a) Discuss the difference between the RGB colour model and the indexed colour model with respect to the depth of the frame (colour) buffer. (4) In both models, the number of colours that can be displayed depends on the depth of the frame (colour) buffer. T The RGB model is used when a lot of memory is available, eg 12 or 24 bits per pixel. T/2 These bits are divided into three groups, representing the intensity of red, green and blue at the pixel, respectively. T The RGB model becomes unsuitable when the depth is small, because shades become too distinct/discreet. The indexed colour model is used where memory in the colour buffer is limited. T/2 The bits per pixel are used to index into a colour-lookup table where any shades of any colours can be specified (depending only on the colours that the monitor can show). T b) Describe, with the use of diagrams, the Cohen-Sutherland line clipping algorithm. (8) 1/2 mark each for correct names ; 2 marks for correct order Object or model coordinates World coordinates Eye or camera coordinates Clip coordinates Normalized device coordinates Window or screen coordinates Perspective division is the division of homogeneous coordinates by the w component T. It is used to transform the clip coordinates, which are still represented by homogenous coordinates into three- dimensional representations in normalized device coordinates.TT 6 COS340-A October/November 2009 [TURN OVER] Angel 7.4.1 (2 bonus marks) The algorithm starts by extending the sides of the window to infinity, thus breaking up space into nine regions.UEach region is assigned a 4 -bit binary number, or outcode. as shown in the diagram below.U 1001 1000 1010 10 10 101 100 110 UU For each endpoint of a line segment, we first compute the endpoint’s outcode. Consider a line segment whose outcodes are given by X(endpoint 1) and Y(endpoint 2).We have four cases: UU X = Y = 0 :Both endpoints are inside the clipping window(AB in diagram), segment can be rasterized.U X … 0, Y = 0. One endpoint is inside the window and one is outside.(segment CD) We must shorten the line segment by calculating 1 or 2 intersections.U X & Y … 0: By taking the butwise AND of the outcodes we determine whether or not the two endpoints lie on the same outside side of the window.If so the line is discarded.(segment EF)U X & Y = 0: Both segments are outside but they are outside on different edges of the window.We cannot tell from outcodes whether segment can be discarded or must be shortened(segments IJ and GH). Need to intersect with one side of window and determine outcode of resulting point. U 7 COS340-A October/November 2009 [TURN OVER] QUESTION 5 [12] a) Discuss the distinguishing features of ambient, point, spot and distant light sources. (8) 2 marks each: • An ambient light source produces light of constant intensity throughout the scene. All objects are illuminated from all sides. • A point light source emits light equally in all directions, but the intensity of the light diminishes with (i.e. proportional to the inverse square of) the distance between the light and the objects it illuminates. Surfaces facing away from the light source are not illuminated. • A spot light source is similar to a point light source except that its illumination is restricted to a cone in a particular direction. A spot light source can also have more light concentrated in the centre of the cone. • A distant light source is like a point light source except that the rays of light are all parallel. The main difference is the improved speed of rendering calculations. b) Describe the difference between flat and smooth shading. (4) Flat shading is where a polygon is filled with a single colour or shade across its surface. A single normal is calculated for the whole surface, and this determines the single colour. TT Smooth shading is where colour is interpolated across the surface of a polygon. This is usually used to give the appearance of a rounded surface, and is achieved by defining different normals at each of the vertices of the polygon, and interpolating the normals across the polygon. TT QUESTION 6 [8] a) Describe environment maps, and explain the difference between the use of cube maps and spherical maps to implement them. (4) 8 COS340-A October/November 2009 [TURN OVER] One way to create fairly realistic rendering of an object with a highly reflective surface is to map a texture to its surface (called an environment map) which contains an image of other objects around the highly reflective object as they would be seen reflected in its surface. TT A spherical map is an environment map in the form of a sphere, which is then converted to a flat image (by some projection) to be applied to the surface. T A cube map is in the form of a cube, i.e. six projections of the other objects in the scene. The renderer then picks the appropriate part of one of these projections to map to each polygon on the surface of the reflective object (as a texture). T (b) Briefly discuss the main difference between the opacity of a surface and the transparency of a surface with respect to alpha blending. (4) Answer: Angel Section 7.9: The alpha channel is the fourth colour in the RGBA (or RGBα) colour mode. Like the other colour components, the application program can control the value of A (or α) for each pixel. If blending is enabled in RGBA mode, the value of α controls how the RGB values are written into the frame buffer. T Because surfaces of multiple objects lying behind one another can contribute to the colour of a single pixel, we say that the colours of these surfaces are blended or composited together. T Opacity of a surface is a measure of how much light penetrates through that surface. T An opacity of 1 (α = 1) corresponds to a completely opaque surface that blocks all light from surfaces hidden behind it. A surface with an opacity of 0 is transparent: All light passes through it. The transparency or translucency of a surface with opacity α is given by 1 ! α.T 9 COS340-A October/November 2009 [TURN OVER] QUESTION 7 [12] Consider the following OpenGL program that draws two walls of a room that meet at a corner. In the middle of the room is a rotating square suspended in mid air. Answer the questions that follow 1. #include <gl/glut.h> 2. #include <fstream> 3. #include <cmath> 4. float eye_pos[3] = {100, 50, -100}; 5. GLfloat angle = 0; 6. bool rotating = true; 7. bool clockwise = true; 8. void drawPolygon() 9. { 10. glColor3f (1.0, 1.0, 0.0); 11. glBegin(GL_POLYGON);// Draw square 12. glVertex3d(20, 20, 0); 13. glVertex3d(20, -20, 0 ); 14. glVertex3d(-20, -20, 0); 15. glVertex3d(-20, 20, 0); 16. glEnd(); 17. } 18. void drawRoom() 19. { 20. glColor3f (1.0, 1.0, 1.0); // left wall 21. glBegin(GL_POLYGON); 22. glVertex3d(0, 0, 0); 23. glVertex3d(0, 100, 0 ); 24. glVertex3d(0, 100, -100); 25. glVertex3d(0, 0, -100); 26. glEnd(); 27. glBegin(GL_POLYGON); // right wall 28. glVertex3d(0, 0, 0); 29. glVertex3d(100, 0, 0); 30. glVertex3d(100, 100, 0); 31. glVertex3d(0, 100, 0); 32. glEnd(); 33. } 34. void display() 35. { glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); 10 COS340-A October/November 2009 [TURN OVER] 36. glMatrixMode(GL_MODELVIEW); 37. glLoadIdentity(); 38. gluLookAt(eye_pos[0], eye_pos[1], eye_pos[2], 0.0, 50.0, 0.0, 0.0, 1.0, 0.0); 39. drawRoom(); 40. glTranslatef(40, 40, -40); 41. glRotatef(angle, 0, 1, 0); 42. drawPolygon(); 43. glFlush(); 44. glutSwapBuffers();} 45. void idle() 46. { 47. if (rotating) 48. { if (!clockwise) // rotate counter-clockwise {angle-= 0.5; if (angle < -360.0) angle += 360.0;} else // rotate clockwise 49. { angle+= 0.5; if (angle > 360.0) angle -= 360.0;} 50. } 51. glutPostRedisplay(); 52. } 53. void myInit() 54. { 55. glPolygonMode(GL_FRONT, GL_FILL); 56. glMatrixMode(GL_PROJECTION); 57. gluPerspective(90, -1, 10, 210); 58. } 59. int main(int argc, char** argv) 60. { 61. glutInitDisplayMode(GLUT_DOUBLE | GLUT_RGB | GLUT_DEPTH); 62. glutInitWindowSize(700, 700); 63. glutCreateWindow(\"Room with floating shapes\"); 64. myInit(); 65. glutDisplayFunc(display); 66. glutIdleFunc(idle); 67. glutMainLoop(); 68. return 0; 69. } 11 COS340-A October/November 2009 [TURN OVER] a) Say the following function is inserted in the program, and is called between lines 64 and 65: void setupMenus() { int main_menu = glutCreateMenu(mainMenuCallback); glutAddMenuEntry(\"Rotate Clockwise\", 0); glutAddMenuEntry(\"Rotate anti-clockwise\", 1); glutAddMenuEntry(\"Pause Rotation\", 2); glutAddMenuEntry(\"Quit\", 3); glutAttachMenu(GLUT_RIGHT_BUTTON); } Write the callback function for this menu to do the following: Rotate square clockwise Rotate square anti-clockwise Pause rotation of square Exit Program Hint : The rotation of the square is controlled by boolean variables rotating and clockwise.(see lines 6 and 7 as well as function void idle ). [4] void mainMenuCallback(int id) { switch (id) { case 0:rotating = true; clockwise = true; break; case 1: rotating = true; clockwise = false; break; case 2: rotating = false; break; case 3: exit(0); } 12 COS340-A October/November 2009 [TURN OVER] b) Write a keyboard callback function that will allow the user to zoom in towards the corner of the room and back out again. Use the ‘<‘ to zoom in and ‘>’ key to zoom out.. You do not need to set maximum or minimum values for the camera position .The y value of the camera position will remain constant and the zoom increment can be set to 3.0. You can assume that glutKeyboardFunc(keyboard) is added to the main function Hint: Take note of the initial position of the camera in line 4 relative to the visible corner of the room. void keyboard(unsigned char key, int x, int y) {switch (key) {case '<' : eye_pos[0] += 3.0;//increment value can be different eye_pos[2] -= 3.0; break; case '>' : eye_pos[0] -= 3.0; eye_pos[2] += 3.0; break; } return; } c) Consider the following function for loading an image from a file into an array, and for specifying it as a texture: void setTexture() { const int WIDTH = 512; const int HEIGHT = 1024; GLubyte image[WIDTH][HEIGHT][3]; FILE * fd; fd = fopen(\"texture.bmp\",\"rb\"); fseek(fd, 55, SEEK_SET); // Move file pointer past header info fread(&image, 1, WIDTH*HEIGHT*3, fd); fclose(fd); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexImage2D(GL_TEXTURE_2D, 0, 3, WIDTH, HEIGHT, 0, GL_RGB, GL_UNSIGNED_BYTE, image); } The file texture.bmp contains a 512x1024 image.If this function is inserted in the above program (and called in the main function just before myinit is called), give the statements that 13 COS340-A October/November 2009 [TURN OVER] need to be inserted in the drawroom function (and state where) to apply the texture to the surface of the right wall of the room . In function drawroom, insert the following calls of glTexCoord2f before the respective calls of gkVertex3f: glTexCoord2f(0, 0); //after line 27 T glTexCoord2f(0, 1); //after line 28 T glTexCoord2f(1, 1); //after line 29 T glTexCoord2f(0, 0); //after line 30 T","libVersion":"0.2.3","langs":""}