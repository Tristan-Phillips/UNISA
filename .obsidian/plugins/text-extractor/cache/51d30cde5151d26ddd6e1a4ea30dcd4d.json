{"path":"UNISA/98906 - BSc Science in Computing/INF3720 - Human-Computer Interaction II/Unsorted/INF3720/z/INF3720 Exam pack/Exam Shit/Materials/INF3720 ASIGN2 MEMO-TuT202-.pdf","text":"INF3720/202/02/2016 Tutorial Letter 202/02/2016 Human Computer Interaction INF3720 Semester 2, Assignment 02 Memo School of Computing: Information Systems IMPORTANT INFORMATION Please register on myUnisa, activate your myLife e-mail address and make sure that you have regular access to the myUnisa module website for INF3720 Note: This is an online module and therefore it is available on myUnisa. However, in order to support you in your learning process, you will also receive some study material in printed format. BARCODE 2 Question 1 (Not marked, the answer already provided) This question takes you through the complete development lifecycle for an interactive product. You are required to design and evaluate an interactive product for booking tickets online for a cinema. A user is supposed to be able to book a venue for watching a movie. Most cinema venues have an online booking facility already but it can be awkward and frustrating to identify and book the seats you want. In order for you to successfully answer this question, study the model answer provided under additional resources (Assignment 02 – Question 01.pdf) 1.1 Identify users’ needs (requirements) for the online facility. To identify user needs, you should collect data from the users. Record your data carefully. 1.2 Based on the user requirements, choose a user profile and produce one persona and one scenario for each, capturing how the user is expected to interact with the product. 1.3 Perform a task analysis on the main tasks associated with the ticket booking system, i.e booking a ticket. 1.4 Using the data gathered in 1.1 and your subsequent analysis, identify different kinds of requirements for the product under the following headings: environmental, user and usability. Answer Markers: Do not mark question one. Skip it. Question 2 Compare usability testing (UT) and field studies (FS) under the following headings: 2.1 The environment in which the evaluation is conducted (2 marks). 2.2 The participants (2 marks). 2.3 Data collection (8 marks). 2.4 Advantages and disadvantages (give at least 3 advantages and dsiadvantages). (12 marks) Answer 2.1 The environment in which the evaluation is conducted • Field Studies: conducted in the natural environment where the system or product is used. • Usability testing: conducted in a laboratory where the conditions are controlled. 2.2 The participants. • For Usability Testing, 5 to12 users are an acceptable number. • For Field Studies may include thousands or even just one participant. 2.3 Data collection. Usability testing (Allocate 4 marks) • The focus is mainly on the product being tested and its usability problems. • Data collection includes user test, interviews and user satisfaction questionnaire, which are lab based. • Variables are controlled during data collection. • Data is captured through video recording of body gestures, think aloud, observations, completing questionnaire survey and structured or semi structured interviews. Field testing (Allocate 4 marks) • The focus is on the user, the environment and the product. • Data collection is mostly by qualitative, involving observations, focus groups and interviews. INF3720/202 3 • Variables not controlled during data collection. • Data is captured through audio and video recording, taking field notes, filling diaries 2.4 Advantages and disadvantages, (Allocate 3 marks for advantages per test and 3 marks for disadvantages per test) Advantages Disadvantages Usability testing • Feedback is direct from target audience • Variables are controllable • Security of sensitive data be enforced • Ability to capture user reactions through body gestures, language and facial expression of participants. • Laboratory based usability studies capture a snapshot of the use in a simulated use environment. • Simulating the use setting is very hard, time consuming, expensive and sometimes impossible to attain • users are isolated from contextual factors • new electronic devices are used in a context, in which multitasking is a key factor • evaluating use experience developed over time instead of snapshot of use provides more reliable information Field testing • Eliminates both the need for a lab environment and the effect of a lab environment on participants • Accommodates diverse groups of participants • Generally is less expensive than a traditional in-person lab testing • It is an opportunity to administer the test to a larger group of people than you might be able to accommodate in a lab environment • Security could be compromised if testing sensitive, privileged, or intellectual property • Restricted or no view of the user’s body language might inhibit some of the cues to their reactions to the material being tested • Technical difficulties are likely if users: • Are not comfortable with the technology involved • Have conflicting software or equipment on their machines • Are unable to share their screen over the Internet • Have unreliable or slow connection speeds • If your test requires special equipment or software downloads or plug-ins which the participants may be unwilling or unable to download 4 Question 3 Go to myUnisa under Additional resources and download the file “Case study – Academic library. pdf”. Read the case study and answer the following questions. 3.1 What was the purpose of the usability evaluation? (2 marks) 3.2 Which challenges were encountered in carrying the usability testing of the website? Give at least 3 challenges. (3 marks) 3.3 List the main tasks or activities performed by the participants during the usability testing of the website. (6 marks) 3.4 Which data collection methods were used to collect data? (5 marks) 3.5 List any five issues discovered by the usability testing. (5 marks) Answer 3.1 What was the purpose of the usability evaluation? (Allocate 2 marks to any of the following) - To determine whether or not the library’ users could effectively use the web site to perform specific tasks. - To determine how effective the library website worked when used for library research by undergraduates with little or no experience using the website. 3.2 Which challenges were encountered in carrying the usability testing of the website? Give at least 3 challenges. (Allocate 1mark for any 3 given by the student) - securing a place for carrying the experiment - privacy of the testing room, to allow participants to comfortably talk aloud - some of the participants were not punctual on appointment time and some did not pitch up - participants had varying learning abilities and technical proficiency - difficulties in interpreting the results due to subjective nature of variables such as aesthetics and idiosyncrasies 3.3 List the main tasks or activities performed by the participants during the usability testing of the website. (Allocate 2 marks per task) - using the site to identify an item/title that is part of the library’s reading collections - using the website to locate the most appropriate resource for finding journal articles on a specific topic - using the site to find an appropriate starting point for researching topic without necessarily knowing the format or source of information. 3.4 Which data collection methods were used to collect data? (Allocate 1 mark per method) - think aloud - direct observation of users being tested - a written log of events that took place during testing - a record of user movements during navigation - post evaluation user satisfaction questionnaire - post evaluation report by the tester 3.5 List any five issues discovered by the usability testing. (Allocate 1 mark for any 5 issues identified) - the “Web Search” and “Need Help” links failed the “easy to learn” measure - participants confused by the meaning of, “Online Resources” and “Library Catalogues” , which resulted in failing to satisfy the “causes few errors” measure - the process of connecting to the catalog through the “Web-interface link” was unnecessarily unpleasant. - “Online Resources” page was difficult to decipher - Users did not find the “Online Resources” page easy to use when searching an article from a named database. Participants could not identify the database titles. INF3720/202 5 - On finding articles on general topics, the ‘Online Resources” page failed the entire usability test because the participants could not identify the “Quick Start” link. - The participants could not identify “reference Resources” as a logical link to begin exploration of a topic. - Question 4 [20 marks] Assume the role of an expert evaluator and do a heuristic evaluation of a single typical student task that you have identified as a possible problem on myUnisa. Use all ten heuristics that appear in the prescribed book Answer (Allocate 2 marks per heuristic) The answer is dependent on the task chosen and we will provide a few general guidelines. Firstly, the evaluator should consider whether the ten Nielsen heuristics are all equally suitable for the evaluation of a task on the myUnisa system. You may want to modify some of the heuristics to cater for unique aspects of the task that you have chosen or specific aspects of the myUnisa system. Heuristics: • Visibility of the system status • Match between system and the real world • User control and real world • Consistency and standards • Error prevention • Recognition rather than recall • Flexibility and efficiency of use • Aesthetic and minimalist design • Help users recognize, diagnose and recover from errors • Help and documentation Secondly, you should consider what format you will use for the evaluation. The easiest is to construct a fill-in questionnaire listing your heuristics and then giving it to a few other myUnisa users or students (including yourself) to complete. After the evaluation you could compile a list of all the usability problems that have been identified and then sort them according to their impact or severity. You can also sort the list according to how easy (or costly) it will be to fix the usability problems. You will then be able to present to the myUnisa development team a list of usability problems that are rated as severe and easy to fix at the top (i.e. high priority problems) to not severe and difficult to fix at the bottom (or low priority or costly-to-fix problems).","libVersion":"0.2.3","langs":""}