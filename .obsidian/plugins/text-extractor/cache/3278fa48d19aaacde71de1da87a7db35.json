{"path":"Subjects/MAT1503 - Linear Algebra I/Unsorted/ass1/Proofs.pdf","text":"Linear Algebra Proofs Below are several proof techniques that you should KNOW how to apply by the end of 3191 . . . this means that any of these is fair game for the ﬁnal exam. Each one below comes with several examples. 1. Let H be a subset of a vector space V . Prove that H is a subspace of V . Technique: Let u, v ∈ H and let c, d ∈ R. Show that cu + dv ∈ H by checking that the membership criterial for H are satisﬁed. Examples: (a) Let A be an m × n matrix. Prove that N ul(A) = {x : Ax = 0} is a subspace of Rn (b) Let A be an m × n matrix. Prove that Col(A) = {b : Ax = b for some x ∈ Rn} is a subspace of Rm. (c) Let C[a, b] be the set of continuous function on the interval [a, b]. Show that S = {f ∈ C[a, b] : f (a) = f (b)} is a subspace of C[a, b]. (d) Show that the set of all matrices of the form ( a b 0 d ) is a subspace of the 2 × 2 matrices (e) Let λ be an eigenvalue of a square matrix A. Prove that the eigenspace, Eλ, is a subspace of Rn. (f) Prove that the orthogonal complement, W ⊥ = {v ∈ Rn : v · w = 0 ∀w ∈ W } is a subspace of Rn. 2. Prove that the transformation T : V → W is linear. Technique: Let v1, v2 ∈ V and c, d ∈ R and show that T (c1v1 + c2v2) = c1T (v1) + c2T (v2) using the deﬁnition of T (and possibly properties from the spaces V and W ). Examples: (a) Prove that if T (x) = Ax where A is an m × n matrix, then T is a linear transformation. (b) Let M2×2 be the vector space of all 2 × 2 matrices, and deﬁne T : M2×2 → M2×2 by T (A) = A + A T . Prove that T is a linear transformation. (also describe the kernel of T ) (c) Deﬁne T : C[0, 1] → C[0, 1] as follows: For f ∈ C[0, 1], let T (f ) be the antiderivative, F , of f such that F (0) = 0. Prove that T is a linear transformation. (also describe the kernel of T ) 3. Prove that the set {v1, v2, . . . , vn} is linearly independent. Technique: Let c1, c2, . . . , cn ∈ R. Prove that the equation c1v1 + c2v2 + · · · cnvn = 0 only has the trivial solution. Examples: (a) Prove that the set       1 1 0    ,    1 1 1    ,    1 −2 1       is linearly independent. (b) Prove that the set of polynomials {1, 1 − t, 1 + t − t2} is linearly independent. (c) Prove that the set of matrices {(1 1 1 0 ) , (2 −1 1 −1 ) , (3 3 3 3 )} is linearly independent. (d) Let S = {v1, . . . , vn} be an orthogonal set of non-zero vectors in Rn. Prove that S is a linearly independent set. 4. Prove that a set S = {v1, . . . vn} is a basis for a vector space V . 1 Technique: Prove that S spans the vector space and prove that S is linearly independent. Examples: (a) Let A ∈ Mn×n such that A −1 exists. Prove that the columns of A form a basis for Rn. (b) Prove that the set of polynomials {1, 1 − t, 1 + t − t2} is a basis for P2. (c) Prove that the set of matrices {(1 1 1 0 ) , ( 2 −1 1 −1 ) , ( 3 3 3 3 ) , ( 0 0 −1 1 )} is a basis for M2×2. 2 Solutions 1. Let H be a subset of a vector space V . Prove that H is a subspace of V . Technique: Let u, v ∈ H and let c, d ∈ R. Show that cu + dv ∈ H by checking that the membership criterial for H are satisﬁed. Examples: (a) Let A be an m × n matrix. Prove that N ul(A) = {x : Ax = 0} is a subspace of Rn (Soln) Let u, v ∈ N ul(A) and let c, d ∈ R. Observe that A(cu + dv) = A(cu) + A(dv) = cAu + dAv = c0 + d0 = 0 + 0 = 0. Therefore cu + dv ∈ N ul(A). Therefore, N ul(A) is a subspace of Rn. (b) Let A be an m × n matrix. Prove that Col(A) = {b : Ax = b for some x ∈ Rn} is a subspace of Rm. (Soln) Let b1, b2 ∈ Col(A) and let c, d ∈ R. If bj ∈ Col(A) then there exists an xj such that Axj = bj. Deﬁne x = (cx1 + dx2) and observe that Ax = A(cx1 + dx2) = cAx1 + dAx2 = cb1 + db2. Therefore there is an x such that Ax = cb1 + db2, and this means that cb1 + db2 ∈ Col(A). Therefore, Col(A) is a subspace of Rm. (c) Let C[a, b] be the set of continuous function on the interval [a, b]. Show that S = {f ∈ C[a, b] : f (a) = f (b)} is a subspace of C[a, b]. (Soln) Let f, g ∈ S and let c, d ∈ R. First observe that since f and g are continouous on [a, b] we must have cf + dg continuous on [a, b] (from calculus). Furthermore, (cf + dg)(a) = (cf )(a) + (dg)(a) = cf (a) + dg(a) = cf (b) + dg(b) = (cf )(a) + (dg)(b) = (cf + dg)(b) where the third equal sign is true since f, g ∈ S. Hence, cf + dg ∈ S. Therefore, S is a subspace of C[a, b]. (d) Show that the set of all matrices of the form ( a b 0 d ) is a subspace of the 2 × 2 matrices (Soln) (we’ll use a theorem to do the work for us on this one). Observe that matrices of this form must belong to the set S = span {(1 0 0 0 ) , ( 0 1 0 0 ) , (0 0 0 1 )} Since all matrices of the desired form can be written as the span of a set then they must form a subspace (theorem 1 pg 194). (e) Let λ be an eigenvalue of a square matrix A. Prove that the eigenspace, Eλ, is a subspace of Rn. (Soln) Let u, v ∈ Eλ and let c, d ∈ R. Observe that A(cu + dv) = cAu + dAv = c(λu) + d(λv) = λ(cu + dv). Therefore, cu + dv ∈ Eλ. Therefore, Eλ is a subspace of Rn (f) Prove that the orthogonal complement, W ⊥ = {v ∈ Rn : v · w = 0 ∀w ∈ W } is a subspace of Rn. (Soln) Let u, v ∈ W ⊥ and let c, d ∈ R. Since u, v ∈ W ⊥ we know that u · w = 0 = v · w for all w ∈ W . Observe that (cu + dv) · w = cu · w + dv · w = c(0) + d(0) = 0 + 0 = 0. Therefore, cu + dv ∈ W ⊥. Therefore, W ⊥ is a subspace of Rn 2. Prove that the transformation T : V → W is linear. Technique: Let v1, v2 ∈ V and c, d ∈ R and show that T (c1v1 + c2v2) = c1T (v1) + c2T (v2) using the deﬁnition of T (and possibly properties from the spaces V and W ). Examples: (a) Prove that if T (x) = Ax where A is an m × n matrix, then T is a linear transformation. (Soln) Let v1, v2 ∈ V and let c, d ∈ R. Observe that T (cv1 +dv2) = A(cv1 +dv2) = cAv1 +dv2 = cT (v1)+dT (v2). Therefore T is linear. 3 (b) Let M2×2 be the vector space of all 2 × 2 matrices, and deﬁne T : M2×2 → M2×2 by T (A) = A + A T . Prove that T is a linear transformation. (also describe the kernel of T ) (Soln) Let A, B ∈ M2×2 and let c, d ∈ R. Observe that T (cA + dB) = (cA + dB) + (cA + dB) T = cA + dB + cA T + dA T = c(A + A T ) + d(B + BT ) = cT (A) + dT (B). Therefore T is linear. The kernel described as ker(T ) = {( 0 a −a 0 ) : a ∈ R } . (c) Deﬁne T : C[0, 1] → C[0, 1] as follows: For f ∈ C[0, 1], let T (f ) be the antiderivative, F , of f such that F (0) = 0. Prove that T is a linear transformation. (also describe the kernel of T ) (Soln) Let f, g ∈ C[0, 1] and let c, d ∈ R. Observe that T (cf + dg) = ∫ (cf + dg)dx = c ∫ f dx + d ∫ gdx = cF + dG = cT (f ) + dT (g). Therefore T is linear. The kernel contains only the zero function. 3. Prove that the set {v1, v2, . . . , vn} is linearly independent. Technique: Let c1, c2, . . . , cn ∈ R. Prove that the equation c1v1 + c2v2 + · · · cnvn = 0 only has the trivial solution. Examples: (a) Prove that the set       1 1 0    ,    1 1 1    ,    1 −2 1       is linearly independent. (b) write the three vectors as the columns of a matrix, A, and row reduce . . . you will see three pivots, and this implies that the only solution to the equation Ax = 0. Therefore the vectors are linearly independnet. (c) Prove that the set of polynomials {1, 1 − t, 1 + t − t2} is linearly independent. (d) Let c1, c2, c3 ∈ R. Observe that c1(1) + c2(1 − t) + c3(1 + t − t2) = (c1 + c2 + c3) + (c3 − c2)t − c3t3. If this polynomial is zero then it is clear that c3 = 0, c3 − c2 = 0, and c1 + c2 + c3 = 0. The obvious solution to this system is c1 = c2 = c3 = 0. Therefore the polynomials are linearly independent. (e) Prove that the set of matrices {(1 1 1 0 ) , (2 −1 1 −1 ) , (3 3 3 3 )} is linearly independent. (Soln) First write the coordinate vectors for each matrix with respect to the standard basis for M2×2: [v1] =       1 1 1 0       , [v2] =       2 −1 1 −1       , [v3] =       3 3 3 3       Now write these vectors as the columns of a 4 × 3 matrix and row reduce. You will ﬁnd that there are three pivots, and therefore the columns are linearly independent. Since the coordinate vectors are independent we know that the matrices must be independent. (f) Let S = {v1, . . . , vn} be an orthogonal set of non-zero vectors in Rn. Prove that S is a linearly independent set. (Soln) Let c1, . . . cn ∈ R such that c1v1 +· · · cnvn = 0. Take the dot product with v1 and we get 0 = v1 · n∑ j=1(cj vj) = c1||v1||2. Therefore, c1 = 0. Similarly we ﬁnd that c2, c3, . . . cn = 0. Therefore S is linearly independent. 4 4. Prove that a set S = {v1, . . . vn} is a basis for a vector space V . Technique: Prove that S spans the vector space and prove that S is linearly independent. Examples: (a) Let A ∈ Mn×n such that A −1 exists. Prove that the columns of A form a basis for Rn. (b) From the invertible matrix theorem, the columns of an invertible matrix are independent and span Rn. Therefore the columns form a basis for Rn. (c) Prove that the set of polynomials {1, 1 − t, 1 + t − t2} is a basis for P2. (d) From the proof above we see that this set is linearly independent. It is also clear that in order to form a quadratic polynomial we must have all three vectors from the set. Therefore the set spans P2. (e) Prove that the set of matrices {(1 1 1 0 ) , ( 2 −1 1 −1 ) , ( 3 3 3 3 ) , ( 0 0 −1 1 )} is a basis for M2×2. (f) Using a similar method as the proof above we can see that the linearly independent (use coordinate vectors). Also, the set of 2 × 2 matrices is four dimensional so we know that any linearly independent set of four vectors must form a basis. 5","libVersion":"0.2.3","langs":""}