{"path":"UNISA/98906 - BSc Science in Computing/COS3751 - Techniques of Artificial Intelligence/Telegram Notes/lec07_constraintsatisfaction.pdf","text":"Fundamentals of Artificial Intelligence Constraint Satisfaction Problems Constraint Satisfaction Problems ‚Ä¢ A constraint satisfaction problem consists of three components, X, D, and C: X is a set of variables, {X1, . . . ,Xn}. D is a set of domains, {D1, . . . ,Dn}, one for each variable. C is a set of constraints that specify allowable combinations of values. ‚Ä¢ Each domain Di consists of a set of allowable values, {v1, . . . , vk} for variable Xi. ‚Ä¢ Each constraint Ci consists of a pair {scope, rel }, where scope is a tuple of variables that participate in the constraint and rel is a relation that defines the values that those variables can take on. ‚Ä¢ A relation can be represented as an explicit list of all tuples of values that satisfy the constraint, or as an abstract relation that supports two operations. ‚Ä¢ If X1 and X2 both have the domain {A,B}, then the constraint saying the two variables must have different values can be written as <(X1,X2), [(A,B), (B,A)]> or as <(X1,X2),X1‚â†X2> Constraint Satisfaction Problems ‚Ä¢ In standard search problem: ‚Ä¢ a state is a black box with no internal structure. ‚Ä¢ it that supports goal test, eval, successor. ‚Ä¢ In CSP: ‚Ä¢ A state is defined by variables Xi with values from domain Di ‚Ä¢ A goal test is a set of constraints specifying allowable combinations of values for subsets of variables ‚Ä¢ CSP allows useful general-purpose algorithms with more power than standard search algorithms Constraint Satisfaction Problems ‚Ä¢ Each state in a CSP is defined by an assignment of values to some or all of the variables, {Xi=vi,Xj= vj , . . .}. ‚Ä¢ An assignment that does not violate any constraints is called a consistent (or legal) assignment. ‚Ä¢ A complete assignment is an assignment in which every variable is assigned. ‚Ä¢ A solution to a CSP is a consistent, complete assignment. ‚Ä¢ A partial assignment is one that assigns values to only some of the variables. ‚Ä¢ In order to solve a CSP, a consistent complete assignment must be found (be searched). Example: Map-Coloring ‚Ä¢ We are given the task of coloring each region of Australia either red, green, or blue in such a way that no neighboring regions have the same color. ‚Ä¢ To formulation as a CSP, Variables: Each region is a variable: X = {WA,NT,Q,NSW, V,SA, T} . Domains: The domain of each variable is the set Di = {red , green, blue}. Constraints require neighboring regions to have distinct colors. ‚Ä¢ Since there are nine places where regions border, there are nine constraints: C = {SA ‚â† WA, SA ‚â† NT, SA ‚â† Q, SA ‚â† NSW, SA ‚â† V, WA ‚â† NT, NT ‚â† Q,Q ‚â† NSW, NSW ‚â† V } . Example: Map-Coloring Variables WA, NT, Q, NSW, V , SA, T Domains Di = {red, green, blue} Constraints: ‚Ä¢ adjacent regions must have different colors ‚Ä¢ e.g., WA‚â†NT (if the language allows this), or (WA,NT) ‚àä {(red,green), (red,blue),(green,red),‚Ä¶} Example: Map-Coloring ‚Ä¢ Solutions are assignments satisfying all constraints, e.g., {WA=red, NT=green, Q=red, NSW=green, V=red, SA=blue, T=green} Constraint Graph ‚Ä¢ It can be helpful to visualize a CSP as a constraint graph. ‚Ä¢ The nodes of the constraint graph correspond to variables of the problem, ‚Ä¢ A link of the constraint graph connects two variables in a constraint. (Binary CSP) ‚Ä¢ General-purpose CSP algorithms use the graph structure to speed up search. Why formulate a problem as a CSP? ‚Ä¢ CSPs yield a natural representation for a wide variety of problems. ‚Ä¢ If we already have a CSP-solving system, it is often easier to solve a problem using it than to design a custom solution using another search technique. ‚Ä¢ CSP solvers can be faster than state-space searchers because the CSP solver can quickly eliminate large portions of the search space. ‚Ä¢ For example, once we have chosen {SA=blue} in the Australia problem, we can conclude that none of the five neighboring variables can take on the value blue. ‚Ä¢ Without taking advantage of constraint propagation, a search procedure would have to consider 35 =243 assignments for the five neighboring variables; ‚Ä¢ With constraint propagation we never have to consider blue as a value, so we have only 25 =32 assignments to look at, a reduction of 87%. ‚Ä¢ With CSPs, once we find out that a partial assignment is not a solution, we can immediately discard further refinements of the partial assignment. ‚Ä¢ Many problems that are intractable for regular state-space search can be solved quickly when formulated as a CSP. Variations on the CSP formalism types of variables ‚Ä¢ The simplest kind of CSP involves variables that have discrete, finite domains. ‚Ä¢ Map-coloring problems, scheduling with time limits and 8-queens problem are finite-domain CSP. ‚Ä¢ A discrete domain can be infinite: the set of integers or the set of strings ‚Ä¢ With infinite domains, constraints cannot be enumerated by all allowed combinations of values. ‚Ä¢ With infinite domains, a constraint language must be used to describe constraints such as T1+d1‚â§T2 directly, without enumerating the set of pairs of allowable values for (T1, T2). ‚Ä¢ Linear constraints on integer variables are solvable. ‚Ä¢ No algorithm exists for solving general nonlinear constraints on integer variables. ‚Ä¢ Continuous-domain CSPs with linear constraints are solvable in polynomial time by linear programming methods. Variations on the CSP formalism types of constraints ‚Ä¢ Unary Constraint restricts the value of a single variable. ‚Ä¢ Ex: <(SA),SA=green> ‚Ä¢ Binary Constraint relates two variables. ‚Ä¢ For example, SA‚â†NSW is a binary constraint. ‚Ä¢ A binary CSP can be represented as a constraint graph. ‚Ä¢ Higher-order constraints (global constraints) involve 3 or more variables. ‚Ä¢ A CSP can be transformed into a CSP with only binary constraints ‚Ä¢ Violation of absolute constraints rules out a potential solution. ‚Ä¢ Many real-world CSPs include preference constraints indicating which solutions are preferred. ‚Ä¢ For example, in a university class-scheduling problem there are absolute constraints that no professor can teach two classes at the same time. ‚Ä¢ But we also may allow preference constraints: Prof. X might prefer teaching in the morning, whereas Prof. Y prefers teaching in the afternoon. ‚Ä¢ CSPs with preferences can be solved with optimization search methods, and they are called as constraint optimization problems. Example: Cryptarithmetic ‚Ä¢ In a Cryptarithmetic puzzle, each letter stands for a distinct digit; the aim is to find a substitution of digits for letters such that the resulting sum is arithmetically correct. ‚Ä¢ The global constraint Alldiff (F, T,U,W,R,O) represents distinction of each letter. ‚Ä¢ The constraints on the four columns of the puzzle can be written as n-ary constraints. where C10, C100, and C1000 are auxiliary variables representing the digit carried over into the tens, hundreds, or thousands column. Example: Cryptarithmetic ‚Ä¢ Constraints can be represented in a constraint hypergraph, ‚Ä¢ A hypergraph consists of ordinary nodes and hypernodes which represent n-ary constraints. Alldiff (F, T,U,W,R,O) Real-world CSPs ‚Ä¢ Assignment problems ‚Ä¢ e.g., who teaches what class ‚Ä¢ Timetabling problems ‚Ä¢ e.g., which class is offered when and where? ‚Ä¢ Hardware configuration ‚Ä¢ Transportation scheduling ‚Ä¢ Factory scheduling ‚Ä¢ Many real-world problems involve real-valued variables Search Formulation for CSPs States are defined by the values assigned so far (partial assignments). Initial State: the empty assignment, {} Successor Function: assign a value to an unassigned variable that does not conflict with current assignment. ‚Ä¢ If there is no legal assignments, cause failure Goal Test: the current assignment is complete and satisfies all constraints. ‚Ä¢ ie. a goal state is a complete and consistent assignment Na√Øve Formulation: ‚Ä¢ This search formulation is the same for all CSPs! ‚Ä¢ Every solution appears at depth n with n variables ÔÉ® use depth-first search ‚Ä¢ There are dn complete assignments for a CSP with n variables of domain size d,. ‚Ä¢ Branching factor: nd at the first level and (n-d)h at depth h, hence n!dn leaves! ‚Ä¢ It is not so practical. Commutativity ‚Ä¢ A problem is commutative if the order of application of any given set of actions has no effect on the outcome. ‚Ä¢ CSPs are commutative because when assigning values to variables, we reach the same partial assignment regardless of order. ‚Ä¢ We need only consider a single variable at each node in the search tree. ‚Ä¢ For example, at the root node of a search tree for coloring the map of Australia, we might make a choice between SA=red, SA=green, and SA=blue, but we would never choose between SA=red and WA=blue. ‚Ä¢ With this restriction (commutative property of CSPs), the number of leaves is dn. ‚Ä¢ All CSP search algorithms consider a single variable assignment at a time, thus there are dn leaves. ‚Ä¢ The backtracking search for CSPs is a depth-first search that chooses values for one variable at a time and backtracks when a variable has no legal values left to assign. ‚Ä¢ Backtracking search is the basic uninformed algorithm for CSPs. Backtracking SearchBacktracking Search: ExampleImproving Backtracking Efficiency ‚Ä¢ General-purpose methods can give huge gains in speed: 1. Which variable should be assigned next? 2. In what order should its values be tried? 3. Can we detect inevitable failure early? 4. Can we take advantage of problem structure? Minimum Remaining Values a heuristic for variable selection ‚Ä¢ The simplest strategy for variable selection is to choose the next unassigned variable in order, {X1,X2, . . .}. ‚Ä¢ This static variable ordering may NOT produce an efficient search. Minimum Remaining Values (MRV) Heuristic: Choose the variable with the fewest legal values. all of them selectable here Select NT or SA here Degree Heuristic a heuristic for variable selection ‚Ä¢ A tie-breaker among MRV variables Degree Heuristic: ‚Ä¢ choose the variable with the most constraints on remaining variables ‚Ä¢ The minimum-remaining values heuristic is usually a more powerful guide, but the degree heuristic can be useful as a tie-breaker. Least-Constraining-Value a heuristic for value selection ‚Ä¢ Once a variable has been selected, the algorithm must decide on the order in which to examine its values. ‚Ä¢ Given a variable, least constraining value heuristic prefers the value that rules out the fewest choices for the neighboring variables in the constraint graph. LCV heuristic prefers this one Variable and Value Ordering ‚Ä¢ Minimum Remaining Values (MRV) heuristic picks a variable that is most likely to cause a failure soon, thereby pruning the search tree. ‚Ä¢ MRV also has been called the most constrained variable or fail-first heuristic. ‚Ä¢ If some variable X has no legal values left, the MRV heuristic will select X and failure will be detected immediately‚Äîavoiding pointless searches through other variables. ‚Ä¢ Least-Constraining-Value heuristic picks a value that is most likely to cause a failure last. ‚Ä¢ We only need one solution; therefore it makes sense to look for the most likely values first. ‚Ä¢ If we wanted to enumerate all solutions rather than just find one, then value ordering would be irrelevant. Interleaving Search and Inference ‚Ä¢ Some inference algorithms can infer reductions in the domain of variables before we begin the search ‚Ä¢ Inference algorithms can infer new domain reductions on the neighboring variables every time we make a choice of a value for a variable. Inference: Forward Checking ‚Ä¢ Whenever a variable X is assigned, the forward-checking process establishes arc consistency for it: ‚Ä¢ For each unassigned variable Y that is connected to X by a constraint, delete from Y ‚Äôs domain any value that is inconsistent with the value chosen for X. ‚Ä¢ Because forward checking only does arc consistency inferences, there is no reason to do forward checking if we have already done arc consistency as a preprocessing step. ‚Ä¢ For many problems the search will be more effective if we combine the MRV heuristic with forward checking. ‚Ä¢ Forward Checking Idea: Keep track of remaining legal values for unassigned variables and terminate search when any variable has no legal values. Forward Checking Initial domains Forward Checking Initial domains After WA=red Forward Checking Initial domains After WA=red After Q=green Forward Checking Initial domains After WA=red After Q=green After V=blue Constraint Propagation ‚Ä¢ Forward checking propagates information from assigned to unassigned variables, but doesn't provide early detection for all failures: ‚Ä¢ NT and SA cannot both be blue! ‚Ä¢ Constraint propagation repeatedly enforces constraints locally Arc Consistency ‚Ä¢ Simplest form of constraint propagation makes each arc consistent. ‚Ä¢ A variable in a CSP is arc-consistent if every value in its domain satisfies the variable‚Äôs binary constraints. ‚Ä¢ Xi is arc-consistent with respect to another variable Xj if for every value in the current domain Di there is some value in the domain Dj that satisfies the binary constraint on the arc(Xi,Xj). ‚Ä¢ X ‚Üí Y is consistent iff for every value x of X there is some allowed y for Y ‚Ä¢ A network is arc-consistent if every variable is arc consistent with every other variable. Arc Consistency X ‚Üí Y is consistent iff for every value x of X there is some allowed y for Y Arc Consistency X ‚Üí Y is consistent iff for every value x of X there is some allowed y for Y Arc Consistency X ‚Üí Y is consistent iff for every value x of X there is some allowed y for Y If X loses a value, neighbors of X need to be rechecked Arc Consistency X ‚Üí Y is consistent iff for every value x of X there is some allowed y for Y If X loses a value, neighbors of X need to be rechecked Arc consistency detects failure earlier than forward checking Can be run as a preprocessor or after each assignment Arc Consistency AlgorithmProblem Structure ‚Ä¢ The structure of the problem can be used to find solutions quickly. ‚Ä¢ Coloring Tasmania and coloring the mainland are independent subproblems ‚Ä¢ Independence can be ascertained simply by finding connected components of the constraint graph. ‚Ä¢ Each component corresponds to a subproblem CSPi. ‚Ä¢ If assignment Si is a solution of CSPi, then ùëñ Si is a solution of ùëñ CSPi . Problem Structure ‚Ä¢ Why independent subproblems are important? ‚Ä¢ Suppose each CSPi has c variables from the total of n variables, where c is a constant. ‚Ä¢ Then there are n/c subproblems, each of which takes at most dc work to solve, where d is the size of the domain. ‚Ä¢ Hence, the total work is O(dc n/c), which is linear in n. ‚Ä¢ Without the decomposition, the total work is O(dn), which is exponential in n. E.g., n=80, d=2, c=20 ‚Ä¢ 280 = 4 billion years at 10 million nodes/sec ‚Ä¢ 4 * 220 = 0.4 seconds at 10 million nodes/sec Tree-structured CSPs ‚Ä¢ A constraint graph is a tree when any two variables are connected by only one path (no loops). ‚Ä¢ Theorem: If the constraint graph has no loops, the CSP can be solved in O(n d2) time (linear in n) ‚Ä¢ Compare to general CSPs, where worst-case time is O(dn) Algorithm for tree-structured CSPsNearly tree-structured CSPs ‚Ä¢ We have an efficient algorithm for trees, we can consider whether more general constraint graphs can be reduced to trees somehow. ‚Ä¢ Delete South Australia, the graph would become a tree. ‚Ä¢ Instantiate SA to a value, and ‚Ä¢ From domains of other variables, delete any values that are inconsistent with the value chosen for SA. ‚Ä¢ Any solution for CSP after SA and its constraints are removed will be consistent with value chosen for SA. ‚Ä¢ The value chosen for SA could be the wrong one, so we would need to try each possible value. Nearly tree-structured CSPs General Algorithm: 1. Choose a subset S of the CSP‚Äôs variables such that the constraint graph becomes a tree after removal of S. S is called a cycle cutset. 2. For each possible assignment to the variables in S that satisfies all constraints on S, (a) remove from the domains of the remaining variables any values that are inconsistent with the assignment for S, and (b) If the remaining CSP has a solution, return it together with the assignment for S. Cutset size c ÔÉ® runtime O(dc (.n - c) d2), very fast for small c Local Search For CSPs ‚Ä¢ Local search algorithms can be effective in solving many CSPs. ‚Ä¢ complete-state formulation is used: the initial state assigns a value to every variable, and the search changes the value of one variable at a time. ‚Ä¢ In choosing a new value for a variable, the most obvious heuristic is to select the valuethat results in the minimum number of conflicts with other variables‚Äîthe min-conflicts heuristic. Min-conflicts ‚Ä¢ Min-conflicts is surprisingly effective for many CSPs. ‚Ä¢ On the n-queens problem, the run time of min-conflicts is roughly independent of problem size. ‚Ä¢ It solves even the million-queens problem in an average of 50 steps Min-conflicts on 8-queens problem ‚Ä¢ A two-step solution using min-conflicts for an 8-queens problem. At each stage, a queen is chosen for reassignment in its column. ‚Ä¢ The number of conflicts (number of attacking queens) is shown in each square. ‚Ä¢ The algorithm moves the queen to the min-conflicts square, breaking ties randomly. Summary ‚Ä¢ CSPs are a special kind of problem: ‚Ä¢ states defined by values of a fixed set of variables ‚Ä¢ goal test defined by constraints on variable values ‚Ä¢ Backtracking = depth-first search with one variable assigned per node ‚Ä¢ Variable ordering and value selection heuristics help significantly ‚Ä¢ Forward checking prevents assignments that guarantee later failure ‚Ä¢ Constraint propagation (e.g., arc consistency) does additional work to constrain values and detect inconsistencies ‚Ä¢ The CSP representation allows analysis of problem structure ‚Ä¢ Tree-structured CSPs can be solved in linear time ‚Ä¢ Iterative min-conflicts is usually effective in practice","libVersion":"0.2.3","langs":""}