{"path":"Subjects/COS3751 - Techniques of Artificial Intelligence/Assignments/Assignment 3 solution.pdf","text":"BAR CODE Deﬁne Tomorrow. university of south africa Tutorial Letter 203/0/2023 Techniques of Artiﬁcial Intelligence COS3751 Year module Computer Science School of Computing CONTENTS Assignment 3 COS3751/203/0/2023 ASSIGNMENT 3 Solution Total Marks: 83 Study material: Chapters 9, and 18. You may skip sections 9.3, and 9.4. You only need to study 18.1, 18.2, and 18.3 Question 1: 16 Marks Convert the following First Order Logic (FOL) sentence to Conjunctive Normal Form (CNF): ∀x(∀y(¬P (y) ∨ Q(x, y)) ⇒ (¬∀yQ(y, x))) Write the context of x in square brackets to make it clear: ∀x[∀y(¬P (y) ∨ Q(x, y)) ⇒ (¬∀yQ(y, x))]✓ Since p ⇒ q is equivalent to ¬p ∨ q, eliminate the implication: ∀x[¬∀y(¬P (y) ∨ Q(x, y)) ∨ (¬∀yQ(y, x))]✓✓ Move the ¬ inwards (in two places here): ∀x[∃y¬(¬P (y) ∨ Q(x, y)) ∨ (∃y¬Q(y, x))]✓✓ The variable y is used in the scope of two quantiﬁers, so we change its name in the second to avoid confusion. Variable x is in the outer context, so remains: ∀x[∃y¬(¬P (y) ∧ Q(x, y)) ∨ (∃z¬Q(z, x))]✓✓ Move the quantiﬁers to outer contexts: ∀x[∃y¬(¬P (y) ∧ Q(x, y)) ∨ ∃z(¬Q(z, x))]✓ Again: ∀x∃y∃z[¬(¬P (y) ∨ Q(x, y)) ∨ ¬Q(z, x)]✓ To remove some of the ¬’s apply De Morgan’s rule to the ﬁrst disjunction: ∀x∃y∃z[(P (y) ∧ ¬Q(x, y)) ∨ ¬Q(z, x)]✓✓ Rewrite the rightmost disjunction: ∀x∃y∃z[(A(y) ∧ ¬B(z, x)) ∧ (¬B(x, y) ∧ ¬B(z, x))]✓✓ Since all the quantiﬁers are now in the outer scope, we need to remove the existential quantiﬁers using Skolem functions. There are two existential quantiﬁers ∃y and ∃z. Each of these need a Skolem function, f (x) replacing y and g(x) replacing z. Both are preceded by a the single universal quantiﬁer ∀x with x in the outer scope. Therefore: ∀x[(P (f (x)) ∨ ¬B(g(x), x)) ∧ (¬B(x, f (x)) ∧ ¬B(g(x), x))]✓✓ Only the universal quantiﬁer remains, which can be removed: (P (f (x)) ∨ ¬B(g(x), x)) ∧ (¬B(x, f (x)) ∧ ¬B(g(x), x))✓ The sentence is now in CNF and it has only one conjunct (one clause) consisting of a disjunction of three literals. 2 COS3751/203/0/2023 Question 2: 36 Marks Consider the following English statements: 1. Anyone who passes their AI exam and who wins the lottery is happy. 2. Anyone who studies hard or is lucky, passes their exams. 3. Jack did not study. 4. Jack is lucky. 5. Anyone who is lucky wins the lottery. (2.1) (8)Provide a vocabulary for the statements. • P ass(p, s). Predicate. Person p passes subject s. ✓ • W in(p, g). Predicate. Person p wins game g. ✓ • Happy(p). Property. Person p is happy. ✓ • Study(p). Predicate. Person p studies. ✓ • Lucky(p). Property. Person p is lucky. ✓ • AI. Constant for a subject. ✓ • Lottery. Constant for a game that can be won. ✓ • Jack. Constant for a person. ✓ (2.2) (7)Translate the above English sentences to FOL statements using the vocabulary you de- ﬁned above. The sentences are translated as follows to FOL: 1. ∀p((P ass(p, History) ∧ W in(p, Lottery)) ⇒ Happy(p)) ✓✓ 2. ∀q∀r((Study(q) ∨ Lucky(q)) ⇒ P ass(q, r)) ✓✓ 3. ¬Study(Jack) ✓ 4. Lucky(Jack) ✓ 5. ∀s(Lucky(s) ⇒ W in(s, Lottery)) ✓ It is important to use unique variable names (standardize the variables) to avoid confusion when dropping the universal quantiﬁers. 3 (2.3) (8)Convert the FOL statements obtained in 2.2 into CNF. The statements are converted as follows to CNF: 1. ∀p((P ass(p, History) ∧ W in(p, Lottery)) ⇒ Happy(p)) ≡ ∀p(¬(P ass(p, History) ∧ W in(p, Lottery) ∨ Happy(p)) ≡ ∀p(¬P ass(p, History) ∨ ¬W in(p, Lottery) ∨ Happy(p)) ✓✓ 2. ∀q∀r((Study(q) ∨ Lucky(q)) ⇒ P ass(q, r)) ≡ ∀q∀r(¬(Study(q) ∨ Lucky(q)) ∨ P ass(q, r)) ≡ ∀q∀r((¬Study(q) ∧ ¬Lucky(q)) ∨ P ass(q, r)) ≡ (¬Study(q) ∧ ¬Lucky(q)) ∨ P ass(q, r) ≡ (¬Study(q) ∨ P ass(q, r)) ∧ (¬Lucky(q) ∨ P ass(q, r)) ✓✓ 3. No action required. ✓ 4. No action required. ✓ 5. ∀s(Lucky(s) ⇒ W in(s, Lottery)) ≡ ¬Lucky(s) ∨ W in(s, Lottery) ✓✓ We thus end up with the following clauses: 1. ¬P ass(p, History) ∨ ¬W in(p, Lottery) ∨ Happy(p) 2. ¬Study(q) ∨ P ass(q, r) 3. ¬Lucky(q) ∨ P ass(q, r) 4. ¬Study(Jack) 5. Lucky(Jack) 6. ¬Lucky(s) ∨ W in(s, Lottery) Note that universal quantiﬁers have been dropped because all variables were universally quantiﬁed. Skolem functions are only introduced to remove existential quantiﬁers. (See section 9.5 of R&N.) 4 COS3751/203/0/2023 (2.4) (13)Use resolution refutation to prove that Jack is happy. In order to use resolution refutation, we negate the goal, convert the negated goal to clause form if necessary, and add the resulting clause(s) to the set of premises (clauses 1 to 6 in part (2.3) above). Here the goal is: Happy(Jack). Therefore the negation of the goal is: ¬Happy(Jack). We then resolve the premises together with the negated goal until the empty clause (Nil) is generated. Review the ground resolution theorem to make sure you understand why this ap- proach works. Also review section 7.5: Remember that α |= β only if (α ∧ ¬β) is unsatisﬁable. 1. ¬P ass(p, History) ∨ ¬W in(p, Lottery) ∨ Happy(p) premise ✓ 2. ¬Study(q) ∨ P ass(q, r) premise ✓ 3. ¬Lucky(q) ∨ P ass(q, r) premise ✓ 4. ¬Study(Jack) premise ✓ 5. Lucky(Jack) premise ✓ 6. ¬Lucky(s) ∨ win(s, Lottery) premise ✓ 7. ¬Happy(Jack) negation of goal ✓ 8. ¬W in(p, Lottery) ∨ happy(p) ∨ ¬Lucky(p) 1&3, {p/q}, {history/r} ✓ 9. ¬W in(Jack, Lottery) ∨ Happy(Jack) 5&8, {Jack/p} ✓ 10. ¬W in(Jack, Lottery) 9&7 ✓ 11. W in(Jack, Lottery) 5&6, {Jack/w} ✓ 12. ∅ 10&11 ✓ We have shown that the negation of the goal together with the premises produce a contradiction (empty clause). Therefore the goal, namely Happy(Jack), is entailed by the premises. ✓ It is important to show which clauses form part of the resolution to produce the resolvent. You must also always show the substitutions. 5 A B C f(A, B, C) 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 Table 1: Boolean function table Question 3: 10 Marks (3.1) (8)Convert the Boolean function in Table 1 to a decision tree: No information gain values were given, so the sequence in which the variables are to be evaluated are not determined. Variable order A, B, C: A B C 0 0 1 1 0 C 0 0 0 1 1 0 B C 0 0 1 1 0 C 1 0 0 1 1 1 ✓✓✓✓✓By consolidating equivalent leaf nodes, the decision tree can be simpliﬁed to: 6 COS3751/203/0/2023 A B C 0 0 1 1 0 0 1 0 B C 0 0 1 1 0 C 1 0 0 1 1 1 ✓✓✓ Variable order A, C, B: A C 0 0 B 1 0 0 1 1 0 C B 0 0 1 1 0 B 1 0 0 1 1 1 Variable order B, A, C: B C B 0 0 1 1 0 B 0 0 1 1 1 0 C 0 00 B 1 0 0 1 1 1 7 Variable order B, C, A: B C 0 0 1 1 0 C A 0 0 1 1 0 0 1 1 Variable order C, B, A: C B 0 0 A 0 0 1 1 1 0 B 1 0 0 1 1 Variable order C, A, B: C A 0 0 B 0 0 1 1 1 0 A B 1 0 0 1 0 B 1 0 0 1 1 1 8 COS3751/203/0/2023 (3.2) (2)When we construct a decision tree without the beneﬁt of gain values, the order in which we evaluate the variables is important. Why? It may be possible to consolidate leaf nodes with similar values to produce a smaller, more compact tree. ✓✓ Question 4: 21 Marks Consider the following table which provides examples of weather conditions used to determine whether a old age pensioner is likely to play golf on a given day. Nr Outlook Temperature Windy Crowded Play? 1 Sunny Hot Yes No Yes 2 Sunny Hot No Yes No 3 Overcast Hot Yes Yes Yes 4 Overcast Hot No No Yes 5 Rain Mild Yes No Yes 6 Rain Cool No Yes No 7 Overcast Cool No Yes No 8 Sunny Mild Yes No Yes 9 Sunny Cool Yes No Yes 10 Rain Mild No No Yes 11 Sunny Mild No Yes Yes 12 Overcast Mild Yes Yes Yes 13 Overcast Hot No No Yes 14 Sunny Mild Yes Yes No 15 Rain Cool No Yes No 16 Rain Cool Yes No Yes (4.1) (14)Determine the root node of the decision tree for this table. Show all your calculations during the determination of the root node (all the entropy, remainder and information gain calculations). Use the table on page 11 for your entropy values and calculations. Step 1 is to calculate the entropy for the table: Eplay = E[11, 5] = 0.88✓ (1) Now, we calculate the remainder for each attribute: Routlook = 6 16 × Eoutlook = sunny + 5 16 × Eoutlook=overcast + 5 16 × Eoutlook=rain = 6 16 × E[4, 2] + 5 16 × E[4, 1] + 5 16 × E[3, 2] = 6 16 × 0.93 + 5 16 × 0.72 + 5 16 × 0.97 = 6 16 × 0.93 + 5 16 × 0.72 + 5 16 × 0.97 = 0.88✓✓ 9 Rtemp = 5 16 × Etemp = hot + 6 16 × Etemp=mild + 5 16 × Etemp=cool = 5 16 × E[4, 1] + 6 16 × E[5, 1] + 5 16 × E[2, 3] = 5 16 × 0.72 + 6 16 × 0.61 + 5 16 × 0.97 = 0.76✓✓ Rwindy = 8 16 × Ewindy=yes + 8 16 × Ewindy=no = 8 16 × E[7, 1] + 8 16 × E[4, 4] = 0.5 × 0.41 + 0.5 × 1.0 = 0.71✓✓ Rcrowd = 8 16 × Ecrowd=yes + 8 16 × Ecrowd=no = 8 16 × E[2, 4] + 8 16 × E[8, 0] = 0.5 × 0.93 + 0.5 × 0 = 0.47✓✓ Now we calculate the gain for each✓✓✓✓: IGoutlook = Eplay − Routlook = 0.88 − 0.88 = 0.00 IGtemp = Eplay − Rtemp = 0.88 − 0.76 = 0.12 IGwindy = Eplay − Rwindy = 0.88 − 0.71 = 0.17 IGcrowd = Eplay − Rcrowd = 0.88 − 0.47 = 0.41 Thus, our ﬁrst node is Crowded.✓ (4.2) (5)Explain brieﬂy what would be done next to determine the complete decision tree. Consider the “Crowded” “Yes” subtree ✓ calculate entropy, remainders and gains to detemine root of next subtree ✓✓ Work downwards in the same way until the complete tree has been built. ✓ At some point will have no work if all situations lead to a no or a yes✓ (4.3) (2)Explain the signiﬁcance of any of the listed attributes becoming the root node of the decision tree. It is an attribute that does a good job of classifying the cases by to some extent separating out the yes and no decisions. ✓✓ 10 COS3751/203/0/2023 Entropy Table (Boolean valued variables) p : Ratio of positive examples. E : Corresponding entropy (−(plog2p + (1 − p)log2(1 − p))). p E 0.00 0.00 0.10 0.47 0.15 0.61 0.20 0.72 0.25 0.81 0.30 0.88 0.35 0.93 0.40 0.97 0.45 0.99 0.50 1.00 0.55 0.99 0.60 0.97 0.65 0.93 0.70 0.88 0.75 0.81 0.80 0.72 0.85 0.61 0.90 0.47 0.95 0.29 1.00 0.00 Example: For a set of 4 positive examples, and 1 negative example (written E[4, 1]), the ratio p = 4 5, or 0.80. The corresponding entropy value is given by the table as 0.72. Always round the ratio to the nearest value on the table, for example: For E[2, 1], the ratio is p = 2 3 ≃ 0.67 ≃ 0.65, which makes the E[2, 1] = 0.93. Copyright ©UNISA 2023 11","libVersion":"0.2.3","langs":""}