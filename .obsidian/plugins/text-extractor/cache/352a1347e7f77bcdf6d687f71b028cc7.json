{"path":"UNISA/98906 - BSc Science in Computing/COS3751 - Techniques of Artificial Intelligence/Telegram Notes/Materials/Examination_Preparation.pdf","text":"COS3751 Examination Preparation ©ornelis Dubbelman-48269328 Page 1 of 12 This is NOT an official memorandum! Question 1 State Spaces [7] (a) Define the concept of a Fully observable environment. (1) An environment is said to be Fully observable if an agent’s sensors give it access to the complete state of the environment at each point in time. (b) Consider a game of chess. Is this a deterministic or stochastic environment? Clearly explain why. (2) Deterministic: because, in chess, the next state of the game (environment) is completely determined by the current state of the game and the move (action) executed by a player (agent). (c) Differentiate between discrete and continuous environments. Provide an example of each (4) An environment is said to be discrete if its state-space is finite and, for each state, there are only finitely many percepts to be perceived and only finitely many actions to choose from. The game of chess is an example of such an environment. On the other hand, a continuous environment has infinitely many distinct states, infinitely many percepts, and infinitely many actions to choose from at any state. Taxi driving is an example of a continuous environment. Question 2 Searching [16] Consider the provided diagram and answer the questions that follow (the ℎ̂ value of each node is provided in brackets after the node name, and the 𝑔̂ value is provided next to the edges between nodes) e(4) k(2) a(10) m(1) b(12) n(0) d(5) l(1) f(7) g(4) c(4) h(5) i(4) 5 2 7 10 3 8 8 5 5 4 3 3 1 2 4 3 7 6 COS3751 Examination Preparation ©ornelis Dubbelman-48269328 Page 2 of 12 (a) Explain what an admissible heuristic is. (2) An admissible heuristic is one that never overestimates the true cost of reaching the nearest goal. (b) List the nodes and their 𝑓̂ values that are added to the frontier when node d is expanded. Assume that node a is already on the explored (closed) list. (3) l(10), i(14) Not enough information is provided to answer this question… Which search strategy should we use, Greedy-Best-First or A*? If A*, which node is the initial (root) node? You cannot calculate PATH-cost if you don’t know where the root is! Let’s ASSUME that A* should be used, and that node a is the start node. Expanding a gives e(4) a(10) b(12) d(5) c(4) 2 7 8 3 f(e) = 6 f(d) = 8 f(c) = 12 f(b) = 19 Next; e has the lowest f-cost, so it will be expanded next: e(4) a(10) b(12) d(5) c(4) 2 7 8 3 f(d) = 8 f(c) = 12 f(b) = 19 k(2)5 f(k) = 9 Finally, expanding node d: e(4) a(10) b(12) d(5) c(4) 2 7 8 3 f(i) = 14f(c) = 12 f(b) = 19 k(2)5 f(k) = 9 l(1) i(4) 7 6 f(l) = 10 Notice that k is already on the frontier. This is how I got to my answer… COS3751 Examination Preparation ©ornelis Dubbelman-48269328 Page 3 of 12 (c) Suppose we have the following frontier list (i(14), c(12), g(20)). Which one of these nodes will be selected for expansion next? State why. (2) Node c: because it has the lowest f-cost among all current frontier nodes. (I assume that the values in brackets indicate f-costs) (d) Explain what is meant by consistence with respect to heuristic searches (1) If the heuristic function of a graph-search strategy is consistent, then the algorithm is guaranteed to be optimal (and complete when the branching factor is finite). For every node in the search tree, the following inequality must hold 𝒉(𝒏) ≤ 𝒄(𝒏, 𝒂, 𝒏′) + 𝒉(𝒏’). (e) Assume that a graph-search is used. Is the heuristic used in this diagram consistent? Explain why/why not. (2) No, this heuristic is not consistent! 𝟏𝟎 = 𝒉̂(𝐚) ≰ 𝒈̂(𝐚, 𝐞) + 𝒉̂(𝐞) = 𝟔 or 𝟏𝟎 = 𝒉̂(𝐚) ≰ 𝒈̂(𝐚, 𝐝) + 𝒉̂(𝐝) = 𝟖 (f) Consider the following diagram J K L M H I E F G A B C D Assume that loops are detected and that you consider moves in the order Up, Right, Down, Left. Also assume that the start node is node E, and the goal node is node G. List the order in which nodes are visited for a depth-first search. (6) E, A, B, C, D, G NB: Depth-first search uses a LIFO queue. A LIFO queue means that the most recently generated node is chosen for expansion. I used depth-first-GRAPH-search to obtain my solution (see diagram below) The labels on the left of each node has the form GENERATE| EXPAND, where GENERATE depicts the order in which nodes are generated and EXPAND depicts the order in which nodes are expanded (visited). COS3751 Examination Preparation ©ornelis Dubbelman-48269328 Page 4 of 12 E H F A C B G D 1|1 2|_ 3|_ 4|2 6|4 5|3 Up Right Down Left 7|5 8|6 Question 3 Adversarial Search [14] Consider the following game tree and then answer the questions that follow (the static utility values for the leaf nodes are provided below each leaf node) A D E F G H I B J C 7 K 5 L 4 M 9 N 10 P 203 O Q 25 R 22 (a) Which choice should Max make (move B or move C)? Explain why. (2) Move B: The minimax (utility) value for MAX for move B is higher than that of move C. COS3751 Examination Preparation ©ornelis Dubbelman-48269328 Page 5 of 12 A D E F G H I B J C 7 K 5 L 4 M 9 N 10 P 203 O Q 25 R 22 7 5 9 10 3 25 5 3 5 (b) Write down the 𝛼 and 𝛽 values for nodes B, D, E, and F. (4) Using the algorithm in our textbook: B = (−∞, 5), D = (7, ∞), E = (5, 7), F = (−∞, 5) OR Using the algorithm in the video: B = (−∞, 5), D = (7, ∞), E = (5, 7), F = (9, 5) I guess the algorithm used in the videos available from myUnisa (https://my.unisa.ac.za/access/content/group/COS3751-13-S2/alphabeta/), is as follows: function ALPHA-BETA-SEARCH(state) returns an action v ← MAX-VALUE(state, −∞, +∞) return the action in ACTIONS(state) with value v. function MAX-VALUE (state, α, β) returns a utility value if TERMINAL-TEST(state) then return UTILITY(state) for each a in ACTIONS(state) do α ← MAX(α, MIN-VALUE(RESULT(s, a), α, β)) if α ≥ β then return α return α. function MIN-VALUE(state, α, β) returns a utility value if TERMINAL-TEST(state) then return UTILITY(state) for each a in ACTIONS(state) do β ← MIN(β, MAX-VALUE(RESULT(s, a) , α, β)) if β ≤ α then return β return β Using this algorithm, I got the following alpha/beta values (green values indicate the value returned by a node) COS3751 Examination Preparation ©ornelis Dubbelman-48269328 Page 6 of 12 A D E F G H I B J C 7 K 5 L 4 M 9 N 10 P 203 O Q 25 R 22 7 ∞ 5 7 9 5 10 ∞ 5 10 5 5 -∞ 5 5 ∞ Using the algorithm in the prescribed textbook, I obtained the following values. The 3-arrays next to nodes take the form 𝒗 𝜶 𝜷 A D E F G H I B J C 7 K 5 L 4 M 9 N 10 P 203 O Q 25 R 22 7 7 ∞ 5 5 7 9 -∞ 5 10 10 ∞ 3 5 10 3 5 10 5 -∞ 5 5 5 ∞ (c) If alpha/beta pruning is applied, a cut occurs. Indicate where this cut occurs, state what type of cut it is, and what the relevant 𝛼/𝛽 values are when the cut occurs (4) The right-most child of node C, namely I (and I’s children etc. of course), is pruned from the search tree. This is an 𝜶-cut. The relevant 𝜶/𝜷 values are 𝜶 = 𝟓 and 𝜷 = 𝟏𝟎 if you use the textbook’s algorithm OR 𝜶 = 𝟓 and 𝜷 = 𝟓 if you use the video’s algorithm. (d) Clearly explain why ordering in alpha/beta searching is important, and how it benefits alpha/beta searching. (2) COS3751 Examination Preparation ©ornelis Dubbelman-48269328 Page 7 of 12 The right order of nodes can result in pruning larger section of the search tree earlier. This benefits alpha/beta searching because it reduces the runtime of the algorithm. (e) Is it possible to re-order the game tree to effect a cut earlier? Is so, explain which branches you would re-order. If it is not possible, explain why it would not make a difference to re-order the tree. (2) Yes, I will swap the order of branch G and H (This will result in G also being pruned) Question 4 Constraint Satisfaction Problems [14] Consider the problem of assigning registers on a central processing unit (CPU) to the variables in a program. Since a program may have many variables and there are a limited number of registers on the CPU, assigning registers to variables is an important problem. Since only certain variables are in use at different times during the execution of the program (variables that are being used at a particular time are called alive), the real task is merely to figure out which alive variables to assign to the limited number of registers. The problem is actually trivially solved by visually arranging the variables in such a way that those variables that are alive together lie adjacent to each other and colouring each program variable (a register is thus represented by a colour) –adjacent variables cannot have the same colour. For a certain program the following holds: 1- There are six variables in use in the program 2- Program variables A, B, and C are alive together. Program variables C, D, E, and F are alive together, and program variables A, E, and F are alive together. 3- There are four registers available for assignment to program variables. Do not confuse the program variables with the CSP variables for this question. (a) Define the variables for this CSP. (3) The variables for this CSP are the program variables. Thus 𝑿 = {𝑨, 𝑩, 𝑪, 𝑫, 𝑬, 𝑭} (b) Define the domain for each variable in the CSP. (2) The domain of each variable is the set of four registers. Thus 𝑫𝑿 = {𝑹𝟏, 𝑹𝟐, 𝑹𝟑, 𝑹𝟒} where each 𝑹𝒊 (𝟏 ≤ 𝒊 ≤ 𝟒) is an abbreviation meaning “Register 𝒊”. (c) Define the constraints for the variables in the CSP. (5) 𝑪 = {𝑨 = 𝑩, 𝑩 = 𝑪, 𝑨 = 𝑪, 𝑪 = 𝑫, 𝑫 = 𝑬, 𝑬 = 𝑭, 𝑪 = 𝑬, 𝑪 = 𝑭, 𝑫 = 𝑭, 𝑨 = 𝑬, 𝑨 = 𝑭} NB: 𝑽𝒊 = 𝑽𝒋 (where 𝑽𝒊, 𝑽𝒋 𝝐 𝑿) is a shorthand notation for 〈(𝑽𝒊, 𝑽𝒋), 𝑽𝒊 = 𝑽𝒋〉, which means variables 𝑉𝑖 and 𝑉𝑗 are alive together. COS3751 Examination Preparation ©ornelis Dubbelman-48269328 Page 8 of 12 (d) Provide the solution to this problem if it exists. If no solution exists, explain what parameters from the problem would have to change in order to get to a solution.(4) One possible solution is: Variables A and D can use the same register; variables B and E can use the same variable; variable C requires its own register; and variable F require its own variable. For example, {𝑨 = 𝑹𝟏, 𝑩 = 𝑹𝟐, 𝑪 = 𝑹𝟑, 𝑫 = 𝑹𝟏, 𝑬 = 𝑹𝟐, 𝑭 = 𝑹𝟒} A B C D E F Register 1 (R₁) Register 2 (R₂ ) Register 3 (R₃ ) Register 4 (R₄ ) Question 5 Predicate Logic [15] (a) Clearly explain what a Horn clause is, and state why they are useful (3) A Horn clause is a disjunction of literals of which at most one is positive. Deciding entailment with Horn clauses can be done in time that is linear in the size of the knowledge base (backward- and forward-chaining). (b) Closely examine the following sentences in a knowledge base 𝑝 1. ¬𝐴 ∨ ¬𝐵 ∨ ¬𝐶 ∨ 𝐷 2. ¬𝐷 ∨ ¬𝐹 ∨ 𝐺 3. ¬𝐺 ∨ ¬𝐻 ∨ 𝐼 4. ¬𝐴 ∨ ¬𝐻 ∨ 𝐶 5. ¬𝐴 ∨ 𝐵 6. 𝐴 7. 𝐻 8. 𝐹 Show that 𝑝 ⊨ 𝐼 using forward chaining (12) First I rewrite these sentences in their equivalent implication form: 1. 𝑨 ∧ 𝑩 ∧ 𝑪 ⇒ 𝑫 2. 𝑫 ∧ 𝑭 ⇒ 𝑮 3. 𝑮 ∧ 𝑯 ⇒ 𝑰 4. 𝑨 ∧ 𝑯 ⇒ 𝑪 5. 𝑨 ⇒ 𝑩 6. 𝑨 7. 𝑯 8. 𝑭 Now I will attempt to derive 𝑰: 𝑨, 𝑯, and 𝑭 are facts, so I add them to my (currently empty) list of true symbols. The premise of 5 is only 𝑨; 𝑨 is known to be true, so I add 𝑩 to my list of true COS3751 Examination Preparation ©ornelis Dubbelman-48269328 Page 9 of 12 symbols. The premise of 4 is 𝑨 ∧ 𝑯; both 𝑨 and 𝑯 are known to be true, so I add 𝑪 to my list of true symbols. The premise of 1 is 𝑨 ∧ 𝑩 ∧ 𝑪; all three of these are in my list of true symbols, so I can add 𝑫 to my list of true symbols. The premise of 2 is 𝑫 ∧ 𝑭; both of these are in my list of true symbols, so I add 𝑮. Finally, the premise of 3 is 𝑮 ∧ 𝑯; Both 𝑮 and 𝑯 are in my list of true symbols, so I am entitled to infer that 𝑰 is true. Hence, by means of forward chaining I have shown that 𝒑 ⊨ 𝑰 (as required) Question 6 First-Order Logic [8] Consider the following sentences in a knowledge base 𝑝 1. (∀𝑥)[(𝑝𝑎𝑠𝑠(𝑥, ℎ𝑖𝑠𝑡𝑜𝑟𝑦) ∧ 𝑤𝑖𝑛(𝑥, 𝑙𝑜𝑡𝑡𝑒𝑟𝑦)) ⇒ ℎ𝑎𝑝𝑝𝑦(𝑥)] 2. (∀𝑦)(∀𝑧)[(𝑠𝑡𝑢𝑑𝑦(𝑦) ∨ 𝑙𝑢𝑐𝑘𝑦(𝑦)) ⇒ 𝑝𝑎𝑠𝑠(𝑦, 𝑧)] 3. ¬𝑠𝑡𝑢𝑑𝑦(𝐽𝑜ℎ𝑛) 4. 𝑙𝑢𝑐𝑘𝑦(𝐽𝑜ℎ𝑛) 5. (∀𝑤)[𝑙𝑢𝑐𝑘𝑦(𝑤) ⇒ 𝑤𝑖𝑛(𝑤, 𝑙𝑜𝑡𝑡𝑒𝑟𝑦)] (a) Use backward chaining to prove that John is happy, show all your steps (8) According to tutorial letter 102, backward chaining for FOL is not part of the syllabus. Instead, I will use a proof of resolution with refutation to prove the query. However, I will choose my resolver pairs in such a way that a backward chaining proof is simulated. First, I rewrite the sentences in the above knowledge base into clause form: 1. ¬𝒑𝒂𝒔𝒔(𝒙, 𝒉𝒊𝒔𝒕𝒐𝒓𝒚) ∨ ¬𝒘𝒊𝒏(𝒙, 𝒍𝒐𝒕𝒕𝒆𝒓𝒚) ∨ 𝒉𝒂𝒑𝒑𝒚(𝒙) 2. ¬𝒔𝒕𝒖𝒅𝒚(𝒚) ∨ 𝒑𝒂𝒔𝒔(𝒚, 𝒛) 3. ¬𝒍𝒖𝒄𝒌𝒚(𝒚) ∨ 𝒑𝒂𝒔𝒔(𝒚, 𝒛) 4. ¬𝒔𝒕𝒖𝒅𝒚(𝑱𝒐𝒉𝒏) 5. 𝒍𝒖𝒄𝒌𝒚(𝑱𝒐𝒉𝒏) 6. ¬𝒍𝒖𝒄𝒌𝒚(𝒘) ∨ 𝒘𝒊𝒏(𝒘, 𝒍𝒐𝒕𝒕𝒆𝒓𝒚) To prove 𝒑 ⊨ 𝒉𝒂𝒑𝒑𝒚(𝑱𝒐𝒉𝒏) by means of resolution refutation, I must show that the empty clause follows from (𝒑 ∧ ¬𝒉𝒂𝒑𝒑𝒚(𝑱𝒐𝒉𝒏)): 1 ¬𝒑𝒂𝒔𝒔(𝒙, 𝒉𝒊𝒔𝒕𝒐𝒓𝒚) ∨ ¬𝒘𝒊𝒏(𝒙, 𝒍𝒐𝒕𝒕𝒆𝒓𝒚) ∨ 𝒉𝒂𝒑𝒑𝒚(𝒙) premise 2 ¬𝒔𝒕𝒖𝒅𝒚(𝒚) ∨ 𝒑𝒂𝒔𝒔(𝒚, 𝒛) premise 3 ¬𝒍𝒖𝒄𝒌𝒚(𝒚) ∨ 𝒑𝒂𝒔𝒔(𝒚, 𝒛) premise 4 ¬𝒔𝒕𝒖𝒅𝒚(𝑱𝒐𝒉𝒏) premise 5 𝒍𝒖𝒄𝒌𝒚(𝑱𝒐𝒉𝒏) premise 6 ¬𝒍𝒖𝒄𝒌𝒚(𝒘) ∨ 𝒘𝒊𝒏(𝒘, 𝒍𝒐𝒕𝒕𝒆𝒓𝒚) premise 7 ¬𝒉𝒂𝒑𝒑𝒚(𝑱𝒐𝒉𝒏) negated goal 8 ¬𝒑𝒂𝒔𝒔(𝑱𝒐𝒉𝒏, 𝒉𝒊𝒔𝒕𝒐𝒓𝒚) ∨ ¬𝒘𝒊𝒏(𝑱𝒐𝒉𝒏, 𝒍𝒐𝒕𝒕𝒆𝒓𝒚) 1&7 {x/John} 9 ¬𝒍𝒖𝒄𝒌𝒚(𝑱𝒐𝒉𝒏) ∨ ¬𝒘𝒊𝒏(𝑱𝒐𝒉𝒏, 𝒍𝒐𝒕𝒕𝒆𝒓𝒚) 3&8 {y/John, z/History 10 ¬𝒘𝒊𝒏(𝑱𝒐𝒉𝒏, 𝒍𝒐𝒕𝒕𝒆𝒓𝒚) 5&9 {} 11 ¬𝒍𝒖𝒄𝒌𝒚(𝑱𝒐𝒉𝒏) 6&10 {w/John} 12 NULL 5&11 {} Hence, by means of resolution refutation; John is indeed happy :-) COS3751 Examination Preparation ©ornelis Dubbelman-48269328 Page 10 of 12 ¬happy(John) ¬pass(John, history) ∨ ¬win(John, lottery) ¬lucky(John) ∨ ¬win(John, lottery) ¬pass(x, history) ∨ ¬win(x, lottery) ∨ happy(x) ¬lucky(y) ∨ pass(y, z) lucky(John) ¬win(John,lottery)¬lucky(w) ∨ win(w, lottery) ¬lucky(John)lucky(John) Question 7 Machine Learning [16] (a) Explain what is meant by Supervised Learning. (2) In supervised learning the agent observes some example input–output pairs (training set) and learns a function that maps from input to output. (b) Consider the following table and answer the questions that follow Instance Classification Size Nationality Family 1 + Large French Single 2 + Small German Single 3 - Large German Married 4 - Small Italian Single 5 - Large Italian Single i. Using the entropy table on the last page of this document, calculate the entropy for the data. (2) I assume that “Classification” is the output, whereas “Size”, “Nationality”, and “Family” are the attributes (input). Thus, 2 of the 5 examples are positive, so 𝒑 = 𝟐 𝟓 = 𝟎. 𝟒. Using the table, I find that 𝑯(𝑪𝒍𝒂𝒔𝒔𝒊𝒇𝒊𝒄𝒂𝒕𝒊𝒐𝒏) = 𝑬[𝟐, 𝟑] = 𝟎. 𝟗𝟔 ii. On which characteristic should the first node be split? Clearly show why you choose that characteristic. Refer to the table on the last page of this document for entropy values. (7) I will make use of the following abbreviations: Cl = Classification Sz = Size Na = Nationality Fa = Family. COS3751 Examination Preparation ©ornelis Dubbelman-48269328 Page 11 of 12 Calculate 𝑮𝒂𝒊𝒏(𝑺𝒛): 𝑮𝒂𝒊𝒏(𝑺𝒛) = 𝑯(𝑪𝒍) − 𝟑 𝟓 𝑬[𝟏, 𝟐] − 𝟐 𝟓 𝑬[𝟏, 𝟏] = 𝟎. 𝟗𝟔 − 𝟎. 𝟔 ∙ 𝟎. 𝟖𝟖 − 𝟎. 𝟒 ∙ 𝟏 = 𝟎. 𝟎𝟑𝟐 Calculate 𝑮𝒂𝒊𝒏(𝑵𝒂): 𝑮𝒂𝒊𝒏(𝑵𝒂) = 𝑯(𝑪𝒍) − 𝟏 𝟓 𝑬[𝟏, 𝟎] − 𝟐 𝟓 𝑬[𝟏, 𝟏] − 𝟐 𝟓 𝑬[𝟎, 𝟐] = 𝟎. 𝟗𝟔 − 𝟎. 𝟐 ∙ 𝟎 − 𝟎. 𝟒 ∙ 𝟏 − 𝟎. 𝟒 ∙ 𝟎 = 𝟎. 𝟓𝟔 Calculate 𝑮𝒂𝒊𝒏(𝑭𝒂): 𝑮𝒂𝒊𝒏(𝑭𝒂) = 𝑯(𝑪𝒍) − 𝟒 𝟓 𝑬[𝟐, 𝟐] − 𝟏 𝟓 𝑬[𝟎, 𝟏] = 𝟎. 𝟗𝟔 − 𝟎. 𝟖 ∙ 𝟏 − 𝟎. 𝟐 ∙ 𝟎 = 𝟎. 𝟏𝟔 According to my calculations, “Nationality” has the highest data gain, namely 0.56. Hence, I will choose “Nationality” to split on first (at the root)! Complete decision tree based on the given data: (You can split on either “Size” or “Family” at the {Nationality = “German”} test node) Nationality + Family - + - French German Italian Single Married (c) Many machine learning techniques suffer from the problem of over-fitting. Briefly discus two techniques that have been developed to reduce the problem of over- fitting during decision tree learning. (5) One technique, called decision tree pruning, works by eliminating nodes that are not clearly relevant: Start with a full decision tree; then look at a test node that has only leaf nodes as decedents: If the test appears to be irrelevant-detecting only noise in the data-then eliminate the test, replacing it with a leaf node. Repeat this process, considering each test with only leaf descendants, until each one has either been pruned or accepted as is. 𝝌𝟐 pruning is an example of such a strategy. Another technique involves limiting the number of input attributes and the size of the hypothesis space. Increasing the number of training examples is also a good idea! COS3751 Examination Preparation ©ornelis Dubbelman-48269328 Page 12 of 12 Entropy Table 𝑝: Ratio of positive examples 𝐸: Corresponding entropy 𝑝 𝐸 0.00 0.00 0.10 0.47 0.20 0.72 0.30 0.88 0.40 0.96 0.50 1.00 0.60 0.98 0.70 0.88 0.80 0.72 0.90 0.47 1.00 0.00 Example: For 𝐸[4, 1], the ratio 𝑝 = 4 5, or 0.80. The corresponding entropy value is given by the table as 0.72 Good luck","libVersion":"0.2.3","langs":""}