{"path":"UNISA/98906 - BSc Science in Computing/COS3761 - Formal Logic III/Unsorted/COS3761/exam pack/Materials/Additional+notes+on+Chapter+1.pdf","text":"ADDITIONAL NOTES FOR COS3761 – PART B ADDITIONAL NOTES ON CHAPTER 1 1 Propositional logic Chapter 1 discusses the syntax and semantics of propositional logic. The natural deduction proof system is presented and its soundness and completeness are shown: only tautologies can be derived in the proof system, and every tautology in a truth table can be proven. In this chapter you will learn to construct answers to questions such as: • How is a valid, propositional logic argument constituted? • How can we show that a propositional logic argument is sound? The chapter deals with propositional arguments. A propositional argument is made up of a finite set of propositions (called premises) that together justify the deduction of another proposition (called the conclusion). Propositions represent statements about the world to which we can attach a truth value (either true or false). A process of reasoning involving a proof calculus is used to ensure the validity of arguments. 1.1 Declarative sentences A declarative sentence is a statement of fact that, in the context of a specific view of the world, can be either true or false. Declarative sentences cannot be partly true or partly false. They can only be completely true or completely false. Examples of declarative sentences are: A cow is an animal My favourite colour is blue Jane got 80% in the Formal Logic exam In propositional logic, a declarative sentence can be expressed as a propositional logic formula. (From now on, we use the term proposition to refer to a propositional logic formula.) A proposition can be an atom, or a combination of atoms and connectives of propositional logic. 1.2 Natural deduction Natural deduction is a rule-based calculus for constructing proofs of propositions. In performing these proofs, we are not interested in the meanings of the propositions. Rather, we start from a set of propositions called premises, and apply the rules of the calculus to reach another proposition called the conclusion. So a proof consists of a list of propositions. Each proposition in the list is either a premise or a proposition which can be proved by applying rules to propositions already in the list. The rules in natural deduction all have a similar form. The rules allow us to add new propositions to the proof if the proof contains propositions of a particular structure. The rules are all syntactic in nature - they make no reference to the semantics of the propositions. We use the \"⊢\" symbol to indicate the provability of propositions using natural deduction. So \"φ1, …,φn ⊢ 𝜓\" states that 𝜓 is provable from φ1, …, φn. In this \"sequent\", φ1, …, φn are the premises and 𝜓 is the conclusion. Similarly, \"⊢ φ \" states that φ is provable from zero premises, or simply that φ is provable in natural deduction. Such a proposition is called a theorem. The notation \" 𝜓 ⊣⊢ φ \" is an abbreviation for \"φ ⊢ 𝜓 and 𝜓 ⊢ φ \", and states that φ and 𝜓 are provably equivalent. 1.2.1 Rules for natural deduction For each of the logical operators, there is an introduction and an elimination rule. We comment on a selection of them. The copy rule This is not stated as a formal rule in the prescribed book, but is discussed on page 20, at the end of the section discussion the rules for disjunction. At any time, we can introduce a copy of an earlier proposition (unless it only occurs inside a closed assumption box). Example: Here is a proof of the sequent p ⊢ q → p 1 p premise 2 q assumption 3 p copy 1 4 q → p →i 2–3 The rules for negation In natural deduction we use the ⊥ symbol to represent contradiction. This symbol is called \"bottom\". If a sequent contains a contradiction among its premises, we can validly derive any conclusion whatsoever from those premises. That is,\"⊥ ⊢ φ \" is always a valid sequent. As a rule of natural deduction, this is called \"bottom-elimination\" and, as may be seen on page 27 of the prescribed book, it looks as follows: ⊥ φ Since a contradiction is necessarily false, and our proofs consist of propositions that are necessarily true, it is not immediately clear how we can introduce a contradiction into a proof. However, we have a rule for doing it (see page 27 of the prescribed book): φ ¬ φ ¬e ⊥ The text refers to this as the \"not-elimination\" rule rather than as the \"bottom-introduction\" rule as in Formal Logic 2. The rule for introducing negation into our proofs also involves using a contradiction. The idea is simple: if we make an assumption and then, by applying the rules of natural deduction we are able to produce a contradiction, then the assumption is not provable - that is, its negation is provable. So the “not-introduction rule\" (¬i) on page 27 of the prescribed book shows an assumption box above the line, containing φ at the top and ⊥ at the bottom, and below the line it shows ¬φ. The or-elimination rule This rule is discussed in the section called The rules for disjunction. It may seem strange that in order to prove χ from φ ∨ 𝜓, one must prove both χ from φ and χ from 𝜓, but consider the following argument in natural language that illustrates this concept: \"Either I am happy, or I am sad\" \"If I am happy, I will want to watch a soap opera\" \"If I am sad, I will want to watch cartoons\" \"If I want to watch a soap opera, I will turn on the TV\" \"If I want to watch cartoons, I will turn on the TV\" From these premises, we conclude that I will turn on the TV. Here is a natural deduction example: (p → q) ∨ (p → r) ⊢ p → (q ∨ r) 1 (p → q) ∨ (p → r) premise 2 p assumption 3 4 5 p → q assumption q → e 3, 2 q ∨ r ∨ i1 4 6 7 8 p → r assumption r → e 6, 2 q ∨ r ∨ i2 7 9 q ∨ r ∨ e 1, 3-5, 6-8 10 p → ( q ∨ r) → i 2-9 When we are inside an assumption box, we can use or copy any previous proposition that is not inside a closed assumption box. We cannot use or copy any proposition that occurs only inside a previous closed assumption box, because then the assumption would have already been discharged. 1.2.2 Derived rules Using the rules that natural deduction provides as fundamental rules, we can derive other useful rules for use in our proofs. Modus Tollens (MT), proof by contradiction (PBC) and double negation introduction can all be derived from the other rules. They are discussed in sections 1.2.2 and 1.2.5 of the prescribed book. Another derived rule is the Law of the Excluded Middle (LEM) which follows here. The law of the excluded middle We normally abbreviate this law as LEM. The rule looks like this: φ ∨ ¬φ As you can see, this rule has nothing above the line. This means that we may introduce the proposition φ ∨ ¬φ into our proofs at any time, with no required premises or previous occurrences of any of the symbols that might happen to be in φ. 1.2.3 Natural deduction in summary The problem with natural deduction is that it is often unclear what rules to apply, to what propositions, and in what order. One often has to resort to a trial-and-error or hit-and-miss method. Our advice it to try to work out an argument in English first and use it as a guide to constructing the natural deduction proof. 1.2.4 Provable equivalence As stated above, if φ ⊢ 𝜓 and 𝜓 ⊢ φ are both valid sequents, then we say that φ and 𝜓 are provably equivalent, and we write φ ⊣⊢ 𝜓. This is useful because it allows us to make some shortcuts in our proofs. Whenever we have a formula that fits the pattern of φ, we can follow it on a new line with 𝜓. For example, one of the provable equivalences given in the prescribed book is p ∧ (q ∨ r) ⊣⊢ (p ∧ q) ∨ (p ∧ r) So if our proof contained an earlier line (a → b) ∧ (¬c ∨ (d → e)) we could add the line ((a → b) ∧ ¬c) ∨ ((a → b) ∧ (d → e)) The justification for adding that line would be stated as \"provable equivalence\" and would technically need a reference to a list of provable equivalences. Below we list a number of equivalences. (Note, however, that you may not use these equivalences when you are required to give a formal proof using natural deduction. You may not, for example, use de Morgan’s law in a formal proof. Only the proof rules of natural deduction may be used.) Equivalences involving ∧ In the equivalences listed here φ, 𝜓, χ denote arbitrary propositions. 1. φ ∧ 𝜓 ⊣⊢ 𝜓 ∧ φ (commutativity of ∧) 2. φ ∧ φ ⊣⊢ φ (idempotence of ∧) 3. φ ∧ ⊤ ⊣⊢ φ 4. ⊥ ∧ φ ⊣⊢ ⊥ and ¬φ ∧ φ ⊣⊢ ⊥ 5. (φ ∧ 𝜓) ∧ χ ⊣⊢ φ ∧ (𝜓 ∧ χ) (associativity of ∧) 6. φ ∨ 𝜓 ⊣⊢ 𝜓 ∨ φ (commutativity of ∨) 7. φ ∨ φ ⊣⊢ φ (idempotence of ∨) 8. ⊤ ∨ φ ⊣⊢ ⊤ and ¬φ ∨ φ ⊣⊢ ⊤ 9. φ ∨ ⊥ ⊣⊢ φ 10. (φ ∨ 𝜓) ∨ χ ⊣⊢ φ ∨ (𝜓 ∨ χ) (associativity of ∨) 11. ¬⊤ ⊣⊢ ⊥ 12. ¬⊥ ⊣⊢ ⊤ 13. ¬¬φ ⊣⊢ φ Equivalences involving → 14. φ → φ ⊣⊢ ⊤ 15. ⊤→ φ ⊣⊢ φ 16. φ → ⊤ ⊣⊢ ⊤ 17. ⊥ → φ ⊣⊢ ⊤ 18. φ → ⊥ ⊣⊢ ¬φ 19. φ → 𝜓 ⊣⊢ ¬φ ∨ 𝜓 ⊣⊢ ¬(φ ∧ ¬𝜓) 20. ¬(φ → 𝜓) ⊣⊢ φ ∧ ¬ 𝜓 Equivalences involving ↔ 21. φ ↔ 𝜓 ⊣⊢ (φ → 𝜓) ∧ (𝜓 → φ) ⊣⊢ (φ ∧ 𝜓) ∨ (¬φ ∧ ¬ 𝜓) ⊣⊢ ¬φ ↔ ¬𝜓. 22. ¬(φ ↔ 𝜓) ⊣⊢ φ ↔ ¬ 𝜓 ⊣⊢ ¬φ ↔ 𝜓 ⊣⊢ (φ ∧¬𝜓) ∨ (¬φ ∧ 𝜓). De Morgan Laws 23. ¬(φ ∧ 𝜓) ⊣⊢ ¬φ ∨ ¬𝜓 24. ¬(φ ∨ 𝜓) ⊣⊢ ¬φ ∧ ¬𝜓 Distributivity of ∧, ∨ 25. φ ∧ (𝜓 ∨ χ) ⊣⊢ (φ ∧ 𝜓) ∨ (φ ∧ χ) 26. φ ∨ (𝜓 ∧ χ) ⊣⊢ (φ ∨ 𝜓) ∧ (φ ∨ χ) 27. φ ∧ (φ ∨ 𝜓) ⊣⊢ φ and φ ∨ (φ ∧ 𝜓) ⊣⊢ φ. Examples We emphasize that these are not formal proofs. Example 1 Let us show that φ → 𝜓 ⊣⊢ ¬𝜓 → ¬φ. ¬𝜓 → ¬φ ⊣⊢ ¬(¬𝜓) ∨ ¬φ (using equivalence 19) ⊣⊢ ¬φ ∨ ¬¬𝜓 (equivalence 6) ⊣⊢ ¬φ ∨ 𝜓 (equivalence 13) ⊣⊢ φ → 𝜓 (equivalence 19 again). Example 2 Let us show that (p ∨ ¬q) ∧ (p ∨ q) ⊣⊢ p. (p ∨ ¬q) ∧ (p ∨ q) ⊣⊢ p ∨ (¬q ∧ q) (equivalence 26) ⊣⊢ p ∨ ⊥ (equivalence 4) ⊣⊢ p (equivalence 9) 1.2.5 Proof by contradiction This looks almost identical to the \"not-introduction\" rule, and is in fact easily derived from it. The rule looks like this ¬φ . . ⊥ φ The sense of this is that if we want to prove φ, we start by assuming ¬φ and show that this leads to a contradiction. Since we do not accept a contradiction as part of a valid proof, the assumption we made must have been false. This yields ¬¬φ, which we simplify to φ. We usually abbreviate Proof by Contradiction to PBC. 1.3 Propositional logic as a formal language Natural languages convey meaning using the grammar rules and vocabulary of the language. The context of language usage often helps to clarify the meanings of pronouncements where this is not immediately clear. Formal languages, on the contrary, have very little to do with information or meaning. The central idea behind a formal language is determining whether or not a given sequence of symbols is a legal or well-formed expression within the language. The study of formal languages is central to computer science for both practical and theoretical reasons: on the practical side, a piece of software must conform to the syntax of the programming language in which it is written, and we need tools that will check this, and on the theoretical side, many of the most fundamental concepts in the study of computational complexity (which tries to determine which problems can be solved quickly and which are inherently intractable) can be expressed in terms of formal languages. The purpose of describing propositional logic as a formal language is not to add any expressive power to it, but rather to put it into a format in which it is easy to determine if a string of symbols actually forms a proposition that we could evaluate. The syntax of a well- formed formula (wff) of propositional logic is defined in terms of a grammar on page 32-33 of the prescribed book. A particular wff can also be expressed using a parse tree. The rules for constructing a parse tree representing a given wff are as follows: • Leaf nodes represent atoms. • Non-leaf nodes represent connectives. • The main connective of a formula forms the root of the parse tree. • ¬ has only one subtree. • Binary connectives (∧, ∨, →) have two subtrees. • The height of a parse tree is 1 + the length of the longest path from root to leaf. • A parse tree consisting of only a single atom has a height of 1 + 0 = 1. The following example illustrates how to construct the parse tree representing a given well- formed formula. The parse tree of p ∨ (¬q → ¬p) is p q p ∨ → ¬ ¬ 1.4 Semantics of propositional logic 1.4.1 The meaning of logical connectives We can use a truth table to examine how the truth value of atomic propositions (atoms) affect the truth value of the compound propositions constructed from the atoms. A truth table consists of a column for each atom, a column for each sub-formula of the overall formula, and finally a column for the complete formula. The set of rows under the atoms represent all possible assignments of truth values to those atoms. Under each sub-formula and the complete formula are columns of truth values resulting from the assignment of truth values to the atoms in the relevant row. For example, the truth table of the formula (p ∨ q) ∧ r is p q r p ∨ q (p ∨ q) ∧ r T T T T F F F F T T F F T T F F T F T F T F T F T T T T T T F F T F T F T F F F Consider a theorem φ of natural deduction, i.e. ⊢ φ. If we construct a truth table for φ, we find that it is true in all rows. We say that φ is a tautology, and write ⊨ φ. Now consider a set of formulas φ1, φ2, ..., φn, 𝜓 and the following sequent: φ1, φ2, ..., φn ⊢ 𝜓 Suppose that we build a truth table that includes a column for each of the formulas φ1, φ2, ..., φn and 𝜓. We observe that on every line where every φi is true, 𝜓 is also true. We say that φ1, φ2, ..., φn semantically entails 𝜓, and we write φ1, φ2, ..., φn ⊨ 𝜓. Clearly, the semantic entailment relation between arbitrary formulas does not always hold. For example, the truth table above shows that \"p ∨ q ⊨ (p ∨ q) ∧ r\" does not hold. This can be seen from line 2 or line 4: in both cases p ∨ q is true, but (p ∨ q) ∧ r is false. The definition of semantic entailment may seem similar to the definition of a valid sequent. This is not coincidental. However, it is crucial to recognize the difference. A sequent is valid if we can use the rules of natural deduction to derive or prove the conclusion from the premises. A semantic entailment holds if we observe the required condition in all the rows of the truth table representation of the sequent. Note finally the changed the title of sections 1.4.3 and 1.4.4 below. There are other proof systems for propositional logic (not covered in the prescribed book), and soundness and completeness relates a specific proof system to the semantics of propositional logic. We have changed the titles of these sections to reflect this. 1.4.3 Soundness of natural deduction On pages 46-49 of the prescribed book it is proven that if φ1, ..., φn ⊢ 𝜓 is a valid sequent, then the semantic entailment φ1, ..., φn ⊨ 𝜓 holds. The proof uses course-of-values induction where the inductive hypothesis is applied to the number of lines in the proof. This result is a demonstration of the soundness of propositional logic. The significance of this result is that it is not possible for us to build a proof of something by natural deduction which is not \"true\" in the semantic entailment representation of truth. To be more explicit, if there exists a proof for the sequent, then, in the truth table representing that sequent, all lines that have a T for each of φ1, ..., φn must also have a T for 𝜓. The result is immediately useful to us. Suppose we are trying to prove the validity of a sequent, but without much success. If we can demonstrate that the corresponding semantic entailment does not hold, then there cannot be a proof of the sequent. To show that the semantic entailment does not hold, all we need to find is one line in the truth table on which all the premises are true but the conclusion is false. For example, consider the sequent p → q ⊢ q → p. This is obviously not valid but it may not be obvious how to prove that. We can demonstrate its invalidity by constructing the truth table: p q p → q q → p T T T T T F F T F T T F F F T T In line 3 of the truth table, the premise p → q has the truth value T but the conclusion q → p has the truth value F. Thus, the semantic entailment relation does not hold, and, from the proof of soundness, we know that the sequent does not have a proof. In other words, it is unprovable. 1.4.3 Completeness of natural deduction On pages 50-53 of the prescribed book it is proven that if the semantic entailment φ1, ..., φn ⊨ 𝜓 holds, then φ1, ..., φn ⊢ 𝜓 is a valid sequent, This is the second part of showing that the two systems of propositional logic (natural deduction proof rules and truth tables) are exactly equivalent. We outline the proof. Remember that a valid sequent is one that we can prove using natural deduction rules. The proof consists of three main steps: 1. Prove that if φ1, ..., φn ⊨ 𝜓 holds, then ⊨ φ1 → (φ2 → (..... (φn → 𝜓))...) holds. 2. Prove that if ⊨ φ1 → (φ2 → (..... (φn → 𝜓))...) holds, then ⊢ φ1 → (φ2 → (..... (φn → 𝜓))...) is a valid sequent. 3. Prove that if ⊢ φ1 → (φ2 → (..... (φn → 𝜓))...) is a valid sequent, then φ1, ..., φn ⊢ 𝜓 is a valid sequent. The proofs of Steps 1 and 3 are straightforward. The proof of Step 2 is more difficult and the explanation in the prescribed book is quite hard to follow. We can summarize the main points as follows: Course-of-values induction is applied to the height of the parse tree for the formula. The main idea is that, given any proposition φ, each line of the truth table for φ can be used to create a provable sequent which has the atoms in φ (or their negations) as premises and either φ or its negation as the conclusion. This is achieved by assuming that it can be done for all formulas with parse trees whose height is smaller than φ 's parse tree, and then show how applying the inductive hypothesis to the last operation in building φ 's parse tree, allows these to be combined to get a proof of the desired sequent. The formula that has to be proved by course-of-values induction applied to the height of its parse tree is φ1 → (φ2 → (..... (φn → 𝜓))...). A sequent is created from each line of its truth table and these are proved separately. LEM is then used over and over again to combine all of these special-case proofs into a complete proof of ⊢ φ1 → (φ2 → (..... (φn → 𝜓))...). Putting this result together with the previous proof of soundness, we can now state that φ1, ..., φn ⊢ 𝜓 is a valid sequent iff the semantic entailment φ1, ..., φn ⊨ 𝜓 holds. 1.5 Normal forms 1.5.1 Semantic equivalence, satisfiability and validity Two propositions are said to be semantically equivalent if their values are identical in all rows of a truth table. We write φ ≡ 𝜓 to indicate that φ and 𝜓 are semantically equivalent. Due to the soundness and completeness of natural deduction, we have that φ ⊣⊢ 𝜓 iff φ ≡ 𝜓 This means that all the provable equivalences listed in Section 1.2.4 are also semantic equivalences. A proposition φ is said to be satisfiable if there is some truth assignment of its atoms that makes φ evaluate to true. On the other hand, a proposition φ is said to be valid (or a tautology) if every assignment of truth values of φ 's atoms makes φ evaluate to true. Validity and satisfiability are linked by the following theorem (given on page 57 of the prescribed book): φ is satisfiable iff ¬φ is not valid (i.e. ¬φ is not a tautology). This theorem can be restated in a number of different ways. For example, \"φ is valid iff ¬φ is not satisfiable\", or \"φ is not valid iff ¬φ is satisfiable\", etc. Satisfiability is a very important practical problem for computer scientists. Unfortunately, there is no known, efficient algorithm to test an arbitrarily chosen proposition for satisfiability. One obvious algorithm is to generate the truth table for the problem, but this is extremely inefficient, and for any realistic application this method is not feasible. The reason is that the number of rows of the table grows exponentially with the number of different atoms in the formula. Think about it: If there are n different atoms in a formula, the truth table needs to have 2n rows. In fact, satisfiability (or SAT, as it is usually called) is still an area of active research in computer science. To recap, we can show that the proposition φ is a tautology (or valid) by constructing its truth table. However, constructing the truth table for φ may be impractical if the number of atoms is large. Is there a solution? One alternative is to convert φ into an equivalent formula for which validity checking is easier. One commonly used method is to convert φ to conjunctive normal form (CNF). A formula is in CNF if it consists of a set of clauses connected by the logical connective \"and\", such that each clause contains only atoms and their negations, connected by the logical connective \"or\". For example, (p ∨ q ∨ ¬r) ∧ (¬p ∨ s) ∧ (q ∨ ¬r ∨ ¬q) is in CNF. The formal definition of CNF (given on page 55 of the prescribed book) depends on a grammar which defines three types of objects: Literals (L), Disjunctions (D) and Conjunctions (C) L ::= p | ¬p this means \"a Literal is either an atom or the negation of an atom\" D ::= L | L ∨ D this means \"a Disjunction is either a Literal, or a Literal connected to a Disjunction with the connective ∨\" C ::= D | D ∧ C this means \"a Conjunction is either a Disjunction, or a Disjunction connected to a Conjunction with the connective ∧\" It is easy to check the validity of a formula that is in CNF. The formula can only be valid if all of its disjunctions are valid. A disjunction is valid under all circumstances only if it contains a pair of complementary literals; that is, if it contains a pair of literals of the form \"p\" and \"¬p\". Such a disjunction will always evaluate to true under any assignment of truth values to the literals. Creating a CNF Formula from a Truth Table Suppose we are given a truth table for a formula φ, but we are not given the actual formula. We can use the truth table to create φ in CNF. Recall that a formula in CNF consists of a conjunction of disjunctions. In order for the formula to evaluate to true, all of its disjunctions must evaluate to true simultaneously. We focus on the lines of the truth table where φ is false. We want to construct a formula that evaluates to true if the combination of literal values does not place us on any of these false lines. By linking together disjunctive clauses, each of which corresponds to the idea \"not on line k of the truth table\" where φ evaluates to false in line k, we create a formula which is true if and only if we are on one of the lines of the truth table where φ is true. As an example, say we have a formula φ that uses three atoms p, q and r: p q r φ T T T T T T F F T F T T T F F T F T T F F T F T F F T F F F F T We will create a formula which says, in effect, \"not on line 2\" AND \"not on line 5\" AND \"not on line 7\" On line 2, p is true, q is true, and r is false. If any of these conditions do not hold, then we are not on line 2. Thus \"¬p ∨ ¬q ∨ r\" is a formula for \"not on line 2\". Analyzing lines 5 and 7 in the same way, we get two more disjunctions, and when we link them together, we get (¬p ∨ ¬q ∨ r) ∧ (p ∨ ¬q ∨ ¬r) ∧ (p ∨ q ∨ ¬r) Note that the correctness of this method has an immediate implication. We started with an entirely arbitrary, unknown formula φ, and derived an equivalent CNF formula. This means that if we had started with a known formula, we could follow exactly the same steps: construct the truth table, identify the lines where the formula is false, and build a CNF formula based on those lines. The conclusion is that, for every formula in propositional logic, there is an equivalent CNF formula. It means that if we can prove things about CNF formulas, or create algorithms that apply only to CNF formulas, we are able to apply the results to all formulas. Unfortunately, this method of translating a given formula into CNF format is inefficient if there are a lot of atoms involved (since it once again depends on writing out a truth table, which grows exponentially). If we are given the truth table up front (and no other information about φ) then this is the method we use. But if we are actually given the formula φ, there is another method for creating a CNF equivalent. The method involves three steps: 1. Eliminate all → operators by applying the equivalence \"p → q ≡ ¬p ∨ q\" 2. Eliminate all double negations and transfer all negations to atoms, using the equivalences \"¬(p ∧ q) ≡ (¬p ∨¬q)\" and \"¬(p ∨ q) ≡ (¬p ∧ ¬q)\" 3. Distribute all the ∨s across the ∧s, using the equivalence \"p ∨ (r ∧s) ≡ (p ∨ r) ∧ (p ∨ s)\" Example: Suppose we have φ = (p ∨ q) → ¬(r ∨ ¬s): ¬(p ∨ q) ∨ ¬(r ∨ ¬s) ≡ (¬p ∧ ¬q) ∨ (¬r ∧ ¬¬s) ≡ (¬p ∧¬q) ∨ (¬r ∧ s) ≡ (¬p ∨ ¬r) ∧ (¬p ∨ s) ∧ (¬q ∨ ¬r) ∧ (¬q ∨ s) Note that the CNF version of φ is considerably longer than the original version. In the worst case, the algorithm will produce a CNF formula which is exponentially longer than the original (i.e. if the original formula contains n literals, then the CNF version will contain about 2n literals). 1.5.3 Horn clauses and satisfiability Horn formulas are one class of propositions for which SAT (see next section) can be solved efficiently. Here are some examples of Horn formulas: p ∧ ⊥ → q (⊤ ∧ ⊥ ∧ ⊤ ∧ ⊥ → ⊤) ∧ (p ∧ p ∧ p → p) (p ∧ q ∧ r → s) ∧ (⊤ → p) ∧ (s → ⊥) Here ⊥ is the familiar \"bottom\", meaning \"always false\", and ⊤ is the same symbol upside down (\"top\"), meaning \"always true\", and p, q, r and s are atoms. A Horn formula is a conjunction of Horn clauses, each of which is an implication, in which the left side is a conjunction of things and the right side is a single thing (where a \"thing\" is ⊥ or ⊤ or an atom). Note that ∨ and ¬ do not appear in Horn formulas. Horn formulas form the basic statement structure of the Prolog programming language. They also have the property that they can be tested for satisfiability very easily. The HORN algorithm works as follows. (1) Go through the formula and mark every occurrence of \"top\". (2) While there is a clause in which everything in the left side has been marked but the thing on the right side has not been marked, mark every occurrence of the thing on the right in the formula. (3) If \"bottom\" has been marked, report \"not satisfiable\" else report \"satisfiable\". This algorithm works by marking everything that is forced to be true by repeated applications of Modus Ponens. Clearly if \"bottom\" is marked, then one of the clauses has only things which must be true on the left side, and something which must be false on the right side. This implication must be false under any truth assignment that satisfies the other clauses, so the formula is not satisfiable. However, if \"bottom\" is not marked by this algorithm, then we can satisfy the formula by setting to true all the atoms that have been marked, and setting all others to false. Example: Say we want to determine whether the following Horn formula is satisfiable: (p ∧ q → r) ∧ (⊤ → p) ∧ (p → q) ∧ (r → ⊥) We apply the HORN algorithm as follows: (p ∧ q → r) ∧ (⊤ → p) ∧ (p → q) ∧ (r → ⊥) (1) (p ∧ q → r) ∧ (⊤ → p) ∧ (p → q) ∧ (r → ⊥) (2) (p ∧ q → r) ∧ (⊤ → p) ∧ (p → q) ∧ (r → ⊥) (2) (p ∧ q → r) ∧ (⊤ → p) ∧ (p → q) ∧ (r → ⊥) (2) (p ∧ q → r) ∧ (⊤ → p) ∧ (p → q) ∧ (r → ⊥) (2) \"not satisfiable\" (3)","libVersion":"0.2.3","langs":""}