{"path":"Subjects/COS3751 - Techniques of Artificial Intelligence/Assignments/Assignment 1 solution.pdf","text":"BAR CODE Deﬁne Tomorrow. university of south africa Tutorial Letter 102/0/2023 Techniques of Artiﬁcial Intelligence COS3751 Year module Computer Science School of Computing CONTENTS Assignment 1 COS3751/102/0/2023 These assignments are for you to have a genuine attempt at solving some sample problems. It is thus a matter of personal learning, and growth. Please don’t leave them to the last minute, and above all: please put in honest, own eﬀort when completing them. ASSIGNMENT 1 Solution Total Marks: 126 Unique Assignment Number: 533732 Study material: Chapters 1 to 4. You may skip sections 4.2 and 4.5. Important: When we use the phrase ‘deﬁne’, we are looking for a formal deﬁnition a formal mathematical notation, and not simply an English description or deﬁnition. For example: ‘Deﬁne the initial state for an agent in Johannesburg’. Answer: In(Johannesburg). ‘Deﬁne the actions available to this agent given that the agent simply moves between major metropolitan areas’. Answer: Actions(In(Johannesburg)) = {Go(Bloemfontein), Go(Durban), . . . }. When we want an English deﬁnition we will explicitly ask for it. Question 1: 11 Marks (1.1) (4)Explain the diﬀerence between fully observable and a partially observable environment. The textbook answer is: If an agent’s sensors give it access to the complete state of the environment at each point in time, then we say that the task environment is fully observable. A task environment is eﬀectively fully observable if the sensors detect all aspects that are relevant to the choice of action; relevance, in turn, depends on the performance measure. Fully observable environments are convenient because the agent need not maintain any internal state to keep track of the world. An environment might be partially observable because of noisy and inaccurate sensors or because parts of the state are simply missing from the sensor data – for example, a vacuum agent with only a local dirt sensor cannot tell whether there is dirt in other squares, and an automated taxi cannot see what other drivers are thinking. If the agent has no sensors at all then the environment is unobservable. A game of chess is fully observable, while a game of poker would be partially observable. Think about why this would be the case in these examples, and think of other examples. ✓4 (1.2) (4)Explain the diﬀerence between a Deterministic and Stochastic environment. In a deterministic environment the next state is completely ✓determined by the current state and the agent’s action ✓. In a stochastic environment one cannot com- pletely ✓determine the next state based solely on the current environment and on the agent’s actions ✓. (1.3) (3)Classify the following environments as deterministic or stochastic: 1. Chess 2. Soccer 2 COS3751/102/0/2023 3. Self-driving car 1. Chess – deterministic (all the states can be calculated if we have suﬃcient mem- ory)✓ 2. Soccer – stochastic (it is not possible to completely determine the next state)✓ 3. Self-driving car – stochastic (there are too many ill-deﬁned variables)✓ Question 2: 22 Marks (2.1) (5)Discuss well-deﬁned problems in terms of its ﬁve components. 1. Initial state✓ 2. Actions✓ 3. Transition model✓ 4. Goal test✓ 5. Path cost✓ The vacuum world could be used as an example of how these are deﬁned. INITIAL STATE: Any state can be designated as the initial state. ACTIONS: In the two-cell world we deﬁned three actions: Suck, move Left, and move Right. In a two-dimensional multi-cell world we need more movement actions. We could add Upward and Downward, giving us four absolute movement actions, or we could switch to egocentric actions, deﬁned relative to the viewpoint of the agent—for example, Forward, Backward, TurnRight, and TurnLeft. TRANSITION MODEL: Suck removes any dirt from the agent’s cell; Forward moves the agent ahead one cell in the direction it is facing, unless it hits a wall, in which case the action has no eﬀect. Backward moves the agent in the opposite direction, while TurnRight and TurnLeft change the direction it is facing by 90 ◦. GOAL STATES: The states in which every cell is clean. ACTION COST: Each action costs 1. (2.2) (2)Diﬀerentiate between search space and goal space. The search space is the set of states that have to be searched for a solution✓, whereas a goal space is a set of goal states✓. 3 (2.3) (1)What is the purpose of the explored set? Avoids inﬁnite loops since it holds the list of nodes that have already been ex- plored.✓ (2.4) (6)Explain why it is possible for the state space in an environment to be ﬁnite, while the search space could become inﬁnite. The state space and the search space of a problem are not the same. The state space shows all the possible states with connections indicating how to get from one state to the next. The search space is the structure (usually a tree, but sometimes a graph) created by the search algorithm to keep track of how the search for a solution is progressing and to keep track of where it was and where to go to next. If the state space has loops, in other words there is a path back to the same state (this could be direct or via other states), or if there are multiple paths between any two given states, it is possible for a search algorithm to get stuck on one of these loops if a solution is not in that path. The search space would then simply keep expanding to inﬁnity. Depth First Search (DFS) that uses a tree search can get stuck this way. Graph versions of the search algorithms are less likely to generate an inﬁnite search space, because it keeps track of the states that it has visited. This is also referred to as completeness.✓6 (2.5) (8)Discuss the four components of the data structure used by search algorithms. Search algorithms maintain a data structure that keep track of the construction of the search tree. For each node n in the search tree, there is a data structure with four components: • n.State: the state in the state space to which this node in the search corresponds • n.Parent: the node in the search tree that generated this node • n.Action: the action that was applied to the parent to generate this node • n.PathCost: the cost (usually indicated as g(n)) of the path from the root node, through the succession of nodes that generated this node ✓8 Question 3: 30 Marks Three (3) siblings, Anele, Busi and Chan, took part in a chocolate Easter egg hunt. Anele found 15 chocolate eggs, Busi found 9 eggs, and Chan found 6 eggs. They are slightly jealous of each other (as siblings sometimes are), so they each keep ‘their’ own eggs in a paper bag (15 in Anele’s bag, 9 in Busi’s bag, and 6 in Chan’s bag). They realise that they only have one bicycle to carry the eggs back home. The bicycle can carry either two kids, or one kid, or one kid and a bag of eggs. If a kid is left alone with more eggs than his or her own share, or if two kids are left alone with more eggs than their accumulated shares, the kid/kids may be tempted to eat the excess, so they want to avoid such a situation. The kids need to devise a strategy to carry all the eggs home, while making sure no eggs get eaten. 4 COS3751/102/0/2023 (3.1) (8)Deﬁne a state using a mathematical notation. Pictures or any form of graphical notation will not be accepted. Discuss the appropriateness of your choice, and provide an example to show that it will be suitable to be employed during a search. There are many possible answers. Abbreviate the kids with the labels Anelle = A, Busi = B, and Chan = C. The two locations (home or playground) would at any point in time have speciﬁc kids and a number of eggs. The location of the bicycle is also an important consideration, so we need to keep track of where it is. Denote the bicycle as X. We can ignore the travel in between, as all that does is remove kids and/or eggs from one location and place these in the other. We could initially represent each of these locations as tuples containing kids and eggs – our state representation. The initial state would have all the kids, the bicycle and all the eggs in the playground (the set on the left) and nothing at home (the set on the right). We also keep track of the three bags of eggs individually. A state becomes a set of two tuples (∅ indicates that there is nothing at that location): sstart = {⟨A, B, C, X, 15, 9, 6⟩, ⟨∅⟩} Let’s say the ﬁrst move is for Chan to take his bag of 6 eggs home. The next state would then be: sﬁrstmove = {⟨A, B, 15, 9⟩, ⟨C, X, 6⟩} Our goal state is: sgoal = {⟨∅⟩, ⟨A, B, C, X, 15, 9, 6⟩} This representation of a state if fairly easy for humans to read, but contains re- dundant information. To keep the execution of an algorithm as eﬃcient as possible, we need to consider the memory requirements. The more compact we can make the state representation the less memory is required. A more compact state representation would be: sstart = {⟨A, B, C, X, 15, 9, 6⟩} Everything that is not in the playground would automatically be at home. We don’t need to keep track of what is happening at home if we know where the bicycle is. In a data structure we could replace the kids and the bicycle with bits, and lump all the eggs together, so the state representation becomes: sstart = {⟨1111, 30⟩} Here the ﬁrst bit represents the presence (bit = 1) or not (bit = 0) of A in the playground. Similarly for B, C, and X. The number is simply the number of eggs in the playground. So we’ve reduced the memory requirement for a state to a 4-bit number and an integer. Here we can see that there is a trade-oﬀ between memory and speed. We can create more compact state representations, but this often comes at the cost of adding computational complexity to the algorithm. In this case we have to add a calculation that subtracts or adds 15, 9 or 6 eggs to the state representation when we make a move. We could, in fact make it more compact if we think carefully about the problem. If we represent each of the three bags of eggs as a bit, the state representation is now 5 reduced to a 7-bit number, where a 1 indicates the presence of a kid, the bicycle or a bag of eggs in the playground. Our start state becomes: sstart = {⟨1111111⟩} In order to keep the rest of the discussion understandable we will use the compact human- readable form: sstart = {⟨A, B, C, X, 15, 9, 6⟩} If we use this representation when coding the algorithm, we again incur a computational cost, as we need to alternate adding or removing elements from the state. ✓8 (3.2) (4)Deﬁne the start and goal states using your representation. The start state, with all the kids, the eggs, and the bicycle in the playground, using our representation, is: sstart = {⟨A, B, C, X, 15, 9, 6⟩} The goal state is an empty playground, with everything and everybody at home: sgoal = {⟨∅⟩} ✓4 (3.3) (2)Deﬁne an appropriate cost function or functions for this problem. The distance between the playground and home is ﬁxed. If we suspect that there may be more than one solution and that some of them require more trips, and if the kids want to get home as soon as possible, then a cost function would be relevant. A cost function would then simply count every trip (one way or back) as 1, so that the total cost for a solution equals the number of trips made. If the kids want to get home as soon as possible, the search algorithm should miminise the cost. ✓2 (3.4) (8)Provide a formal deﬁnition of a valid action function for this problem – you need not provide a formal deﬁnition for the operation of the function. Discuss the operation of the function and provide an example to illustrate its use. The action to change the state would be to move the bicycle, a kid, and one bag of eggs, or one kid, or two kids to the other location. This means that a move would either remove elements from the tuple if it is there, or add elements if it is not there. The move would require that we decide which of the kids and/or which bag of eggs to move. Similarly then, a move would either remove or add one or two kid to the tuple, depending on whether they are present or not, and the same for the bag of eggs. A formal deﬁnition for the action would then be: Move(K, E) where K ∈ {A, B, C}, E ∈ {A, B, C, 15, 9, 6}, and K ̸= E. The assumption is that the bicyle, X is moved every time, in the correct direction. K ̸= E ensures that we don’t put the same kid on the bike twice. For example, we cannot do Move(A, A), but Move(A, B) is a valid move. The start state, with all the kids, the eggs, and the bicycle in the playground, using our representation, is: The goal state is an empty playground, with everything and everybody at home: sgoal = {⟨∅⟩} 6 COS3751/102/0/2023 The start state is: sstart = {⟨A, B, C, X, 15, 9, 6⟩} Our ﬁrst move (Chan takes 6 eggs home) would then be executed using Move(C, 6), which would change the state to: smove1 = {⟨A, B, 15, 9⟩} Since the bicycle is now at home, we have only two valid moves, namely Move(C, 6) or Move(C, ∅). The ﬁrst of these moves simply brings us back to the start state (HINT: here is an example of a potential inﬁnite loop in the search space), while the second possible move produces the state: smove2 = {⟨A, B, C, X, 15, 9⟩} which leaves the bag with 6 eggs at home and all the rest in the playground. ✓8 (3.5) (8)Find a solution to the problem. There are a maximum of 128 possible states. This follows from the fact that there are seven elements in our tuple, which are either present or not, i.e. 2 7 = 128 (remember the 7-bit represenation in Question 3.1). Following the rules of the game, not all of the states are valid. For example, if there is only one kid in the playground with all the eggs, he/she may be tempted to eat the eggs – a situation we want to avoid. Also, some states are invalid due to the rules of movement. The bicycle cannot move on its own, so any state where the bicycle is at a location without one or more kids is invalid. The same applies to the eggs. Eggs always have to move with a kid on the bicycle. The following diagram shows all 128 possible states for this problem. According to the rules of the problem some of these states are not valid. For example, s9 is invalid because there are 6 more eggs than A and B are entitled to. These states are shown in red. Some states are invalid, because the bicycle can only move with one or two kids, and eggs can only move with a kid. It is not possible to reach these states given this limitation. These states are shown in orange. The green states are the remaining valid states, if the rules are applied. In many problems a state may be valid, but is not reachable from the start state or any valid state. The two yellow states are such states (try and see if you can reach a valid state from these two). 7 A, B , C , X , 15 , 9 , 6 s1 A, B , C , X , 15 , 9 s2 A, B , C , X , 15 , 6 s3 A, B , C , X , 15 s4 A, B , C , X , 9 , 6 s5 A, B , C , X , 9 s6 A, B , C , X , 6 s7 A, B , C , X s8 A, B , X , 15 , 9 , 6 s9 A, B , X , 15 , 9 s10 A, B , X , 15 , 6 s11 A, B , X , 15 s12 A, B , X , 9 , 6 s13 A, B , X , 9 s14 A, B , X , 6 s15 A, B , X s16 A, C , X , 15 , 9 , 6 s17 A, C , X , 15 , 9 s18 A, C , X , 15 , 6 s19 A, C , X , 15 s20 A, C , X , 9 , 6 s21 A, C , X , 9 s22 A, C , X , 6 s23 A, C , X s24 A, X , 15 , 9 , 6 s25 A, X , 15 , 9 s26 A, X , 15 , 6 s27 A, X , 15 s28 A, X , 9 , 6 s29 A, X , 9 s30 A, X , 6 s31 A, X s32 B , C , X , 15 , 9 , 6 s33 B , C , X , 15 , 9 s34 B , C , X , 15 , 6 s35 B , C , X , 15 s36 B , C , X , 9 , 6 s37 B , C , X , 9 s38 B , C , X , 6 s39 B , C , X s40 B , X , 15 , 9 , 6 s41 B , X , 15 , 9 s42 B , X , 15 , 6 s43 B , X , 15 s44 B , X , 9 , 6 s45 B , X , 9 s46 B , X , 6 s47 B , X s48 C , X , 15 , 9 , 6 s49 C , X , 15 , 9 s50 C , X , 15 , 6 s51 C , X , 15 s52 C , X , 9 , 6 s53 C , X , 9 s54 C , X , 6 s55 C , X s56 X , 15 , 9 , 6 s57 X , 15 , 9 s58 X , 15 , 6 s59 X , 15 s60 X , 9 , 6 s61 X , 9 s62 X , 6 s63 X s64 A, B , C , 15 , 9 s65 A, B , C , 15 , 6 s66 A, B , C , 15 s67 A, B , C , 15 , 9 , 6 s68 A, B , C , 9 , 6 s69 A, B , C , 9 s70 A, B , C , 6 s71 A, B , C s72 A, B , 15 , 9 , 6 s73 A, B , 15 , 9 s74 A, B , 15 , 6 s75 A, B , 15 s76 A, B , 9 , 6 s77 A, B , 9 s78 A, B , 6 s79 A, B s80 A, C , 15 , 9 , 6 s81 A, C , 15 , 9 s82 A, C , 15 , 6 s83 A, C , 15 s84 A, C , 9 , 6 s85 A, C , 9 s86 A, C , 6 s87 A, C s88 A, 15 , 9 , 6 s89 A, 15 , 9 s90 A, 15 , 6 s91 A, 15 s92 A, 9 , 6 s93 A, 9 s94 A, 6 s95 A s96 B , C , 15 , 9 , 6 s97 B , C , 15 , 9 s98 B , C , 15 , 6 s99 B , C , 15 s100 B , C , 9 , 6 s101 B , C , 9 s102 B , C , 6 s103 B , C s104 B , 15 , 9 , 6 s105 B , 15 , 9 s106 B , 15 , 6 s107 B , 15 s108 B , 9 , 6 s109 B , 9 s110 B , 6 s111 B s112 C , 15 , 9 , 6 s113 C , 15 , 9 s114 C , 15 , 6 s115 C , 15 s116 C , 9 , 6 s117 C , 9 s118 C , 6 s119 C s120 15 , 9 , 6 s121 15 , 9 s122 15 , 6 s123 15 s124 9 , 6 s125 9 s126 6 s127 ∅ s128 The following diagram shows the complete state space for this problem. From this diagram we can see that there are 8 possible solutions to the problem, that doesn’t require backtracking to previous states. 8 COS3751/102/0/2023 A, B , C , X , 15 , 9 , 6 s1 A, B , C , X , 15 , 9 s2 A, B , C , X , 15 , 6 s3 A, B , C , X , 15 s4 A, B , C , X , 9 , 6 s5 A, B , C , X , 9 s6 A, B , C , X , 6 s7 A, B , X , 15 , 9 s10 A, C , X , 15 , 6 s19 A, X , 15 s28 A, X , 9 , 6 s29 B , C , X , 15 s36 B , C , X , 9 , 6 s37 B , X , 9 s46 C , X , 6 s55 A, B , 15 , 9 s74 A, C , 15 , 6 s83 A, 15 s92 A, 9 , 6 s93 B , C , 15 s100 B , C , 9 , 6 s101 B , 9 s110 C , 6 s119 15 , 9 s122 15 , 6 s123 15 s124 9 , 6 s125 9 s126 6 s127 ∅ s128 Move(B, 9) Move(B, ∅) Move(A, 6) Move(A, ∅) Move(B, C) Move(C, 6) Move(A, 15) Move(B, 9) Move(B, C) Move(A) Move(A, 6) Move(B, ∅) Move(B, 9) Move(A, 15) Move(C, 6) Move(C, ∅)Move(A, ∅) Move(B, C) Move(A, 9) Move(B, 9) Move(A, B) Move(A, 15) Move(A, C) Move(C, 6)Move(A, C) Move(A, B) Move(A, 9) Move(C, ∅) Move(C, 6) Move(A, 15) Move(A, ∅) Move(B, C) For the vast majority of real-world problems it is not possible to ﬁnd all the possible states, and it is even more diﬃcult to construct the entire state space. For example, chess has a state-space complexity of 44, as a log to base 10, which means this is a number with 44 digits. A search tree generated from such a state is even larger and could grow to a number with 58 digits! ✓8 9 Question 4: 12 Marks (4.1) (4)Discuss the diﬀerences between a tree and graph search. Remember that a tree is a simple-connected acyclic graph. (That means that there are no loops, and that by deﬁnition there must be nodes that have no children). A graph, on the other hand may have cycles or loops. The main diﬀerence between a tree search is thus that we don’t need to keep track of already explored nodes, since a simple tree cannot have revisited states. Thus, the tree search simply selects a leaf node from the frontier, goal tests, and if it is a goal it returns the path (solution) to that node.✓ Applying a tree search to a graph creates problems since there may be redundant paths and loops.✓The graph search solves this problem by augmenting the tree search with a ’closed list’ (or explored list). When nodes are generated during the search that are already on the closed list they are not added to the frontier.✓2 (4.2) (4)How does Breadth First Search (BFS) rate in terms of the four criteria for measuring the performance of problem solving? The four criteria for measuring problem-solving performance are: Completeness: Is the algorithm guaranteed to ﬁnd a solution when there is one, and to correctly report failure when there is not? Optimal cost: Does it ﬁnd a solution with the lowest path cost of all solutions? Time complexity: How long does it take to ﬁnd a solution? This can be measured in seconds, or more abstractly by the number of states and actions considered. Space complexity: How much memory is needed to perform the search? See the textbook discussion on BFS and how it measures up against the four criteria. ✓4 (4.3) (4)Consider an example of a sliding-block puzzle game state provided below (Figure 1). How many distinct states are there for puzzles of this sort? How many search nodes? Explain how you reached your answer. A B E I F H C N G J L M O K D Figure 1: Sliding-block puzzle 10 COS3751/102/0/2023 It is interesting to note that half of random start states for the 15 puzzle are not solvable. For the 15-puzzle, we will always have 16! distinct states. However, since only half of the random start states are solvable, we have a possible search space of 16!/2.✓4 Why use 16!? If we start with an empty board we can choose to place any of the 16 tokens (numbers 1 to 15 and blank space) in the top-left position, from here on we can choose any one of the remaining 15 tokens for the position just to the right of the top-left, and so we carry on: 16 × 15 × 14 × . . . × 2 × 1 = 16!. If you’re concerned about the number of distinct states for the example provided above, you will have to consider the number of moves that can be used to solve the puzzle – but that would only yield a possible lower-bound (assuming our search is super-eﬃcient) on the search space. From a space-complexity viewpoint, it will suﬃce to state that the upper bound of the distinct number of states is 16!. Question 5: 6 Marks Consider the search tree in Figure 2. D C B A H I L M E J N O F K G Figure 2: Search Tree (Iterative Deepening Search (IDS)) (5.1) (6)Show the order in which the nodes will be expanded (from limit 0 to limit 4) given that IDS is used. Assume the goal node is N , and that nodes are expanded from left to right. So expansion means we apply legal actions to a chosen node – this, by deﬁnition, means that our order look somewhat diﬀerent from what one may expect. Also, note that the IDS is a repeated invocation of the depth limited search. In the depth limited search, once we generate a node, we recursively call the depth limited search on that node. Thus, goal state checking happens immediately after generation for each node. In general, the children of nodes that are expanded are thus goal checked. 1. Limit 0: (No expansion – D is just goal tested) ✓ 2. Limit 1: D ✓(C and E are just goal tested, not expanded) 11 3. Limit 2: D C E ✓ 4. Limit 3: D C B I E J F✓2 5. Limit 4: None, search terminates once J is expanded – once J is expanded, N will be generated and goal tested on the recursive call. ✓ Visually, this is what happens (squares are goal tests and circles are expansions). Limit 0: D Limit 1: D C E Limit 2: D C B I E J F Limit 3: D C B A H I L M E J N Question 6: 16 Marks Consider the graph in Figure 3. 12 COS3751/102/0/2023 Z Y X W V U T S 11 20 15 4 24 22 14 12 9 Figure 3: Search Graph (Uniform Cost Search (UCS)) (6.1) (4)Explain the concept of Uniform Cost Search (UCS). Provide an example to aid your discussion Uniform cost search is an uninformed search – thus no heuristics!. It calculates the cost of moving from this state to the next (keeping the cost of reaching the current state in mind), and chooses the cheapest (as deﬁned in the problem) next state from the frontier✓2. It helps to think of it as explained in the textbook: it uses an evaluation function (similar to an informed search such as A ∗): ˆf (n) = ˆg(n) or just ˆg(n). example✓2 (6.2) (12)Suppose we start at X and the goal is T . Write down the nodes in the order they are expanded. Show your steps and calculations. The step cost between nodes is provided next to the edges in the graph. Since we’ve been talking about uniform cost, we’ll use the UCS algorithm. 1. X is placed on the frontier. (Technically we would put (X,0) on the frontier – see the next step for more detail) Frontier is: (X,0)✓ 2. Choose X (and remove) for expansion: generate the path (X, U, 4), (X, Z, 20), and (X, V, 24) (where (X,Z,20) means that there is a path from X to Z which costs 20), and place on frontier. Frontier is: (X,U,4), (X,Z,20), (X,V,24) ✓ 13 3. Choose (and remove) (X,U,4) (lowest cost, but not goal) – generate (X,U,S,13) and place on the frontier. Frontier is: (X,U,S,13), (X,Z,20), (X,V,24) ✓ 4. Choose (and remove) (X,U,S,13) (lowest cost, but not goal) – generate (X,U,S,T,25) and place on the frontier. Frontier is: (X,Z,20), (X,V,24), (X,U,S,T,25)✓ 5. Choose (and remove) (X,Z,20) (lowest cost, but not goal) – generate (X,Z,Y,31) and place on the frontier. Frontier is: (X,V,24), (X,U,S,T,25),(X,Z,Y,31)✓ 6. Choose (and remove) (X,V,24) (lowest cost, but not goal) – generate (X,V,W,46) and place on the frontier. Frontier is: (X,U,S,T,25), (X,Z,Y,31), (X,V,W,46)✓ 7. Choose (and remove) (X,U,S,T,25) (lower cost, and goal) – search terminates.✓ Taking the nodes from the map as they are expanded, you thus have X✓,U✓,S✓,Z✓,V✓. Question 7: 4 Marks (7.1) (4)Diﬀerentiate between an admissible and a consistent heuristic. An admissible heuristic does not overestimate the actual cost of getting from a node in the search space to the goal✓2. A consistent heuristic is more strict than an admissible one: it obeys the triangle inequality: it is not possible for one side of a triangle to be longer than the sum of the lengths of the other two sides – thus, the heuristic should not estimate a higher cost from a node to a goal than a shorter actual path to the goal from that node.✓2 Question 8: 25 Marks Consider Figure 4 and Table 1 and answer the questions that follow. Table 1 provides the straight-line distances (SLD) from each city to PTA, as an estimate (thus ˆh for each node). The label next to each edge provides the cost between cities (thus ˆg). City SLD to PTA CT 1310 PTA 0 PE 945 BFN 425 KMB 475 JHB 50 NSP 280 DBN 535 PMB 480 EL 810 Table 1: Distance Table 14 COS3751/102/0/2023 Figure 4: South Africa road distances – A∗ Search (8.1) (10)We want to get from CT to PTA. List the nodes in the order in which they are expanded (not generated). Show your steps (don’t just list the nodes, explain the reason for each choice). To initialise the A ∗-algorithm we add the start node and an initial ˆf (n) value. The only information we have is the straight-line distance (SLD) to the target node, i.e. ˆh. Since we have not traversed any edges in the graph, ˆg = 0. Therefore ˆf = 1310. So the frontier has only one node: 1. ⟨⟨CT ⟩, (1310)⟩ Expand the node in the frontier with the lowest ˆf value. The frontier initially only has one node, so we expand CT to get the next frontier: 1. ⟨⟨CT, KMB ⟩, (1445 = 970 + 475)⟩ 2. ⟨⟨CT, PE ⟩, (1715 = 770 + 945)⟩ Notice what we did here. Instead of only keeping a single city (KMB or PE) in the frontier nodes, we keep the entire path. This will allow the algorithm to choose between alternative paths to the destination if their ˆf -values are equal. To do this we can add a rule to the algorithm to pick the route with fewer cities. Now we choose the node with the lowest ˆf -value, namely ⟨CT, KMB ⟩, and expand KMB: 15 1. ⟨⟨CT, KMB, JNB ⟩, (1500 = 970 + 480 + 50)⟩ 2. ⟨⟨CT, KMB, BFN ⟩, (1560 = 970 + 165 + 425)⟩ 3. ⟨⟨CT, PE ⟩, (1715 = 770 + 945)⟩ Of the three nodes in the frontier we again explore the node with the lowest ˆf -value. Therefore we expand JNB: 1. ⟨⟨CT, KMB, BFN ⟩, (1560 = 970 + 165 + 425)⟩ 2. ⟨⟨CT, PE ⟩, (1715 = 770 + 945)⟩ 3. ⟨⟨CT, KMB, JNB, PTA ⟩, (1510 = 970 + 480 + 60 + 0)⟩ 4. ⟨⟨CT, KMB, JNB, EL ⟩, (3260 = 970 + 480 + 1000 + 810)⟩ You will notice on the map that it is possible to go from JNB to BFN, but BFN does not appear in the frontier. The reason for this is that the algorithm calculated that this would be a longer route to PTA than those already explored, and therefore ignores it. At this point the algorithm has found a solution to the search task. There are no other paths to the target and the algorithm terminates. So our solution is: CT, KMB, JNB, PTA. ✓10 (8.2) (4)When adding nodes to the frontier (during the search), is it enough to simply add nodes from the state space to the frontier? Justify your answer. Simply adding the nodes in the state space may not convey the needed information to solve the problem. It is not always the case, if the search space naturally encodes the solution (or an intermediate solution) then the nodes from the state space should suﬃce. For example: if the nodes in the search space for the previous question are simply nodes in the state-space, then the path to follow from start to ﬁnish is not properly encoded in the solution to the problem. We need to have the path to follow (or the route to travel) in order to be able to solve the problem. Thus it is often better to encode partial solutions in the nodes in the search space: in this way they become part of the solution to the problem, and will be used as they are in the frontier.✓4 (8.3) (4)Provide the content of the frontier at the time the search terminates. 1. ⟨⟨CT, KMB, BFN ⟩, (1560 = 970 + 165 + 425)⟩ 2. ⟨⟨CT, PE ⟩, (1715 = 770 + 945)⟩ 3. ⟨⟨CT, KMB, JNB, PTA ⟩, (1510 = 970 + 480 + 60 + 0)⟩ 4. ⟨⟨CT, KMB, JNB, EL ⟩, (3260 = 970 + 480 + 1000 + 810)⟩ ✓4 16 COS3751/102/0/2023 (8.4) (7)Is the heuristic being applied consistent? Justify your answer by providing proof from the graph. Heuristics for A∗ must fulﬁll two properties. They must be admissible (in this case the heuristic distance must always be larger than the actual route), and they must be monotone, which means that it may not violate the triangle inequality. In this problem we are only given the heuristic values for the distance between PTA (the target) and the other cities. We are not given any heuristic values for the distance between all the cities. If, for example, we have an estimated SLD between JNB and PMB of 420, we get the following diagram: JNB PTA PMB 50 480 420 We see that the heuristic estimates the route via JNB as shorter than the straight distance between PTA and PMB, which means that the heuristic would be inconsistent. ✓7 Read up on what it means for the execution of informed search algorithms when you use inconsistent heuristics. © UNISA 2023 17","libVersion":"0.2.3","langs":""}