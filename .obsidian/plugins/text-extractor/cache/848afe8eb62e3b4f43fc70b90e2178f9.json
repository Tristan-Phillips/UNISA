{"path":"Subjects/COS3751 - Techniques of Artificial Intelligence/Exam Packs/Stuvia-854993-awesome-cos3751-summary-techniques-of-ai 1.pdf","text":"AWESOME! COS3751 Summary (Techniques of AI) written by francoissmit www.stuvia.com Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal A Note: For the summaries, a block with a ‘red E’ means that it is an exam question and is very important. A yellow block with an A means it is an assignment questions, which is also important. Agents and uninformed searches A problem can be defined by 5 components:  Initial state: e.g. In(Arad)  A description of the possible actions available to the agent: With particular state s then ACTIONS(s) will return actions applicable in s. e.g. in state In(Arad) the applicable actions are {Go(Sibuiu), Go(Timisoara), Go(Zerind)}  Transition model which is description of what each action does. Specified by function RESULT(s,a) that returns the state that results from doing action a in state s. e.g RESULT(In(Arad), Go(Zerind)) = In(Zerind) Think: transition to another state To define this 1 st define the applicable actions. Then go Result(action1,State) -> Resulting state Result(action2,State) -> Resulting State Normally it will only ask 1 case. It will give you a state from which to work with e.g. Here the state we working from is S = {Andile, Bob, Torch} Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E E Although here there are more than 1 way to define actions and states.  Goal test which determines whether a given state is a goal state. E.g. the goal state is {In(Bucharest)}  Path cost function that assigns a numeric cost to each path. A step cost of taking action a in state s to reach state s1 is denoted by c(s, a, s1). Reflex agent:  Simple agent that choose action based on current percept (and maybe memory). So based on input and current state (there is a lookup table) agent will choose and action.  Do not consider future consequences  Consider how the world IS  They are rational, because they will chose as to achieve the best outcome when given a certain percept.  GIVE THIS IN EXAM: A rational agent is an agent that Acts in order to achieve the best outcome, or where there is uncertainty, the best-expected outcome. Conceptually speaking, it does the “right thing”. Definition of rationality: A system is rational if it does the right thing, given what it knows. A rational agent is one that acts so as to achieve the best outcome or, when there is uncertainty, the best expected outcome. Simple reflex agent:  Select actions on the basis of the current percept (information it received from environment) , ignoring the rest of the percept history.  Basically the one as before  Used condition-action rule. e.g. if car-in-front-is-braking then initiate-braking Model based reflex agent  uses knowledge about how the world works, i.e. uses a model.  Def: It bases actions on current percept and percept history and it uses a model of how the world works  model shows what actions will do to change the world. Environments: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Discrete vs continuous environment:  Discrete = an environment with precise, finite states. Eg: a light switch (2 states: on/off).  Continuous = an environment with an infinite number of possible states (real life). Eg: temperature. Fully vs partially observable environments:  Fully observable: If an agent’s sensors give it access to the complete state of the environment at each point in time. Only the states the agent need to function.  Partially observable: If agent’s sensors does not provide complete set of all the states. Single agent vs Multiagent:  Single agent environment: When a single agent is alone in an environment. E.g. Agent playing crossword puzzle  Multiagent environment: When there are more than one agent in the environment. E.g. Agent playing chess. Deterministic vs stochastic:  Deterministic: If the next state of the environment is completely determined by current state and the action executed by the agent. e.g. agent playing crossword puzzle next state determined (deterministic) by current state and the action  Stochastic: If next state is not only determined by current state and the action. E.g. Taxi driver agent since it can’t predict the traffic Episodic vs sequential:  Episodic: An agent whose action is not based on previous actions taken. E.g. Agent that has to spot defect in assembly lines  Sequential: Agent whose actions is based on its previous actions, i.e. current decisions effect future decisions. E.g. Agent playing chess, since short term decisions effect future decisions. Static vs dynamic: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace A  Static: If the environment cannot change while the agent is deliberating (making decisions). e.g. agent playing crossword puzzle  Dynamic: If environment can change while agent is deliberating: E.g. Taxi driving agent, because traffic is constantly changing while agent is making decisions Known vs unknows:  Known: All outcomes for all actions are known to the agent.  Unknown: If not all outcomes of all actions are known to the agent Competitive vs cooperative:  Competitive: When there are 2 agents which goals conflict with each other. E.g. 2 agents playing chess. B is trying to maximize its performance, which minimizes A’s performance.  Cooperative: When agents goals are similar and a particular agents action maximizes all agents’ performance. E.g. taxi driver agent, because avoiding collisions maximizes performance of all agents.  Note: That single agent environment can never be Competitive or cooperative. It must be multiagent. Optimal vs. complete planning: A complete planning agent finds a solution (reaches goal state) and an optimal agent finds a solution in the most optimal way. Planning vs. replanning Planning agent comes up with an entire plan to get to the solution and a replanning modifies this plan to make it more optimal (basically a utility agent). Replanning agent can initially also comes up with many plans and then choose the best one. Difference between model based and reflex based agent: Simple Reflex agent: Agent’s actions are only based on current percept, not percept history. E.g. E.g. Agent that has to spot defects in assembly lines Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E Model based agent: Here the agent’s actions is not only based on current percept, but also on percept history. E.g. taxi driving agent Representation: Example: A state representation is a general state of a specific problem in a formal way. Example is State: S=(P, x) x: represent how many items are left on the heap. x€(0,1,2,3,4,5) P: Represents which player’s turn it is in this state to remove item/s, either A or B , P€(A,B) A specific state can be Sj = (A, 4) i) they ask what elements form part of the state representation, so to make state representation you must look at initial state, actions and transition model Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Remember elements that from a state representation is initial State (or states of the problem), actions and transition model Example: To define a game’s state representation:  You represent a general state in mathematical notation.  Something like State: S=(P, x)  Then you say what each variable is be specific and list what values the variables can take on  E.g.:  x: represent how many items are left on the heap. x€(0,1,2,3,4,5) Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace  P: Represents which player’s turn it is in this state to remove item/s, either A or B , P€(A,B) Here is the full answer: a) i) State: S = (P,n), P represents whose turn it is, either A or B, and n is the amount of items on the heap P€(A,B), P represents either player A or B n€(0,1,2,3,4,5) n represent the amount of items currently on the heap To define an action using this representation:  Represent action using mathematical notation. Also use the state in the action:  Example: Action: a= remove(i) Note: don’t put state in the action, also we use i, since n is already taken  You must say what the variable mean, what the action does in English (explain it in English) and what values the variable can take on. You can also give an example.  You can also show what the action returns in formal notation.  An example of an action would be remove(2) which will remove 2 items. Here is answer to ii): Applicable actions: Ai = remove(i), this action removes i items from the heap. Explain what the action does and explain what the variable is IN ONE SENTENCE i€(1,2,3) say what values the variable can hold e.g. A3 = remove(3), this will remove 3 items from the heap The action will return a state e.g. Result(S, Ai) -> S’, this says the result of doing action Ai in state S will yield S’ How to show a state was achieved by doing a certain action: iii) Start state: S=(A,5) we need to define A2 as well, try to define everything and be specific: action A2 = remove(2) Result(S,A2) -> S’ = (B,3), This says doing action A2 with starting state S will result in state S’ Note: they did no say that we should define this formally thus the memo have used English, but I will always define it formally Make sure your examples are consistent with your definition. Search problem (same as problem definition previously) Consists of: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace - A state space: set of all the states in this world. - A successor function : which is description of what each action does. Specified by function RESULT(s,a) that returns the state that results from doing action a in state s. e.g RESULT(In(Arad), Go(Zerind)) = In(Zerind) - A start state and a goal test e.g. A solution is a sequence of actions (plan) which transform the start state to the goal state. Search problems are models! World state includes every detail of the environment(e.g. In previous example it includes, cities, roads, birds, dears, etc.), but search state includes only the details needed for planning (abstraction) (e.g. cities, road cost) State space graph: A mathematical representation of a search problem. Graphical representation of all the states and which actions leads to which states. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace This state corresponds to the PLAN of being in the start state and going north - nodes are (abstracted) world configurations (states) - Arcs represents successors (action results) - The goal test is a set of goal nodes - Each state only occurs once, regardless of the paths that could lead to get to it. - But this consumes too much memory, it’s only for understanding. Search Trees  So we use this instead of a state space graph.  A “what-if” tree of plans and their outcomes  Start state it the root node  Children correspond to successors (state after applying an action to another state)  Nodes show states, but correspond to PLANS that achieve those states. This means same state can appear multiple times on the tree.  For most problems, we can never build the whole tree. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Tree search algorithm: How does the algorithm work? Pass in a problem and strategy (what type of search we do / what frontier nodes do I expand next). Returns either a solution or failure. Then continuously do: if no children for expansion (meaning I have not reached a goal and cant expand)return failure Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E E E choose lead node for expansion according to strategy if node contain goal state then return solution (path to the goal state) You pick expansions out of the frontier (fringe) which is nodes that currently can be expanded, i.e. leave nodes which can be expanded. We can evaluate an algorithm’s (strategy’s) performance in 4 ways: - Completeness: Is algorithm guaranteed to find a solution - Optimality: Does strategy find optimal solution (path with lowest cost) - Time complexity: How long does it take to find a solution (basically how many nodes gets expanded) - Space complexity: How much memory is needed to perform search (i.e. store the nodes in memory)(basically how big can the frontier get) With A* search, UCS and DFS, you only stop when the goal node is expanded, but with BFS you stop when you reach the goal, i.e. when goal node is generated. Think soccer BFS reach goal. Depth-first search  uses a LIFO stack data structure. TO REMEMBER: LIFE has a lot of Depth. LIFE, replace E with O  Strategy: expands the deepest (depth) node in the current frontier 1st. If equally deep then expands left most node 1st. (if left most search is chosen, can also be right depending on the question)  Not cost sensitive search Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E  Finds the left most goal 1st (if left most search is chosen, otherwise it finds right most goal)  Strategy: Expand the deepest node 1st, if equally deep expand the left most node 1st.  Implemented as a LIFO stack M is the goal state in this example, White are on the frontier, grey is removed nodes. : To ask the properties let’s look at some terms: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Red dots are the solutions. Here it stops when it finds the left most goal. E Terms: - b is the branching factor - m is the max depth How many nodes are there in the entire tree: Remember Big-O notation you get largest term of the entire expression and put it in the O. It basically searches from left to right until it reaches the left most goal as seen in these pictures: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E - Some left prefix of the tree - Could process whole tree - If m is finite, takes O(𝑏𝑚) O(bm), it is branching factor * max depth. Because as seen in this picture b is 2 (every node expands into 2 nodes) and m is 2. So at most there can be 4 nodes in the frontier. DEFG nodes are at depth 2. A at depth 0.  Properties: - Complete: Yes if m is finite - Optimal: No, because if optimal (shortest) path is at the right then we won’t find it. because we might find a solution that is at bottom left. See here the other red dot is optimal solution - Time complexity (How many nodes gets expanded): - Space complexity (How many nodes in frontier): O(bm) Think: bs to be so deep down. Thus DFS is bm (m being how deep you are, i.e. at what level) Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E You need to know how to calculate the performance of DFS with regards to storage, i.e. space complexity. Space complexity is how big the fringe can get. So if they say the solution is at 7 levels deep and the branching factor is 6 then: Eg =bd =6*7 42 Know both space and time complexity Breadth-first search:  uses a FIFO queue data structure. TO REMEMBER: Soccer player’s breadth stinks, soccer is FIFA. Replace a with O  Strategy: is to 1st expands the root node, then it expands the root node’s successors (starting at the left node), then it expands their successors, and so on.  Not cost sensitive search  Move down horizontally in the search tree  Finds the shallowest goal How BFS ensures it expands shallowest node 1st: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E Strategy: Expand root node, then all the successors of root node, then their successors, and so on. Implementation: Uses FIFO data structure TO REMEMBER: Clean BREADTH is important in LIFE (LIFO). Replace e and o. How to apply BFS using state graph and showing how the FIFO is used:  Note still have to check that this example is correct Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Displaying the properties through images: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E You need to know how to calculate the performance of BFS with regards to storage, i.e. space complexity. Space complexity is how big the fringe can get. So if they say the solution is at 7 levels deep and the branching factor is 6 then: Eg =b^d =6^7 =27994 What nodes does BFS expand:  Processes all nodes above shallowest solution  Let depth of shallowest solution be s Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E A E Here s is our shallowest solution Know what time and space complexity is  Properties: - Complete: Yes if s is finite - Optimal: No. Yes if costs are all 1. - Time complexity( how many nodes gets expanded): - Space complexity (How big can the frontier get): Has roughly the last tier: Thus: O(𝑏𝑠) s is the depth, b is branching factor Know both space and time complexity DFS is better with space complexity and BFS is better with time complexity. From the picture above since space complexity is how big fringe can get as you can see with BFS the frontier will get very big at the bottom of search tree (triangle). Think: Deep space Dfs space complexity When would you chose DFS over BFS? Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace A A DFS Time complexity is: BFS time complexity is So why is BFS better with time complexity if both is exponential, because m is the max tiers whiles s is tiers until shallowest solution. So in general it would be less. <- Important Iterative deepening Search (IDS) Also called iterative deepening depth0first search  Combined advantages of BFS and DFS.  Get DFS’s space advantage and BFS’s time advantage How to do this: - Run a DFS with depth limit 1. If no solution - Run a DFS with depth limit 2. if no solution until Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace A e.g. Black is deleted nodes, white is on frontier, grey means already explored. Arrow thingy is node we going to expand. Cost sensitive searches  BFS finds shortest path in terms of number of actions, but not the least- cost path. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace A E  A Cost sensitive search is search which find the least-cost path.  Here the paths have different costs.  BFS will chose this path: Shortest path, but not the path that cost the least. Now let’s look at some searches which fiNds lowest cost. Uniform cost search (UCS)  is a cost sensitive search  Uses a queue (priority queue) data structure  Strategy: is to expand the cheapest (lowest cost) node 1st  Here we move down uniformly in the search tree  Finds the goal with the least amount of cost. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace A  Instead of moving down in layers like with BFS and DFS we move down non-uniformly.  Here we move down prioritizing cost.  Strategy: Expand a cheapest node 1st  Frontier is stored in priority queue. Priority: cumulative cost THINK: The time cost of standing in a queue. Example of UCS on a graph: *Ask tutor about this Start node is M and goal is F. At each step we will provide the frontier and show which node is selected for expansion. For any search we place start node at the frontier. g is the cost. Step Node expanded Frontier 1 M(g=0) 2 M E-M(7), O-M(7), G-M(10) 3 E-M C-E-M(15), O-M(7), G-M(10) 4 O-M C-E-M(15), N-O-M(14), A-O-M(12), G-M(10) 5 G-M C-E-M(15), N-O-M(14), A-O-M(12), F-G-M(18), H-G-M(14) 6 A-O-M C-E-M(15), N-O-M(14), F-G-M(18), H-G-M(14) 7 N-O-M C-E-M(15), C-N-O-M(16), F-G-M(18), H-G-M(14) 8 H-G-M C-E-M(15), C-N-O-M(16), F-G-M(18), D-H-G-M(17), J-H-G-M(18) We don’t stop even though goal path have been generated. 9 C-E-M N-C-E-M(17), C-N-O-M(16), F-G-M(18), D-H-G-M(17), J-H-G-M(18) 10 C-N-O-M N-C-E-M(17), E-C-N-O-M(24), F-G-M(18), D-H-G-M(17), Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace J-H-G-M(18) 11 N-C-E-M O-N-C-E-M(24), E-C-N-O-M(24), F-G-M(18), D-H-G-M(17), J-H-G-M(18) 12 D-H-G-M O-N-C-E-M(24), E-C-N-O-M(24), F-G-M(18), J-H-G-M(18) 13 F-G-M We only stop when we actually expand the goal node. Note: In the frontier we store paths. E.g. A-O-M is path from A to M through O and we list each path’s total cost. Also we actually expand the paths and initially a node. We actually expands on the paths. Let me show you: Step 2: We expand node M and then on the frontier is the paths E-M, O-M and G-M (Notice we list new nodes 1st and the expanded node last) : Step 3: We look at previous step (step 2) and expand in the path with the least cost, if 2 have the same cost take one to the left. Thus we expand the path E-M: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Then continue expanding path with the least cost: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E Notice that it’s the accumulative cost from the root to that node. Accumulative meaning we add all the costs from the root to the fringe. . . . Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace c is cost. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace When there are steps that cost the same then UCS performs the same way as BFS in which it expands the deepest node 1st. If all equal deep then expands the left most node 1st. - Processes all nodes with cost less than cheapest solution will get expanded - arcs meaning actions. So each action cost. Thus 𝐶 ∗/𝐸 would be how deep the cheapest solution would be  Properties: - Complete: Yes assuming best solution is finite cost and min arc cost is positive. - Optimal: Yes, it returns cheapest according to the costs. - Time complexity( how many nodes gets expanded): In the worst case: O(𝑏𝐶∗/𝐸) - Space complexity (How big can the frontier get): As seen by the red O(𝑏𝐶∗/𝐸). It’s the same Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace The good about UCS: Complete and optimal The bad about UCS: Explores options in every direction No info. about goal location Another bad thing is it expands in all directions as seen by the following picture: We use search tree to find a solution (sequence of actions that leads to goal state. Root node is initial state, nodes are states and branches are actions. Expanding the current state means to apply legal actions to the current state. Thus generating new set of states. To do this we add branches to the current state. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace This is called searching: Following up one option now and putting the other aside for later consideration. The 6 bottom nodes are leaves-node with no children which is called the frontier(set of nodes available for expansion at a given time) Process of expanding nodes on the frontier continues until either a solution (goal state) is found or there are no more states. This is searching. Search strategy is choosing which state (node) to expand next. Notice @ (c) we end up at Arad again which is called a redundant paths which makes searching algorithm fails. The frontier separates state-space graph into the explored region and unexplored regions. e.g. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace White is frontier(states can be expanded at any given time), grey is unexplored states and black is explored state. White separate grey from black. Search algorithms require data structure to keep track of search tree that is being constructed. For each node of the tree the structure contains the following components:  State  Parent: Node that generated this node. Node points to their parents.  Action: Action that was applied to parent to generate this node  PATH-COST When a tree is constructed the SOLUTION function return the sequence of actions obtained by following parent pointer back to the root. Appropriate data structure to add the nodes to is a queue. Queue functions are:  EMPTY(queue)  POP(queue)  INSERT(queue) We can evaluate an algorithm’s performance in 4 ways: - Completeness: Is algorithm guaranteed to find a solution - Optimality: Does strategy find optimal solution (path with lowest cost) - Time complexity: How long does it take to find a solution - Space complexity: How much memory is needed to perform search (i.e. store the nodes in memory) The term depth is basically at what level of the tree (how height the tree is) Successor is child(state after an action has been applied to another state) Uninformed search strategies: Uninformed means that the strategies have no additional information about states beyond that provided in the problem definition. This is done by storing frontier as priority queue( which pops the element of the queue with the highest priority, i.e. in this case with the lowest cost). Goal test is applied to a node when it is selected for expansion Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Uniform-cost search expands nodes in order of their optimal path cost. Performance: Completeness: Yes Optimal: Yes it finds the shortest path Time complexity: High Space complexity: High  Breadth-first search: strategy in which the root node is expanded 1st, then all successors of the root node are expanded next, then their successors and so on. Think Breadth is width and width if it expands if you do it the way described in the definition of it. BFS uses a FIFO queue for the frontier to ensure that it expands the shallowest node first. So how is it performance according to the criterial Completeness: Yes, it will eventually find the goal state Optimal: No, because it goes through each one until it finds the solution Time complexity: Takes a lot of time, because we go through each one Space complexity: Take up a lot of space because we make a lot of nodes, thus we require a lot of space to store it. Here the goal test is applied to each node when it is generated rather than when it is selected for expansion.  Uniform-cost search: Expands the node n with the lowest path cost g(n). This is done by storing frontier as priority queue( which pops the element of the queue with the highest priority, i.e. in this case with the lowest cost). Goal test is applied to a node when it is selected for expansion Uniform-cost search expands nodes in order of their optimal path cost. Performance: Completeness: Yes Optimal: Yes it finds the shortest path Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Time complexity: High Space complexity: High  Depth-first search: Always expands the deepest(furthers from the root/ lowest level) node in the current frontier of the search tree. Uses a LIFO queue, meaning that the most recently generated node is chosen for expansion. How this work: Expand deepest (lowest) node in the current frontier, starting with left most node. Explored nodes (white) with no children( nodes at depth 3) in the frontier are removed from memory Has 2 version: Tree-search on and graph-search(uses recursion Performance: Completeness: Tree-search: not complete ;Graph one: Is complete Optimal: No Time complexity: High Space complexity: Not high since we delete the nodes  Depth-limited search This search is like depth-first search, but we set a limit to the depth. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Here a depth limit l is defined so that it does not have an infinite state space(set of all states reachable from the initial state by any sequence of actions). i.e. nodes at depth l are treated like they have no successors. <-This solves the infinite-path problem, but introduces incompleteness if we chose l smaller than the shallowest goal. Depth-first can be seen Performance: Completeness: Incomplete if we chose l smaller than shallowest goal, i.e. l<d. d is place of shallowest goal Optimal: No, if we choose l > d Time complexity: High Space complexity: Not high since we delete the nodes The diameter of the state space of known as the maximum number of steps it takes to go from one state to any other state and it can be used to give us a better depth limit. e.g. map of cities (in reaching Bucharest problem) any city can be reached from any other city in at most 9 steps.  Iterative deepening depth-first search Search in which the depth limit is found by the algorithm. It does this by gradually increasing the limit, starting at 0 and incrementing by 1 each time until a goal is found. It combined DFS (where we delete the nodes) and BFS. Performance: Completeness: Yes Optimal: *Don’t know Time complexity: *Don’t know Space complexity: *Don’t know Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Note that the states are generated multiple times, e.g. in limit 2 and 3 state B is generated in each.  Bidirectional search Here we run 2 searches simultaneously, one from the initial state forward and 1 backward from the goal- hoping that the 2 searches meet in the middle. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Here we run 2 breadth first searches from initial state and goal state. Performance: Completeness: Yes Optimal: Yes we can find the shortest path Time complexity: Good Space complexity: Bad  Comparing uninformed search strategies Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace A E Adversarial Search  It is how to decide to act when there is an adversary (opponent) in your world.  Here we want our agent to adept to the current state (according to the opponents)  What we want is an algorithm for calculating a strategy (policy) which recommends a move from each state. This policy will be given by a function which will tell us what to do.  How is this different from a search? In a search there is a search problem and the solution is a plan/path, i.e. a sequence of actions that is guaranteed to succeed. HOWEVER, with adversarial search it won’t always work, because we can’t control our adversary Objective function  Also called utility function Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace  An objective function is a function maps the current state to some value which can be used to judge the ‘goodness’ of the state.  You get two types: Minimizer and Maximizer.  When we try to avoid loss we define an objective function with respect to loss and try to minimize the objective function. Called a minimizer  When we want reward, we define an objective function with respect to reward and try to maximize the objective function. Called a Maximizer  Tips in writing objective function:  1st write it in English  Try to keep things simple by writing general functions. And then use these function to make a total function. You can just say what the inner functions return you don’t have to explain how they do it.  E.g.: This is start state Rules:  Only 1 shop per Str  1 shop per Ave  No shop adjacent from one another. In English: 1. As many streets and avenues that do not have 2 or more shops on them 2. As many blocks with a shop on it, that is not adjacent to a block containing another block. AS many blah blah blah Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Note: For minimizer we will use ‘as few’ for the initial words instead ‘as many’ Now we do it formally using mathematical notation: For a given state S, we define the following: 1. Function A: S -> N which returns number of streets and avenues that do not have 2 or more shops on them. (N is natural number) 2. Function B: S ->N which returns number of blocks with a shop on it, that is not adjacent to a block containing another block Objective function: F(S) = A(S) + B(S) Note: For functions A and B we simply say what it does, not how it does it to simplify things. S ->N means the functions A and B maps a state S to a numerical value. Note that the streets and avenues are the lines, not the blocks. So there are 5 streets and 5 avenues. So local search generates series of successors according to the rules of the game. Rules are given by: Initial: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Note notation S’ normally means successor to state S. So means successor 1 to state S. means successor 2 to state S. Remember we can only move shops up or down. This is easy: From the state F(𝑆2’) = 9 +4 = 13 Successors are: Note S’’ means successor to S’. Move A down: F(𝑆5’’) = 10 +4 = 14 Note gona do the rest, but just show all of them like this. 𝑆5’’ is the better successor. This is solution to the problem. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Before we do the next question you must learn the Topographical features:  Local maximum: Peak that is higher than each of its neighbouring states, but lower than the global maximum E.g. So if S’’ have higher value for its objective function than its neighbouring states S’ and S’’’  The rest can be determined by the picture. In previous question we went from state 𝑆2’ which have value of 13 to state 𝑆1’’ which have value of 14 and is a solution thus it is a global maximum: To do this question I will come up with mock values which I got for the other successors in previous question. Say we got these values: 𝑆1’’ = 12 𝑆2’’ = 11 𝑆3’’ = 10 𝑆4’’ = 12 Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace 𝑆5’’ = 14, This one we calculated and it was solution to problem. Now the topographical feature would be: The purple one is the state we start form in question 6.4 Note: On the x axis we move on with successors and a solution is always a Global Max. We will have a set of states just like in a normal search There can be many players Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Set of actions and different players have different actions. Also call successor function. Tells us to which state to go to when certain actions are taken. Tells us when the game is over (like a goal state) It tell us for an end state how much it is worth to each of the players policy maps states to actions. Utility function: A utility function provides a numerical value for a final state s for player p. It is used to identify winning and losing states for a player. A zero-sum game defined as one where the total payoff to all players is the same for every instance of the game. Like Chess because every game has payoff of either 0+1, 1+0 or 0.5+0.5. Basically the sum is the same no matter the outcome. For adversarial searches we assume perfect information, i.e. the agent can see what will happen. However agents can still get the ideal strategy(tells us what moves to take to get to a final state) when playing without all the information. An agent that has perfect information will most likely outperform an agent that has imperfect information for the same problem. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace  We interested in zero-sum games  Here we have adversarial agents (opponents of each other)  If 1 agent likes a state the other 1 hates it.  There is 1 function. The blue player wants to MAX this function and the red want to MIN it. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Reasoning in adversarial search: We are going to have an agent who tries to figure out what to do. To know what to do we are going to think about the consequences of our actions. The difference is rather than the sequences of actions that I (agent) can perform, I need to think about my opponent. I imagine taking an action, then I imagine my opponent will think about what I will do. As seen in the picture we get imbedded future states. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace We also know what our terminal states are since the game defined the terminal states. Value of the state under the opponent’s control is equal to the MIN value of its children, e.g. this state will be -10 Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Value of state under the agent’s control is the MAX value of its children. So in general states under opponent’s control we minimize and states under the Agent’s control we maximize. We work our way upward. The bottom values are called utilities. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Note: The upside down triangle is MIN and the non-upside down triable is MAX The algorithm works like this: To calculate the MAX value we start with the lowest possible value and make it the max value. Then for each child (successor) we calculate the max between Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace the current MAX value and the MIN value of the successor. This is recursion. Note the red, blue, red, blue value. Here we handle the base case of the root node being the terminal state. So 1st we check if it is terminal state and then if yes return the state’s utility (bottom value) Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace So this is how the algorithm looks like in steps: So if I want to compute the MAX value of this root I got to take the MAX and MIN of a bunch of things. So far the MAX is negative infinity. So I look for the 1st child: This is a MIN node. So I need to calc the MIN if its children: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace The MIN so far is 3 The MIN so far is still 3 The MIN is still 3 and there are no more children. Now I can return the MIN value of 3: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Now at the root the MAX is 3, but there are still more children to check, so I check the 2nd child. This child is a MIN node. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace The maximum of the root is till 3, but there are still more children to check: Only after this when all children are checked I can say the MAX value of the root is 3: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Note the arrow says the root is supported by that node: Then the 3 node is again supported by the left 3 leaf: It is just like DFS so it will have the same efficiency as DFS, so same Time and space complexity as DFS. The time is bad news, but the space isn’t so bad. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Let’s see the properties using this example: This assumes a perfect player (opponenet). What if we don’t have a perfect player? See the opponent (red) forces us to go to ten. But if we don’t use MINMAX we can get the 100 which is better. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E So here if the ghosts (opponents) are perfect (master minds) then pac man is going to die. If the ghosts are just moving at random then there is a chance that we can win. So in general if your opponent is perfect (master mind) then you want to use MINMAX algorithm, if opponent is not perfect then MINMAX is not the greatest. ======================================== Evaluation function is a function used by game-playing programs to estimate the value (or goodness) of a position in the minimax algorithms. Problem with minimax algorithm and alpha-beta pruning is it still have to search all the way to terminal states which isn't desirable. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Solution is to use this function to turn nonterminal nodes into terminal nodes, i.e. to cut of the search earlier An evaluation function returns an estimate of the expected utility of the game from a given position (just as the heuristic function return an estimate of the distance to the goal) To pick a good evaluation function: -Eval func should order terminal states in same way as true utility func, i.e. winning states must EVAL better than draws -2nd computation should not take too long From assignment The question asks to use the minimax algorithm to provide the value for the root node, but since we don't have the entire game tree and no values at terminal states, we cannot use the utility values. So when we don’t have entire game tree and thus no terminal states we must use EVAL function' So with EVAL function we can determine the values for minimax if only a few levels of the search tree is given and we don't have the terminal states. Assume that player 1 is a MAX function, so root node will me a MAX node if it isn’t specified otherwise. So to do an EVAL function problem: If they give you a EVAL function with a definition (how to determine) Then 1st draw the search tree. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace (Remember top node is a MAX node if not specified). Then work out the values of most bottom nodes using EVAL function. Then for each node get the MIN value of the node's children and max value for MAX nodes. Then when they ask which nodes will be pruned then we will have to look at the values from the EVAL function. Still working with alpha beta, but using values of the EVAL function. So pruning can also be thought of logically without using the alpha and beta value. So pick a node. Then if the node is a MIN for instance and it gets a -1 value from one of its children. Now when we get to a next child. If the value of this child is > or = to -1(same value it got from the previous child) then we can prune that child and don't have to consider it. ============================================ In order to make this Depth limited search works we have to have the ability to decide whether a state that we are looking at in the future if is it good or bad. An evaluation function is a function which take a non-terminal state and return some number. We know what we want out of this number. We want the number to return the actual MINMAX value of that position, but that is not going to happen. ON average we come up with a function that if the actual MINMAX value is negative then the number returned by this function will be negative and when the actual MINMAX value is positive this function will return a positive value. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace So the evaluation function in this example would be thought up as some properties of chess (like if black has queen and white does not have queen then it’s good for black, etc.) which is calculated. The properties are functions themselves and adding these functions make up the evaluation function. Note the w1 and w2 are coefficients that say how important the properties are. E.g. the queen gets coefficient of 20 and knight gets coefficient of 10 Definition of forward pruning: The order in which nodes are examined in minimax only matter if we prune, because minimax is an exhaustive search and node orders do not matter. Pruning as in making our search shorter So let’s see if we can make our search shorter with this example done previously: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace So with the 1 st child you will have to look at all of them so see the min is 3. But with 2nd child we don’t have to. After we see a 2 we know the min will be equal to or less than 2. The guy on top will pick the max of the 3 and the < and = 2. So it will pick 3 and we don’t have to look further. Now let’s look at the next child: Here we must still go on, because the <=14 may be bigger than the 3 and root nodes want to pick max. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Here we must still go on because it might be 5 and max might pick it. So sometimes we can prune and sometime we can’t. So in general as soon as one of the MIN nodes drop below our current level’s (level 2 deep in the tree, i.e. children of the root) minimum value (3) then we can stop looking at that child. Alpha-beta pruning α= best value thus far the Maximizer on the path from the node to the root node (NOT THE BEST VALUE THUS FAR ENCOUNTERED BY THE ALGORITHM) β= best value thus far for the Minimizer on the path from the node to the root node (NOT THE BEST VALUE THUS FAR ENCOUNTERED BY THE ALGORITHM) For maximizer, when v>β then we prune AND this is called beta-cut (when we use β in the condition v>β ). AND for minimizer when v< α then we prune and this is called alpha-cut. Smaller or equal, bigger or equal Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace maximizer, when v>β, think: Maximizer has to do with α, so opposite is β and β has to do with min values, thus opposite think larger Example: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Note that the value (value would be the worst possible value since we don’t have a value yet). Thus we say it is –INF(infinity) for maximizer or +INF for minimizer. Note the 1000 should actually be INF. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace See the value of 5 gets passed up. Thus the node gets the value 5. Also now the best value thus far for a maximizer is now 5, thus α must change to 5. We pass the 5 up to that node. Now the value of that node is 5. Also β must change, since the best value for minimizer is 5. 5 is better than +INF (or in this case 1000). But α do not Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace change, because α is best value from this node to the root node, NOT the best value the algorithm has encountered thus far and also it’s minimizer and we don’t change the value of alpha when we change v of minimizer We do not pass the value down, So we don’t pass v=5 down. But β is 5, because β is defined as the best value for a minimizer on the path from this node to the root node and as you can see the path from this node to the root node already says that β is 5 Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace So, passed the value 8 up and v=8. BUT notice that α does not change, because we pruned. When we prune it doesn’t change. For maximizer, when v>β then we prune AND this is called beta-cut (when we use β in the condition v>β ). AND for minimizer when v< α then we prune and this is called alpha-cut. Smaller or equal, bigger or equal Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace WE bring 8 up, but since it is a minimizer 5 is better than 8, so the value doesn’t change. Also, α doesn’t change since we dealing with minimizer Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace 10 is better than –INF(-1000), thus we change v=10. ASK why doesn’t α change? (Note that α does change if you are using the video’s algorithm. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Nothing change, since 10 is not better than 5 for minimizer. This used to be root node: . The v change cause 5 is better than -1000 and since it is maximizer we update α as well. We do not update β because we only update it when a minimizer node’s ‘v’ change. Since we starting at new node the best possible value for the minimizer is the worst possible value thus it is 1000. Thus β is 5. We do not have a value yet that was passed up so, its value is the worst possible value which is 1000. The best possible value for a maximizer from this node to the root node is 5 (since the root node is maximizer and its α value is 5), thus α is 5. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace We only know value of α, since root node’s α and alpha is best possible value for maximizer on the path from this node to the root node. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace -5 is better than -1000 for maximizer, thus v changes, but -5 is not better than 5, thus α do not change. 3 is better than -5 for maximizer, thus the new value is 3. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Pass the value 3 up, so the value (v) change to 3. But since v< α for minimizer, thus we prune and when we prune we don’t update β or α. The value for root node was . The values don’t change since v=3 is not better for the maximizer which have v=5. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E Informed searches Uninformed Search  Explore the tree in a systematic way, like top down, or left to right as with Breadth First Search and Depth First Search.  You are unaware of where the goals are. e.g. uninformed.  It basically expands on everything and that is what we want to improve upon. Thus we use informed search informed search  DEF: It is when you add information to the search of where the solution might be, so that they can find the optimal solution without expanding so much nodes.  In these searches we see if we are getting close to our goal.  Heuristics  Greedy Search  A* Search  All the search algorithms are the same except for frontier strategies. - Conceptually, all frontiers are priority queues (collection of nodes with attached priorities - Practically for DFS and BFS, you can avoid the log(n) overhead from and actual queue with stacks and queues. What this means is for these you can just use stacks/queues for the frontiers - Can even code one implementation that takes a variable queueing object. A heuristic is:  A function that estimates how close a state is to a goal  Designed for a particular search problem. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E  It will look at the world and what state you are and say hey you are far from the goal, or you are close and return a number corresponding to how far you are.  How do you see whether you are close or not? Examples are: Manhatten distance is path directly to goal, either allowed to move diagonally or not. Also, you ignore obstacles.  More difficult when we are not dealing with distance. Example is: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace A E Heuristic is 6 since each horizontally or vertically move costs 1. Thus as you can see from ‘U’ you must move 6 time (2 horizontally and 4 down). And you are not allowed to move diagonally. Heuristic is normally represented by H or H(x) How to prove that consistent heuristic is admissible: Admissible means: DEF: Admissible is when Heuristic never overestimates the cost of reaching the goal, i.e. when heuristic is smaller or equal to the actual cost A heuristic h is consistent if: its estimate cost of the goal [h(n)] is always less-than-or- equal to the sum of the actual costs [c(n,n’)] to any successor node plus its estimate from that node to the goal [h(n’)]. n is any node, n’ is neighbour node of n. h(n) mean heuristic from node n to goal. h(m) = 0 if m is the goal heuristic tells us how far we are from goal. A heuristic h is admissable if: estimated cost is less than the actual cost. So how to prove with steps: We give proof by induction Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Base case:  Assume goal is neighbour of n, i.e. n’=m thus h(n’) = 0  Thus since h is consistent: h(n) c(n,n’) + 0 Thus h is admissible Inductive case:  Let n’ be a node on shortest path between n and m, k steps from m, and say h(n’) c(n’,m).  Since h is consistent, We proving that a consistent h is admissible so we can assume consistency  Thus h(n) c(n,n’) +c(n’,m) = c(n,m) replace with since is bigger than so if we put a bigger term on the side that is bigger than, then it won’t change it. AND true, because is cost from n to n’ and is cost from n’ to m. Thus adding them up will yield cost from n to m which is  Since n is k+1 steps from the goal, we conclude that the heuristic is admissible. n is Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E greedy search  Expand the node that seems closest according to our heuristic  Example: Heuristic function is straight line distance to Bucharest. We want to go from Arad to Bucharest. Note: That this search will not take the shortest route. The shortest route is through Rimnicu Viicea and Pitesti to Bucharest Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Sibiu is shortest according to Heuristic function (shortest straight-line distance to Bucharest). So expand Sibui As you can see with greedy search there is a chance that we don’t find the optimal solution  Strategy: expand a node that you think is closest to a goal state Heuristic: estimate of distance to nearest goal for each state Takes you to a goal, but it is the wrong goal Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E greedy search is only good as its heuristic and heuristics isn’t perfect A* Search  Best search which takes all the ideas of the previous searches and blend them together.  It combines Uniform cost search (which is slow and steady so its finds the solution) and Greedy search( is fast, but can run into problems)  A* graph search requires that the property of a heuristic depends on the conditions on h(n) which is called the heuristic function, and the basic condition of the heuristic is admissible Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace  An admissible heuristic Never over estimates the cost to reach the goal, thus it is optimistic explanation of why if h(n) is admissible then A* is an optimal search  Example: Start state is S and end state is G, h is heuristics at each point. The other numbers are the action costs. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace A So A* adds them together g(n) is the path costs To get f you add heuristic(h) and path cost (g) e.g. from S to ‘a’ f(n) would be 1+5 = 6 Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace A Do we stop when we enqueue a goal (put goal state on queue)? No we don’t because it might not be the shortest path. In this example otherwise we would go through B which is not correct path. We only stop when we dequeue a goal, i.e. when we expand the goal node Example of A* search: Question: Use A* search on the graph. G is start and goal is H. Heuristic is: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Answer: Step Node expanded Frontier 1 G(g=0, h=19, f=19) 2 G F-G(g=8, h=18, f=26), M-G(g=10, h=12, f=22), H-G(g=4, h=0, f=4) 3 H-G F-G(g=8, h=18, f=26), M-G(g=10, h=12, f=22), D-H-G(7,13,20) J-H-G(8,7,15) The algorithm stops at step 3 since the goal was expanded. or popped of priority queue. : So why is g=4 and h=0. We look at node H. H in heuristic table is 0 and from H to G the cost is 4. That is why. In step 3 from step 2 since H-G have lowest f value we expand it. In this example it A* search choses non optimal (longest path) Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Here is why: On queue: g(path cost) h(heuristic) total This is on queue: S -> A 0 0 0 S-> G 1 6 7 S->G 5 0 5 Now when we pop last queue then our goal is there, so our goal has been popped off thus we stop. But it is not optimal path. Path through A is optimal. Problem is: Heuristic is bigger than action cost. 6 bigger than 3. It over estimated (heuristic) the cost. We need our estimates (heuristic) to be < than actual costs! Idea: Admissibility  Method of getting our A* search correct  Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace  (Pessimistic) inadmissible heuristic lies to you and say it costs more than it actually does. It says you are father from the goal that you are. This heuristic is bad (bad outlook on life, thus pessimistic)  (Optimistic) admissible is one that underestimates the true costs. So heuristic is < or = to the actual cost. It never overestimates the cost to reach a goal.  For optimality h(n) needs to be an admissible heuristic For consistency: i.e. the heuristic h(n) is consistent if, for every node n and every successor n’ of n generated by action a, the estimated cost (heuristic) of reaching goal from n is no greater than the step cost of getting to n’ plus the estimated cost of reaching the goal from n’ A heuristic h is admissible (optimistic) if: See this say heuristic is smaller or equal to the actual cost. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E DEF: Admissible is when Heuristic never overestimates the cost of reaching the goal, i.e. when heuristic is smaller or equal to the actual cost, Inadmissible, when heuristic over estimates the cost of reaching the goal. e.g. Rules: Cost moving 1 horizontally or vertically is 1. Cost of moving diagonally is 2. In this example the heuristic is admissible because it will never overestimate the cost of reaching the goal. Where h*(n) is defined as the true optimal cost to a nearest goal Coming up with admissible heuristics is most of what’s involved in using A* search in practice. Let’s see why A* is optimal: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Ancestor is of a node is node that is higher up that the other node. It’s like the parent, then parent, then another parent. If it happens that n will be expanded before B then we are fine, because n will get expanded and another node until we get to G since n is ancestor of G. and if G expands before B then it means that G will get popped of 1st, because it will no longer be in the fringe (frontier) Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Uniform-Cost will search in jagged patterns, but it will still go from top to bottom basically. A* is gona go deep near the goals and shallower away from the goals. Illustrations of searches: Note the dark blue has more cost to move through it. BFS: Because it expands outwards in every direction ignoring cost Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Uniform Cost search: because it also expands all around, but faster in the lighter area Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Greedy search: Because it goes straight for the goal but not optimal Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace DFS: Expands deeper in 1 direction 1st. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace A* search: Because it finds the most optimal solution. It takes cost into consideration Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Creating Heuristics: A relaxed problem is when we take our original problem (which is hard) and we change the problem in a way that we make things the same or easier. E.g.: Imagine there is straight line from Arad to Bucharest, so the easiest path to take is the straight line: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Here we change it so Pac Man can go through walls. We change the problem, even though it’s not correct it’s a way that we simplified the problem. Let’s do an example:  Actions are any square next to the blank you can move left, right, up or down.  Costs are all 1. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Heuristic: Number of tiles misplaced. This will return a real number so it is a Heuristic. This Heuristic is admissible because every move in the optimal solution either fixes one of these mistakes, but it can’t fix more than one. Because all of them are out of place when you can remove the pieces. We making the problem simpler. Let’s look at another way of simplifying the problem: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Here we can slide the “1” 1 left and 2 up to get it in its place. Called Manhatten distance. Here is the amount of steps. It isn’t bad. Yes, it is admissible. We would have too many nodes expanded thus it is expensive to compute. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Better heuristics mean you have to expand fewer nodes on the other hand each node is expensive because you have to compute to find the heuristic itself. If it is true for ALL n and a heuristic is always bigger than c than h of a dominates h of c Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Here we retrace our steps and avoid work we have already done. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace See the work gets exponential. See we should not do node e again. The circled branches are the same. Only the one should be done. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace You get Tree search which is the previous searches we have discussed and then we get graph search. A* search algorithm can then be implemented using Tree or Graph search. The set that keep track of which nodes was already expanded are the “closed set” By refusing to expand certain nodes in the tree can it make it incomplete? Answer is NO! since we only don’t expand the nodes that have already have been expanded. Let’s see with an example: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E State space graph A way of searching with a graph instead of binary tree. Each node is state. Arrows is path from 1 state to another state. You can use all the searches, BFS, DPS, etc., with these graphs. The red is the heuristic (cost) The red is the closed set (it represents nodes that were already visited: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Note that cumulative total cost (the 3) is cost from S to C (we add the costs) We have our goal G, but the goal hasn’t come off our queue so we continue. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace We can’t expand C because it is on the CLOSED set. Thus we stop and choose the path through B. Now we choose the path through B. But note that this it’s a mistake because its choosing the non-optimal path. The path through A is actually the optimal path. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace The problem is with the 4. It is not admissible, i.e. it over estimates the cost. See from A to C actual cost is 1. Then from C to G the heuristic tells us the cost is 1. So from A->C->G the cost is 2. But the heuristic at A say that from A to G it is 4. It wasn’t inadmissible, so it’s still admissible so it’s fine. So, the problem is that it is inconsistent compared to the other heuristic values around it. Note the red is the heuristic cost (guessed/optimistic) and the green is the actual cost from A to C. So this says the actual value from A to C plus heuristic cost from C to the goal should be bigger than the optimistic cost from A to goal. It makes sense since the left part have an actual cost in it in and the left side only have an optimistic (better than what we would expect) How do we fix it: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Fixed it by making the 4 a 1. Now consistency of heuristic holds. 1 1 1 Basically this must be true of we transform this formulae: Important information: a heuristic function is said to be admissible if it never overestimates the cost of reaching the goal, i.e. the cost it estimates to reach the goal is not higher than the lowest possible cost from the current point in the path. Admissible: heuristic is cheaper than reality (actual costs) Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E Summary: CSP (constraint satisfaction problem)  Previous search algorithms we were looking for the path that gets us to the goal.  Now we dealing with searches that the goal itself is important, not the path.  Here is the search problem we already dealt with like A* search and UCS, i.e. Standard search problems: Successor function return the successor state given a state. How to solve CSPs with example: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace These are the aircraft Step 1:1st define the variables: To define the variable it is 'thing' that we can assign values to. So for example if they say consider the problem of determining to assign aircraft to a fleet of flight. Then variable are the flights since we gona assign aircraft to flights. Example: Step 2 Then determine the domain. The domain are the values that the variables can be assigned to. i.e. the 'things' that can be assigned to the variables. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Domains are written in the form: Dx={value1, value2, etc.} Step3: Then define the constraints Constraints are normally written like value1 != value2 and will be determined by the problem. For this problem just look and see that the flights can’t overlap. E.g. QQ144 can’t be equal to QQ256 since the flights overlap. Or they can’t happen just after each other. Planes need to be refuelled. Domains don’t have to have the not equal sign. Example: 𝑀11 + 𝑀12 + 𝑀13 = 6 Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace A constraint graph can also be drawn. Here the values are the nodes and the constraints are the edges. Step 4: Then provide solution. Normally will be asked to use the Minimum remaining Values (MRV) heuristic and at each step to establish arc consistency ( what this mean is to not go against the constraints). Steps of MRV: -Assign any value to a variable, then according to the constraint graph and this chosen variable list the domains of each variable. See the domains gets restricted by the chosen value. The values connected to QQ144 (the chosen variable), i.e. QQ108, QQ512, QQ256, QQ134, in the graph can’t contain the XAX- 143 now, but the rest can still contain this value. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace -Then select any of the variables with the least domains and do another assignment. According to assignment and constraint graphs list the domains of variable that have not been assigned.  -Repeat this process. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E Example: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Solution: i) The variables in CSPs are the things that can be assigned variables to The variables are the cells: Variables: X = {𝑀11, 𝑀12, 𝑀13, 𝑀21, 𝑀22, 𝑀23, 𝑀31, 𝑀32, 𝑀33 ii) Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Domains are the values that the variables can contain. 𝐷𝑥={1,2,3} Each cell can take on the values 1,2 or 3 iii) 𝑀11 + 𝑀12 + 𝑀13 = 6 𝑀21 + 𝑀22 + 𝑀23 = 6 𝑀31 + 𝑀32 + 𝑀33 = 6 𝑀11 + 𝑀21 + 𝑀31 = 6 𝑀12 + 𝑀22 + 𝑀32 = 6 𝑀13 + 𝑀23 + 𝑀33 = 6 𝑀𝑖𝑗 + 𝑀(𝑖+1)(𝑗+1) + 𝑀(𝑖+2)(𝑗+2) = 6, i€(1,2,3), j€(1,2,3) iv) Consistent means that all of the assignments (domains) should satisfy the constraints. This is also what is called arc consistency if domains satisfies constraints. 𝐷𝑀12= { 2,3 } Why? Because to make 6 each row and column should have 1,2 and a 3. So if a 1 is picked we need a 2 or 3. 𝐷𝑀13= { 2,3} Same reason as the above one 𝐷𝑀21= {2,3} 𝐷𝑀22= {1,2,3} 𝐷𝑀23= {1,2,3} 𝐷𝑀31= {2,3} 𝐷𝑀32= {1,2,3} 𝐷𝑀33= {1,2,3} Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Constraint satisfaction problem(CFP) A state is a set of variables that take on values (domain). Goal test now is set of constraints that tell you what combinations are allowed on a subset of variables. Here we want to assign a colour to a states and make sure adjacent states don’t have the same colour. The variables are the states. These are the values the variables can take on. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace With constraint we write some procedural (technical) way of checking a constraint. So this is one constraint. We check that WA must not be equal to NT, because these states are next to each other. Explicit mean we actually write down all the allowable combinations So solution you need to assign a value to each variable and all the constraints need to be met/satisfied. Remember queens in the same row or column can attack each other. Also queens can attack each other diagonally. It is a position on the check board. Each variable (position on the chess board) can either be occupied or empty. Thus domain is {0,1} For constraints we can’t have queens attack each other. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace This says for any row (i) we look at all columns j and k and say the possible values are (0,0), (0,1) or (1,0). This basically says that there can’t be 2 queens in a row. Remember corresponds to a position on the board in row I and column j. So this constraint takes care for threatening across rows. All the constraints: These constraints aren’t enough because we allowed all of the board to be 0. So we need another constraint: Here is another formulation of the queen problem: So Qk says where the queen will be in row k. And give it a value of 1,2,3,4 corresponding to columns. These indicate a column For all i, j, rows they should not be threatening. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Remember Q1 means row 1 and Q2 means row 2. So if (Q1,Q2) is (1,3) That means queen is in row 1 column 1 and another queen is in row 2 and column 3. Q1=1, Q2=3. One thing we do is draw the graph associated with the problem and it is helpful. This is the Map colouring problem’s constraint graph Basically we connect all of our constraint. Here are all the constraints: WA ≠ NT Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace WA ≠ SA NT ≠ SA NT≠ Q SA ≠ Q SA ≠ NSW SA ≠ V Q ≠ NSW NSW ≠ V Now for constraint graph we simple represent all these constraint with a picture. Each variable (e.g. WA,etc.) is related to other variables via constraints so you just connect the variables via the constraints. Example of 5 queens problem’s constraint graph Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace See the constraints which are the edges (like Queens 1) does not give information as to what the constraints are. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Discrete variable is variable that can only take on a certain number of values. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Now we will see how to solve the CSPs. So here we use the searches we have uses thus far and use them to solve CSPs. But we will improve upon this. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace All solutions are at the bottom. So BFS would not do very good. DFS is good since all goals are at the bottom and the search goes deeper. Here is a visual example of DFS on a CSP: Assume we start at the bottom left. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Assuming the next on is middle bottom node. It assigned it blue again: Immediately it makes a mistake, because 2 blues are not allowed to be next to each other. So let’s discuss a new search:  Backtracking search is the basic uninformed algorithm for solving CSPs  It takes 2 ideas: Have to consider all possible values for a variable. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace So with the previous problem we should have immediately noticed it was wrong when assigning the 2nd node the blue since the 1st one was blue and the constraints said that it was wrong. Same example but with backtracking: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Now it is not going to work out because the next one (middle right) can’t be any of the colours. So we are going to back track: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace . . . . . . Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Here are some general purpose ideas that give huge gains in speed: Filtering is going ahead of the backtracking search and figuring out elements in the domain of the unassigned variables (not yet assigned) which can be safely eliminated. 1 st approach: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Here we check the unassigned variable and if some values conflict with the constraints then we are going to cross them off. e.g. Let’s say we assign red to Western Australia (WA). Initially the variable and the possible values look like this: Now we look at the states next to WA and see which values need to be crossed out from them. E.g. In NT and SA red value needs to go. After we take away red from NT it will look like this: Now let’s make Q green: Now we might do this: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Problem, because now SA don’t have any legal values. Now we will need to backtrack. Say we are here: We assigned WA with red and then Q with green. So if we assign both blue to NT and SA it is allowed with the allowed variables, but won’t yield the solution. So Forward checking doesn’t know about this (problem between 2 unassigned variables) So forward checking does not deal with problems between unassigned variables. We would like to know this: One type of constraint propagation method: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace An arc is a new idea in Filtering. It goes from a variable (say x) to another variable (say y). For an arc to be consistent is essentially if there aren’t any constraints violations lurking there. Example: So we look if we can go from NT to WA. This constraint is not consistent, because we can’t pick red for NT. Remember it says for any X in the tail (so meaning we should be able to pick any value for the tail but we can’t pick red. If we get rid of the red then it can become consistent: So we can delete values from the tail to make it consistent. This arc is consistent: It’s consistent because Q is not next to WA, so it can take on any value without violating a constraint. Remember an arc is a directed idea. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace You always delete from the tail of the arc to make it consistent. Lets look at this example: Both NT and SA can’t be blue, so one of them must be red or green. Thus, we can never get to the goal state from this position. So let try and find algorithm which will detect the failure right away. So let’s look at the arcs and delete stud that will yield inconsistencies from the tail: So here check the tail and ask yourself is there anything in the tail that guarantees us failure, if yes then it is incnosistent. So this is consistent, because if I pick blue in V I can pick red in NSW, if I pick red in V I can pick blue in NSW. If I pick green I can pick either blue or red. Thus this arc is consistent. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace This arc is also consistent because nothing here can guarantee us failure. If we pick blue we can pick red in V. This arc is not consistent. We can pick blue and it will give us failure. So we must remove blue. So we delete the blue: Now if we come back to this arc: It stopped being consistent, because something disappeared. Now we need to delete red again: The algorithm for enforcing our consistency: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Arc consistency will not narrow you down to one solution Example: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Here every arc is consistent (if you assign tail blue then head can be read and other way around) thus it is arc consistent. But there are no solution for this. SO arc consistency does not guarantee a solution. Arc consistency is only part of the back track algorithm, it is a filtering algorithm. In ordering we have choices in our backtracking search Here we chose the variable with the least amount of variables remaining. Example: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace From here we chose the middle bottom region because it only has 1 value left, i.e. it can only be made blue. Basically you should take the one that is the most constraint, which have the minimum amount of values left. Do the hard values 1st, because you will eventually have to do them and it will decrease our backtracking. This is the opposite of min remaining values Here we pick a value that rules out the fewest other values. E.g.: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace So here we have a choice to make the top right blue or red. By making it blue the other states around it becomes more constraint than making it red. Think when you make it blue the middle bottom state have no states left so making it more constraint. Logic Ɐ ⱻ Meanings: In , the premise is and the conclusion is |= sign means entailment or logical consequence. The conclusion is a consequence of the premise. Thus, the premise must be true if the goal/conclusion. Formal definition is ========================= not(¬): means not and(^): conjunction or(v): disjunction implication(=>): It implies, also knowN as if-then statements biconditional(<=>): if and only if anbd can also be written as '3 equal signs' Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E E A resolution is a powerful rule of inference for propositional logic and a clausal sentence is either a literal or a disjunction of literals. However, the resolution closure is a rule that govern a set of clauses to know whether the clauses are satisfiable or not. If a set of clauses are unsatisfiable, the resolution closure of those clause contains the empty clause. Conjunction NF: p253 Chapter 8 Writing in FOL: Example of vocabulary: Note: Both predicates and constants need to be in singular. Quantifiers and let us express collection of objects or general object. Universal quantifier : means all the objects. Pronounced “For all” Existential quantifier : Use to make statement about ‘some’ object. Terms such as “There exist an x such that…” or “For some x…” A variable x refers to any or all objects. E.g. Nested quantifiers: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace e.g. “Brothers are siblings”: So another way of expressing the phrase is saying: All brother are siblings (‘are’ normally goes with =>) and we can express it also: If people are brothers it implies that they are siblings. People are all and x and y are brother. e.g. “Everybody loves somebody”: So x loves y, but x has to do with everybody which is and y with somebody which is e.g. “there is someone who is loved by everybody” e.g. “There exist a lawyer all of whose customer are doctors” Make layer p and the customers q. Note that this is implication. It implies that if customer then you are doctor. How to read this: There exist a Lawyer and all customers are doctors. (Note All are something means implication. e.g. “All greedy kings are evil” if you greedy and you are a king, then you are evil e.g. With this vocabulary: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace “Anyone who studies or is lucky, passes their exams” So here it says they pass exams and they didn’t say which, so we should also use a variable for it and put it with the Universal quantifier. Tips:  When they say Emily (person’s name) is a doctor or a surgeon. Note that ‘or’ in English means one or the other, not both.  If they don’t give names then you have to use variables to substitute the names  When they say ALL something is something. We use implication symbol. Also you can say it in other words. E.g. All surgeons are doctors. Another way of saying this is If anyone is a surgeon then it implies that he/she is a doctor as well. E.g. Emily has a boss who is a lawyer. Saying it in other words: There exist a person who is both Emily’s boss and who is a lawyer. Now it’s easier  A ‘but’ in English means a ^(AND) in FOL  If they say if something is blah, Piet won’t blah2. This is implication and with implication even if they say something then you should use Universal quantifier. E.g. Ax( Poisonous(x) => !Eats(Asale,x) ) Note that implication you must use A, not E. because it implies that if anything is poisonous, he won’t eat it. You must know how to provide a vocabulary: E.g.: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Predicate. Pass(x,y) : Person x passes subject y Predicate. Win(x,g) : Person x wins game g Win, not wins. SINGULAR Property. Happy(x): x is happy Predicate. Study(x): x studies Study, not studies. Remember singular Property. Lucky(x): Person x is lucky Constant for a subject: History Constant for a person: John Constant for a game: Lottery Translate these into FOL using this vocabulary 1. Am( (Pass(m,History) ^ Win(m, Lottery)) => Happy(m) ) can’t use x or y since it is used in vocabulary This is wrong because you can’t use the same variables as the vocabulary. Use different variables for each sentence. This is correct: 2. Az (Study(x) v Lucky(x)) => AyPass(x,y) Correct, but rather leave the quantifiers outside the brackets: 3. ! is not sign I use !Study(John) 4. Lucky(John) 5. Av(Lucky(v) => Win(v,Lottery)) Chapter 9: Inference in FOL Propositional vs first-order inference Inference rules for quantifiers Infer means deduce Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Say we start with “all greedy kings are evil”: By using the Universal Instantiation (it says we can infer any sentence obtained by substituting a ground term (term without variables) for the variables) we can infer any of the following sentences: So basically taking quantifiable phrase and replacing variable with term without variable (ground term) General rule is . This says from the quantifiable phrase we can substitute variable v with ground term g. Existential Instantiation Here variable is replaced by single new constant symbol. Rule: k being a constant term. e.g. we can infer the sentence C1 must not be in knowledge base. For example: C1 can’t be Doctor, or Emily Note: Universal instantiation can be applied many times to produce many different consequences. Existential Instantiation can be applied once. Reduction to propositional inference A universal quantified sentence can be replaced can be replaced by the set of all possible instantiations. E.g. Suppose our knowledge base is: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E Then we apply UI (universal instantiation) (process of replacing variables of universal quantifiable phrases with non-universal quantifiable phrases) to the 1 st sentence using all possible ground-term substitutions from the vocabulary of the knowledge base: Ground terms substitutions: Unification and Lifting How to convert a FOL statement to clause form/CNF. CNF/clause form means: Predicate V Predicate V Predicate … OR (Predicate V Predicate) ^ (Predicate V Predicate) Steps to convert PL to CNF (conjunctive normal form): Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E e.g. Convert to CNF: Then: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Note: it’s all in the form so Predicate v Predicate v predicate. Also we have to drop universal quantifiers Note the use of the triple = sign. It means its equivalent. Note: From the start we can get rid of the quantifiers Another example: We got this in the form (predicate v predicate) ^ (predicate v predicate) Another example: 2. !(study(y) v lucky(y)) v pass(y,z) !study(y) ^ ! lucky(y) V pass(y,z) I am allowed to put bracket around a ^ : (!study(y) ^ ! lucky(y)) V pass(y,z) Now use the rule, i.e. multiple pass(y,z) into the bracket, this is distributive rule: (!study(y) V pass(y,z)) ^ (! lucky(y) V pass(y,z)) Now these can actually be written separately: 2. !study(y) V pass(y,z) 3. ! lucky(y) V pass(y,z) So number 2 have become number 2 and 3 and this is used in resolution with refutation Another example: A  (B v C) (A => (B v C)) ^ ((BvC) => A) (!A v (B v C)) ^ (!(BvC) v A) (!A v B v C) ^ (!B ^ ! C) v A) Note: !A v (B v C) I can just take the brackets away (!A v B v C) ^ ( (!B v A) ^ (!C v A)) since these are all ^ I can drop the brackets Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace A (!A v B v C) ^ (!B v A) ^ (!C v A) Now since we have a ^(disjunction) of ‘X v X’(literals) we can stop How to use resolution/refutation to prove something: 1st we must learn definitions: ======================== In , the premise is and the conclusion is |= sign means entailment or logical consequence. The conclusion is a consequence of the premise. Thus, the premise must be true if the goal/conclusion. Formal definition is ========================= Now the example: 1 st we convert the premise and the negation of the goal to CNF, and then apply the resolution rule to try to attain the empty clause. Converting the premise: Converting the negation of the goal/conclusion to CNF The goal: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Remember that if we have (X1 ^ X2) v (X1 ^X3) then we can undistribute Now we take the clauses of both the CNF forms of the premise and negatated goal and write them underneath each other: You see the clauses are between the ^ of the CNF Now we apply resolution to pair the clauses that contain complementary literals, as many times as needed to get the empty clause: Note you are allowed to pair it with newly created literals/statements. Since we attained the empty clause we proved that Another example: 1 st convert all statements to CNF, i.e. clause form: 1. !P v !Q v R 2. !T v Q 3. !W v P 4. !R Nothing needed Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E E Then negate what we are trying to prove and using resolution with the CNF form statements we try to get the empty clause 1. !P v !Q v R 2. !T v Q 3. !W v P 4. !R 5. W Negation of goal cant write W ^ T 6. T Negation of goal 7. P 3&5 8. Q 2&6 9. !P v !Q 1&4 10. !Q 8&9 11. Ø 8&10 Thus we have proven W => !T since we arrived at the empty clause How to show that a sentence in not valid: Steps: 1. Draw a Truth table and show that there exist a possibility where the sentence isn’t true, i.e.e where there isn’t a 1. Example: Big Dumb ¬Dumb Big ^ Dumb (Big ^ Dumb) V ¬Dumb 0 0 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 The sentence is not valid because there exists a world where the sentence is not true. The sentence is satisfiable because there is at least 1 world where the sentence is true. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace How to use resolution refutation (basically same as using just resolution) to prove: Use resolution refutation to prove that John is happy: using these clauses: So with this example we will negate the goal and then try to reach a contradiction. Steps with example: 1. 1st write down the assumption. They will be the clauses: 2. Then negate the goal: 3. Convert negated goal to clause form (CNF form) It is already in CNF form 4. Add the resulting clauses, i.e. the assumptions. To do this if you have ¬A in clause 1 and A in clause 2 then you can add the clauses. So this says we added clause 1 and 3. See both clause 1 and 3 have ‘Pass’ predicate. But the 1 is negated so you can add them. Let’s call this the combining predicate Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Note that with the combining predicate the 1st and 2nd constants aren’t the same. e.g. is not the same as . So we have to make them the same. Thus, we substitute by making them the same. So 1st constant we have to do and 2nd constant we have to do . Here we add 5 and 8 using combining predicate Lucky. Need to make Lucky’s constant the same by the substitution of {John/p} Join 9 and 7 using Happy. Happy’s constant is the same thus no substitution necessary. 5. We do this until we reach a contradiction. See we have no reached a contradiction with 10 and 11 since the 1 is not the other 1. We have reached a contradiction which proved that john is happy. Converting a Boolean function to a decision tree Steps with an example: 1. So make initial decision tree from the Boolean function. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Note: Start at X1 node. Then level 1 is X2 node and level 2 is X3 node. Consider this path: Here we have X1=0, X2=0, X3=0. Look at table. This yield a 1 so put a 1. Consider this path: Here X1=0, X2=1, X3=1. In table this correspodns to 1. So put a 1 at the frontier (leaf) 2. Simplify the decision tree by combining leave nodes: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Note: Both of the node’s leaves are 1, so we can replace the node with the values (leave): 3. Now we pick the sequence in which the variables are to be evaluated: This graph is in sequence x1, x2, x3 regarding to the variable. Now we have to show all other sequences of variables: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace These are all the sequence orders that we have to represent the decisions tree in: X1, X3, X2 X2, X1, X3 X2, X3, X1 X3, X1, X2 X3, X2, X1 So showing the sequence: X1, X3, X2: So here X1, need to be at level 0, X3 at level 1 and X2 at level 2 So showing how we got the values for this decision tree: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace X2, X1, X3: X2, X3, X1: X3, X2, X1: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E X3, X1, X2: Gain values in decision tree construction: When constructing decision tree without the benefit of gain values, the order in which we evaluate the variables is important, because it may be possible to combine leaf nodes with similar values to produce a smaller, more compact tree. So constructing with gain values we have to check the order in which we evaluate the variables Entropy Measure of how quickly the particles inside object is moving Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace It can also be applied to mathematics Example: Here Entropy is ion how many ways can I arrange my set. The more you ca n arrange your data set the higher Entropy Think of enthalpy as in how many ways can we arrange the set. BUT THERE IS MORE PROCISE WAY BASED ON INFORMATION Same example: Here we are picking a ball. What information do we have of picking a ball? Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace So with the 1 st one I know exactly what I am picking (you always picking red ball), Thus high knowledge which corresponds to low Entropy. We come up with a better definition for Entropy with a games: Game is taking 1 ball out at a time and putting it in order. We put ball back so repetition is allowed. Say this is the order we got: Now if we do it again and we get this same sequence we win, otherwise we lose. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Going get to our buckets: What is the best bucket to play the game? Obviously it is the left one. Right one is the worst. Now let’s go back to this bucket: and calculate the probability of winning. Draw ball: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace What is probability that the ball is red? It is 0.75 since there is 3 out of 4 red balls. Draw ball: So now if we put the balls back and redraw and check if we get the same sequence. These events are independent (since u putting balls back) and when it is independent then Probability is product of all the probabilities: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Let’s see if we play with this arrangement: Playing with this arrangement: Let’s summarize probabilities of winning: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Using products is bad, because if you have a big sequence and you multiplying a lot of decimals then you going to get a really small number: So we use SUM instead of products. How do we turn product into SUM? Ez use log. Use this identity: So using the specific function out products can become sums: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace How to go from 1 to 0: −𝑙𝑜𝑔2(1) = 0 Also: −𝑙𝑜𝑔2(0.75) = 0.415 Then finally the Entropy is the average of the sums: We can write the general formulae of Entropy: The formulae means it’s a logarithm of a product where the product is a probability of a bunch of events that are independent General formulae of Entropy: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Note: is probability of the red and is the probability of the blue. So formulae is basically log function with probability of 1(red) + probability of the other (blue). And the log function is −𝑙𝑜𝑔2(𝑃). Also log function have probability as coefficient as well. Example using the formulae: Here we have 2 classes (red and blue), but what if we have more classes. Lets look at another example: Still we are playing the game if picking letters and putting them in a sequence. The sequences: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Now we have 4 classes, i.e. red, blue, green and black Let’s order them in terms of Entropy: So let us calculate probabilities: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Note: Using the formulae we apply the log function different type of probability. SO if there are 4 different types of probability we need 4 terms. Here we only have 1 probability so the formulae is only going to have 1 term in it. Note that 8/8 makes 1. Let us summarize: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Number of question you need to ask is the Entropy: Let’s say you picked a letter then you can ask 4 questions: But question 4 is unnecessary, because if you say ‘no´ to question 1,2 and 3 then you know it will be question 4 automatically. Therefore we need 3 questions. Let’s see how we deal with this sequence: Dealing with this sequence: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Instead of asking the number of questions there is a smarter way: You can do a binary search: We can say is it A or B? A? means: Is it an A and then if it is yes then it is A. What is the average number of questions we could ask? Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Put the probabilities on the leaf nodes. So the level corresponds with the number of questions. See this: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace See to follow the red line we asked 2 question. And then we multiply the probability with the amount of questions asked. Then we sum them all. Let’s do sequence 2 with the same approach: We have 2 question for every scenario: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Here letters are differently distributed. Average number of questions: But we can do better: So better question to ask is. Since A appears a lot we ASK is it A? Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Since A appears half of the time in the sequence we say if yes then just A or other half will be BCD. Now only in BBCD, B appears half the time in BBCD so we ask is it B, and yes will be half of it, so yes will go to B: Now finally only 2 left so we ask the next available 1 which is C: Add the probabilities: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace See for A (Which have probability of ½) we only ask 1 question that is why we say ½ times 1, i.e. probability * number of times we ask the question. The level corresponds to the number of questions asked. Conclusion: If we ask our questions in the smartest possible way then the average number of questions we need will give us the Entropy. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E How to solve an exam type question involving Entropy and Information gain: Information you require: So they will give you a table which you can use to calculate Entropy when you have probability: So this notation E[2,1] means there is 3 of a specific element (“thing”) underneath a specific attribute. The 1st value is how many ‘yes’ the element corresponds with the target and the 2nd with how many ‘no’ it corresponds with e.g.: So if we dealing with ‘On Target’ element of Budget the notation will look like this: E[4,0], because all of the ‘On Target’ rows have Yes at target (take over), so there are 4 yes and there are 0 no’s To calculate the probability of this you go (1st value)/total. E.g. 2/3 = 0.67 But this does not correspond to any value of the table. So you you need to round it to the closest value: 0.67 = 0.70 Then E[2,1] = E 0.88 Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Steps with example: This one is easy. We will do it without steps: When they mean data they mean the target: p=0.6 E[6,4] = 0.98 1. Calculating remainder for all attributes: To do this we use the formulae: 𝑅𝐴𝑡𝑡𝑟𝑋 = 𝑅1𝑠𝑡 𝑣𝑎𝑙𝑢𝑒 𝑜𝑓 𝐴𝑡𝑡𝑟𝑋 + 𝑅2𝑛𝑑 𝑣𝑎𝑙𝑢𝑒 + 𝑅3𝑟𝑑 𝑣𝑎𝑙𝑢𝑒 + …. Remainder of element is calculated by P(value) * E [y,n ] 𝑅𝐵𝑢𝑑𝑔𝑒𝑡 = 𝑅𝑈𝑛𝑑𝑒𝑟 + 𝑅𝑜𝑣𝑒𝑟 + 𝑅𝑂𝑛 𝑇𝑎𝑟𝑔𝑒𝑡 = (3/10) * E[1,2] + (3/10) * E[1,2] + (4/10) * E[4,0] = 0.3 * 0.88 + 0.3 * 0.88 + 0.4 * 0 = 0.53 Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace 2. Now calculate the gain on each of the attributes: Formulae for calculating gain is: 𝑮𝒂𝒕𝒕𝒓𝑿 = 𝑬𝒕𝒂𝒓𝒈𝒆𝒕 - 𝑹𝒂𝒕𝒕𝒓𝑿 Now calculating the gain for each variable: 𝐺𝐵𝑢𝑑𝑔𝑒𝑡 = 𝐸𝑡𝑎𝑘𝑒𝑂𝑣𝑒𝑟 - 𝑅𝐵𝑢𝑑𝑔𝑒𝑡 = 0.98 - 0.53 = 0.45 3. Then list the root node of the highest information gain: As you can see that the attribute Budget has the highest information gain, thus it should be the root node. The arrows should be its values/elements: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace E How to determine which attribute will be chosen under a specific branch Steps with example: i) Its easy: Remember they can also ask calculate the Entropy of the Data. : E(take Over) = E[6:4] P=0.6 From table: E[takeover)= 0.97 Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace The steps are the same as the previous example except that we do not have to calculate the remainder for the ‘Time-line’ attribute since it has already been decided to be the root node: *Ask tutor if we need to calculate the gain and remainder of Time- Line since it is already the root? 1. Calculate Remainder of each attribute: 𝑹𝑨𝒕𝒕𝒓𝑿 = 𝑹𝟏𝒔𝒕 𝒗𝒂𝒍𝒖𝒆 𝒐𝒇 𝑨𝒕𝒕𝒓𝑿 + 𝑹𝟐𝒏𝒅 𝒗𝒂𝒍𝒖𝒆 + 𝑹𝟑𝒓𝒅 𝒗𝒂𝒍𝒖𝒆 + …. 𝑅𝐵𝑢𝑑𝑔𝑒𝑡 = 𝑅𝑢𝑛𝑑𝑒𝑟 + 𝑅𝑜𝑣𝑒𝑟 + 𝑅𝑂𝑛 𝑇𝑎𝑟𝑔𝑒𝑡 = (2/10) * E[1,1] + (4/10)*E[2,2] + (4/10)*E[3,1] = 0.2 + 0.4 + 0.32 = 0.92 Not doing the rest just writing down the answer: 𝑅𝑅𝑒𝑠𝑜𝑢𝑟𝑐𝑒𝑠 = 0.2 𝑅𝑆𝑒𝑛𝑡𝑖𝑚𝑒𝑛𝑡 = 0.98 2. Then calculate gain of each attribute 𝐺𝐵𝑢𝑑𝑔𝑒𝑡 = 𝐸𝑡𝑎𝑘𝑒𝑂𝑣𝑒𝑟 - 𝑅𝐵𝑢𝑑𝑔𝑒𝑡 = 0.97 – 0.92 = 0.05 𝐺𝑅𝑒𝑠𝑜𝑢𝑟𝑐𝑒𝑠 = 𝐸𝑡𝑎𝑘𝑒𝑂𝑣𝑒𝑟 - 𝑅𝑅𝑒𝑠𝑜𝑢𝑟𝑐𝑒𝑠 = 0.97 – 0.98 = -0.1 𝐺𝑆𝑒𝑛𝑡 = 𝐸𝑡𝑎𝑘𝑒𝑂𝑣𝑒𝑟 - 𝑅𝑆𝑒𝑛𝑡 = 0.97 – 0.98 = -0.1 3. Then list value with highest gain, this value will need to be next Budget must be underneath Ahead since it has the highest gain Definitely do this example: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace a) E = Ed1 + Ed2 + Ed3 Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace = E[2,3] + E[2,3] + E[1,4] = 0.53 + 0.53 + 0.46 = 1.52 b) Attribute A: D1 + D2 + D3 Entropy(A1) = E[1,1] + E[1,1} + E[0,0] = 0.5 + 0.5 +0 = 1 Entropy(A2) = 0.53 + 0.53 + 0.53 = 1.59 Gain(A) = 1.52 – P(A1) * Entropy(A1) – P(A2) * Entropy(A2) = 1.52 - 0.4 * 1 - 0.6 * 1.59 = 0.166 Attribute B Entropy(B1) = 0.39 + 0.53 + 0 Total: 3 = 0.92 Entropy(B2) = 0 + 0.5 + 0.5 Total: 2 = 1 Gain(B) = 1.52 - 0.6 * 0.92 - 0.4 * 1 = 0.568 Attribute C: Entropy(C1)= 0 + 0 + 0 Total: 1 = 0 Entrop(C2) = 0 + 0 + 0 Total: 2 = 0 Entrop(C3) = 0.5 + 0 + 0.5 =1 Gain(C) = 1.52 – 0 – 0 – 0.4 * 1 = 1.12 c) Attribute C, since it has the highest information gain. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace d) Taking the choice C1 must yield the node D1 and taking C2 will yield node D2, (since all the C1 yield D1 and all C2 yields D2). After C3 we need attribute B, since it has the 2nd highest gain. e) Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace **Don’t do this one How to solve Entropy problem using information gain and how to draw decision tree Steps with example: 1. Calculate Entropy of the target(last column) The last column is usually the target(deciding column). To calculate the Entropy of the target get the probability of ‘YES’ and probability of ‘NO’, i.e. the probability of all the classes in the last column. P(no)=5/14=0.36, P(Yes)=9/14=0.64 To calculate the Entropy use the formulae Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace 2. Then calculate the Entropy of each attribute over the target To do this you need to draw frequency table of each specific attribute with the target. e.g.: Then calculate Entropy of Target,attribute e.g. Do this for alll attributes 3. Then calculate the information gain of each attribute: To do this we go G(Target,AttributeX) = E(target) – E(target,AttributeX) e.g. Do this for all the attributes: 4. Choose attribute with the largest information gain as the decision node. Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace As seen Outlook attribute have the largest Gain. Then we branch out the table (this table: according to the attribute with the most gain: This is our tree so far: The tree is also with the table, but just rotated 5. Then we split branches with entropy more than 0 and say YES (or specific class) with branches: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace See above: at the Overcast branch in the table where it all says Yes, we must make its leaf equal to YES: The other branches with Entropy more than 0 requires further splitting: To split this: So we see which attribute matches the target, See Windy have ‘FALSE’ everywhere PlayGolf Have ‘YES’. So we can turn the table into this table: Which yields this: This table is left: We can match the target (PlayGolf) with the Humidity attribute. Thus the branch will look like this: Stuvia.com - The study-notes marketplace Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal Stuvia.com - The study-notes marketplace Powered by TCPDF (www.tcpdf.org) Downloaded by: YeNahGetThat | likewise52@protonmail.com Distribution of this document is illegal","libVersion":"0.2.3","langs":""}