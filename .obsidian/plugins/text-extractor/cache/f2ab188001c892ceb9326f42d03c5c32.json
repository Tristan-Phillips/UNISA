{"path":"Subjects/INF3720 - Human-Computer Interaction II/Unsorted/INF3720 Answers/INF3720 Answers/INF3720 203_2011_1_b.pdf","text":"INF3720/203/1/2011 INF3720 Human-Computer Interaction II Tutorial letter 203 Discussion of Assignment 3 Correction to Assignment 1 Important Additional Examination Information School of Computing 2 Important Additional Examination Information IMPORTANT: There will be a question on prototyping in the examination. You may ignore that question – it will not be marked as chapter 11 is excluded. We present the following extract from your tutorial letter 101: The syllabus for this module is covered in the chapters of the prescribed book as listed below. Not all of this material will be covered in detail. The syllabus includes the following: Chapters 1, 2, 4, 5, 7, 9, 10, 12, 14, 15 (not Chapters 3, 6, 8, 11 and 13) • What is interaction design? • Understanding and conceptualising interaction. • Designing for collaboration and communication. • Understanding how interfaces affect users. Data gathering. • The process of interaction design. • Identifying needs and establishing requirements. • Evaluation. • Testing and modelling users. • Analytical evaluation. Please refer to your tutorial letters 102 and 103 for further examination information. Die studiemateriaal vir INF3720 is slegs in Engels beskikbaar. U is welkom om u dosente te nader indien u enige probleme met die inhoud en/of terme sou ondervind. Correction to Assignment 1 QUESTION 2 a. What is a conceptual model? b. Briefly describe the four components that make up a conceptual model (according to Johnson and Henderson). (a) See page 51: High-level description of how a system is organized and operates. An abstraction that outlines what people can do with a product and what concepts are needed to understand interacting with it. (b) See pages 51-52: Metaphors and analogies to convey understanding. The concepts, objects and operations that users are exposed to. The relationship between those objects. The mappings between the concepts and the user experience. INF3720/203 3 Assignment 3 Nota aan Afrikaanse studente: Weens die tegniese aard van die studiemateriaal is hierdie studiebrief in Engels. Moet asb. nie huiwer om ons te kontak indien iets vir u nie duidelik is nie. Some of these questions were open-ended and student answers will be varied in terms of the specific technologies they chose to discuss, the specific social behaviours they focussed on, and the depth in which they treated these issues. Therefore there is no single model answer to these questions, but we will explain how we could have evaluated the answers by presenting a few examples as shown below. We also look at aspects such as: If it is an essay type answer is the essay well structured (i.e. does it have an introduction, a main body and a logical conclusion)? We also look at whether student use appropriate academic language and correctly reference all the sources consulted (where this was appropriate). Question 1 (Chapter 10) According Preece, et al. (2007), a requirement is ‘a statement about an intended product that specifies what it should do or how it should perform’. Using the explanations of the different kinds of requirements in section 10.3.1, describe the following requirements for the MyUnisa system: 1.1 Functional requirements. (4) 1.2 Data requirements. (4) 1.3 Environmental requirements (context of use). (8) 1.4 User characteristics. (4) Functional requirements – this describes what the product should do. For MyUnisa these could include facilities for uploading of assignments, downloading of tutorial letters and other study material, enabling asynchronous communication between student(s) and student(s), and student(s) and lecturer(s) via discussion forums, providing for a calendar-scheduling function, and providing a student account facility etc. Data requirements – this is the type, lifetime, size/volume, accuracy of data used. For MyUnisa the persistence of data should include the lifetime of study material – i.e. tutorial letters are removed at the beginning of a new academic semester, whilst students account data must be held for many years. Environmental requirements – this is the context of use. Technical aspects: a new addition to MyUnisa is the facility to upload MCQ data via a cellphone and the context of use is then the typical mobile phone characteristics such as small display size. Physical aspects: Mobile phones may be used under noisy circumstances, and under intermittent communications. Social aspects: Mobile phones may be used in an environment that is not private. Organizational aspects: Should MyUnisa users be trained or is it sufficient to provide them with a manual (such as a quick-start guide)? 4 User characteristics. MyUnisa users could have very diverse characteristics. They could be computer literate or illiterate. They could be English first language speakers or users that can barely understand English. They could be handicapped in some aspect such as visually or aurally challenged. Question 2 (Chapter 12) Assume the role of an expert evaluator and do a heuristic evaluation of a single typical student task that you have identified as a possible problem on MyUnisa. Use all ten heuristics that appear on pp. 686 and 687 of the prescribed book. The answer is dependent on the task chosen and we will just provide a few general guidelines here. Firstly, the evaluator should consider whether the ten Nielsen heuristics as presented on page 686 and 687 are all equally suitable for the evaluation of a task on the MyUnisa system. You may want to modify some of the heuristics (see page 688) to cater for unique aspects of the task that you have chosen or specific aspects of the MyUnisa system. Secondly you should consider in what format will you do the evaluation. The easiest is to construct a fill-in questionnaire listing your heuristics and then giving it to a few other MyUnisa users or students (including yourself) to complete. See figure 15.1 on page 689 for a short discussion on the number of evaluators that should be used. After the evaluation you could compile a list of all the usability problems that have been identified and then sort them according to their impact or severity. You can also sort the list according to how easy (or costly) it will be to fix the usability problems. You will then be able to present to the MyUnisa development team with a list of usability problems that are rated as severe and easy to fix at the top (i.e. high priority problems) to not severe and difficult to fix at the bottom (or low priority or costly-to-fix problems). Listed below are some examples of the most frustrating aspects of the MyUnisa interface that came up in the last year’s students' answers (Why are these aspects frustrating? – is it because of usability or task-support concerns?) 1. The page where students can provide their credit card information for payment does not inspire trust. This may cause students to choose another payment option which may be more time-consuming and require more effort. 2. Students find it difficult to access the correct information about compiling a curriculum. They expect to find the information on myUnisa but then have to revert back to Google or the general Unisa web site. 3. Students find the split between myUnisa and myLife frustrating. They now have to manage an additional email account and resetting of passwords requires many steps. 4. When moving between tabs the complete page is reloaded instead of just the parts that change. For students with slow internet connections this will cause frustration. 5. Because of the option to submit assignments through myUnisa, students often leave the submission to the last minute. It is then extremely frustrating if the system is not available. INF3720/203 5 Question 3 (Chapter 14) – 20 marks Compare usability testing (UT) and field studies (FS) under the following headings: 3.1 The environment in which the evaluation is conducted. (5) 3.2 The participants. (5) 3.3 Data collection. (5) 3.4 Advantages and disadvantages. (5) 3.1 The environment in which the evaluation is conducted. Field studies (FS), are conducted in the natural environment where the system or product is used and is very different from the controlled conditions (see the last paragraph on page 655) that is evident during formal usability testing (UT). It is interesting to note that during UT the focus is mainly on the product being tested and its usability problems, whilst during FT the focus is also on the user and his/her use environment (as well as on the product). 3.2 The participants. For UT 5-12 users are an acceptable number, whereas FS may include thousands or even just one participant. Also note the comparison in table 14.3 (page 554) between different participant designs. 3.3 Data collection. Compare UT data collection (see pages 656, 656) (it includes the user test, interviews and the user satisfaction questionnaire), with FS data collection methods (see page 670). Typically UT include performance, efficiency and effectiveness data collected under controlled conditions, whereas for FS the same type of data are collected within the real context of use. The instruments used for data collection may then be different (for FS the primary aim should be its unobtrusivess), but generally both use interviews, observations, questionnaires, and video/audio recordings. 3.4 Advantages and disadvantages. See Chapter 12 pages 591-592, and page 594. Table12.1 compares three evaluation approaches: UT, FS and Analytical. Also see pages 674 and 678 for a summarised comparison of the two approaches: “Usability testing is most suitable for testing software upgrades, prototypes, and working systems, and more specific questions are usually addressed. Field studies are used when discovering how products and prototypes will be used within their intended socio- physical context of use.” © UNISA 2011","libVersion":"0.2.3","langs":""}